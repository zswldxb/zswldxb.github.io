<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.1.1"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon_logo_2.svg"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon_logo_2.svg"><link rel="mask-icon" href="/images/logo_2.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/themes/blue/pace-theme-minimal.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"zswldxb.github.io",root:"/",scheme:"Mist",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:type" content="website"><meta property="og:title" content="智商为零的小白的博客"><meta property="og:url" content="https://zswldxb.github.io/page/14/index.html"><meta property="og:site_name" content="智商为零的小白的博客"><meta property="og:description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:locale" content="zh_CN"><meta property="article:author" content="智商为零的小白"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://zswldxb.github.io/page/14/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!0,isPost:!1,lang:"zh-CN"}</script><title>智商为零的小白的博客</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">智商为零的小白的博客</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content index posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002002000.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002002000.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.RandomAffine</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:20:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:20:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:19:10" itemprop="dateModified" datetime="2021-10-27T09:19:10+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002002000.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002002000.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.7k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsrandomaffine"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsrandomaffine"></a> Pytorch.torchvision.transforms.RandomAffine</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomAffine</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Random affine transformation of the image keeping center invariant.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        degrees (sequence or number): Range of degrees to select from. If degrees is a number instead of sequence like (min, max), the range of degrees will be (-degrees, +degrees). Set to 0 to deactivate rotations.</span></span><br><span class="line"><span class="string">        translate (tuple, optional): tuple of maximum absolute fraction for horizontal and vertical translations. For example translate=(a, b), then horizontal shift is randomly sampled in the range -img_width * a &lt; dx &lt; img_width * a and vertical shift is randomly sampled in the range -img_height * b &lt; dy &lt; img_height * b. Will not translate by default.</span></span><br><span class="line"><span class="string">        scale (tuple, optional): scaling factor interval, e.g (a, b), then scale is randomly sampled from the range a &lt;= scale &lt;= b. Will keep original scale by default.</span></span><br><span class="line"><span class="string">        shear (sequence or number, optional): Range of degrees to select from. If shear is a number, a shear parallel to the x axis in the range (-shear, +shear) will be applied. Else if shear is a sequence of 2 values a shear parallel to the x axis in the range (shear[0], shear[1]) will be applied. Else if shear is a sequence of 4 values, a x-axis shear in (shear[0], shear[1]) and y-axis shear in (shear[2], shear[3]) will be applied. Will not apply shear by default.</span></span><br><span class="line"><span class="string">        interpolation (InterpolationMode): Desired interpolation enum defined by :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.NEAREST``. If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` are supported. For backward compatibility integer values (e.g. ``PIL.Image.NEAREST``) are still acceptable.</span></span><br><span class="line"><span class="string">        fill (sequence or number): Pixel fill value for the area outside the transformed image. Default is ``0``. If given a number, the value is used for all bands respectively.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>RandomAffine</code> 将对图片进行仿射变换，仿射变换可由一系列原子变换的复合来实现，包括旋转 <code>Rotation</code>，平移 <code>translation</code>，放缩 <code>scale</code>，错切 <code>sheer</code> 和翻转 <code>flip</code>。</p><p>参数：</p><ul><li><code>degrees</code>：设置旋转角度范围，若为 <code>float</code>，则旋转角度的取值范围为 <code>(-degrees, +degrees)</code>，若为 <code>(min, max)</code>，则旋转角度的取值范围为 <code>(min, max)</code>。</li><li><code>translate</code>：平移因子 <code>(a, b)</code>，表示图片宽度和高度的平移因子，宽度平移数值的取值范围为 <code>-img_width * a &lt; dx &lt; img_width * a</code>，高度平移数值的取值范围为 <code>-img_height * b &lt; dy &lt; img_height * b</code>。</li><li><code>scale</code>：放缩比例，放缩的图片比例介于 <code>(scale[0], scale[1])</code> 之间。</li><li><code>shear</code>：错切角度设置。<ul><li>若 <code>shear</code> 为数值，则 <code>x</code> 轴在 <code>(-shear, shear)</code> 之间随机选择错切角度。</li><li>若 <code>shear</code> 为长度为 <code>2</code> 的 <code>sequence</code>，则 <code>x</code> 轴在 <code>(shear[0], shear[1])</code> 之间随机选择错切角度。</li><li>若 <code>shear</code> 为长度为 <code>4</code> 的 <code>sequence</code>，则 <code>x</code> 轴在 <code>(shear[0], shear[1])</code> 之间随机选择错切角度，<code>y</code> 轴在 <code>(shear[2], shear[3])</code> 之间随机选择错切角度。</li></ul></li><li><code>interpolation</code>：插值模式。</li><li><code>fill</code>：填充值。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">100</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomAffine(degrees=(<span class="number">10</span>, <span class="number">20</span>),</span><br><span class="line">                            translate=(<span class="number">0.5</span>, <span class="number">0.5</span>),</span><br><span class="line">                            scale=(<span class="number">0.5</span>, <span class="number">2</span>),</span><br><span class="line">                            shear=(<span class="number">0</span>, <span class="number">10</span>, <span class="number">0</span>, <span class="number">10</span>),</span><br><span class="line">                            fill=<span class="number">255</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[255, 255,  40,  42,  43,  45,  37,  38, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255,  61,  62,  54,  56,  57,  59, 255, 255],</span></span><br><span class="line"><span class="string">         [255,  80,  81,  73,  75,  76,  78, 255, 255, 255],</span></span><br><span class="line"><span class="string">         [255,  91,  92,  94,  95,  97,  99, 255, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255, 255, 255, 255, 255, 255, 255, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255, 255, 255, 255, 255, 255, 255, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255, 255, 255, 255, 255, 255, 255, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255, 255, 255, 255, 255, 255, 255, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255, 255, 255, 255, 255, 255, 255, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255, 255, 255, 255, 255, 255, 255, 255, 255]]],</span></span><br><span class="line"><span class="string">       dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002001900.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001900.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.LinearTransformation</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:19:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:19:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:18:02" itemprop="dateModified" datetime="2021-10-27T09:18:02+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001900.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001900.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.9k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformslineartransformation"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformslineartransformation"></a> Pytorch.torchvision.transforms.LinearTransformation</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinearTransformation</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Transform a tensor image with a square transformation matrix and a mean_vector computed offline. This transform does not support PIL Image. Given transformation_matrix and mean_vector, will flatten the torch.*Tensor and subtract mean_vector from it which is then followed by computing the dot product with the transformation matrix and then reshaping the tensor to its original shape.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Applications:</span></span><br><span class="line"><span class="string">        whitening transformation: Suppose X is a column vector zero-centered data. Then compute the data covariance matrix [D x D] with torch.mm(X.t(), X), perform SVD on this matrix and pass it as transformation_matrix.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        transformation_matrix (Tensor): tensor [D x D], D = C x H x W</span></span><br><span class="line"><span class="string">        mean_vector (Tensor): tensor [D], D = C x H x W</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>LinearTransformation</code> 将每个输入图片展平为一维张量，然后减去 <code>mean_vector</code> 后与 <code>transformation_matrix</code> 进行矩阵乘法，之后 <code>reshape</code> 为输入图片的形状。可以用于白化变换。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">27</span>, dtype=torch.uint8).view(<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2],</span></span><br><span class="line"><span class="string">         [ 3,  4,  5],</span></span><br><span class="line"><span class="string">         [ 6,  7,  8]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 9, 10, 11],</span></span><br><span class="line"><span class="string">         [12, 13, 14],</span></span><br><span class="line"><span class="string">         [15, 16, 17]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[18, 19, 20],</span></span><br><span class="line"><span class="string">         [21, 22, 23],</span></span><br><span class="line"><span class="string">         [24, 25, 26]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">transformation_matrix = torch.randn((<span class="number">27</span>, <span class="number">27</span>))</span><br><span class="line">mean_vector = torch.randn(<span class="number">27</span>)</span><br><span class="line">t = transforms.LinearTransformation(transformation_matrix, mean_vector)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ -14.9178,   58.1802,  -72.7115],</span></span><br><span class="line"><span class="string">         [   3.6158,   41.1680,   34.1660],</span></span><br><span class="line"><span class="string">         [  74.3085,  -31.5985,   26.1868]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ -77.4617,  -32.0464,   58.4086],</span></span><br><span class="line"><span class="string">         [  81.9418,  138.2631,  -49.3175],</span></span><br><span class="line"><span class="string">         [ -20.2952,   46.8438,  -19.6297]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ -22.5609,   16.5201,   39.5175],</span></span><br><span class="line"><span class="string">         [  63.9926,  -49.8711,   59.0279],</span></span><br><span class="line"><span class="string">         [  20.9642,   38.1091, -127.6566]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002001800.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001800.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.Grayscale</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:18:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:18:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:17:44" itemprop="dateModified" datetime="2021-10-27T09:17:44+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001800.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001800.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.4k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsgrayscale"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsgrayscale"></a> Pytorch.torchvision.transforms.Grayscale</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Grayscale</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Convert image to grayscale.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., 3, H, W] shape, where ... means an arbitrary number of leading dimensions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        num_output_channels (int): (1 or 3) number of channels desired for output image</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        PIL Image: Grayscale version of the input.</span></span><br><span class="line"><span class="string">        - If ``num_output_channels == 1`` : returned image is single channel</span></span><br><span class="line"><span class="string">        - If ``num_output_channels == 3`` : returned image is 3 channel with r == g == b</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>Grayscale</code> 将图片转换为灰度图。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">27</span>, dtype=torch.uint8).view(<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2],</span></span><br><span class="line"><span class="string">         [ 3,  4,  5],</span></span><br><span class="line"><span class="string">         [ 6,  7,  8]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 9, 10, 11],</span></span><br><span class="line"><span class="string">         [12, 13, 14],</span></span><br><span class="line"><span class="string">         [15, 16, 17]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[18, 19, 20],</span></span><br><span class="line"><span class="string">         [21, 22, 23],</span></span><br><span class="line"><span class="string">         [24, 25, 26]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.Grayscale()</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 7,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 11, 12],</span></span><br><span class="line"><span class="string">         [13, 14, 15]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.Grayscale(<span class="number">3</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 7,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 11, 12],</span></span><br><span class="line"><span class="string">         [13, 14, 15]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 7,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 11, 12],</span></span><br><span class="line"><span class="string">         [13, 14, 15]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 7,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 11, 12],</span></span><br><span class="line"><span class="string">         [13, 14, 15]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002001700.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001700.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.ColorJitter</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:17:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:17:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:16:30" itemprop="dateModified" datetime="2021-10-27T09:16:30+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001700.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001700.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.6k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformscolorjitter"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformscolorjitter"></a> Pytorch.torchvision.transforms.ColorJitter</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ColorJitter</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Randomly change the brightness, contrast, saturation and hue of an image.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., 3, H, W] shape, where ... means an arbitrary number of leading dimensions. If img is PIL Image, mode &quot;1&quot;, &quot;L&quot;, &quot;I&quot;, &quot;F&quot; and modes with transparency (alpha channel) are not supported.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        brightness (float or tuple of float (min, max)): How much to jitter brightness. brightness_factor is chosen uniformly from [max(0, 1 - brightness), 1 + brightness] or the given [min, max]. Should be non negative numbers.</span></span><br><span class="line"><span class="string">        contrast (float or tuple of float (min, max)): How much to jitter contrast. contrast_factor is chosen uniformly from [max(0, 1 - contrast), 1 + contrast] or the given [min, max]. Should be non negative numbers.</span></span><br><span class="line"><span class="string">        saturation (float or tuple of float (min, max)): How much to jitter saturation. saturation_factor is chosen uniformly from [max(0, 1 - saturation), 1 + saturation] or the given [min, max]. Should be non negative numbers.</span></span><br><span class="line"><span class="string">        hue (float or tuple of float (min, max)): How much to jitter hue. hue_factor is chosen uniformly from [-hue, hue] or the given [min, max]. Should have 0&lt;= hue &lt;= 0.5 or -0.5 &lt;= min &lt;= max &lt;= 0.5.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>ColorJitter</code> 将改变图片的属性：亮度 <code>brightness</code>、对比度 <code>contrast</code>、饱和度 <code>saturation</code> 和色调 <code>hue</code>。</p><ul><li><code>brightness</code>：若为 <code>float</code>，则 <code>brightness_factor</code> 将根据均匀分布从 <code>[max(0, 1 - brightness), 1 + brightness]</code> 中采样，若为 <code>(min, max)</code>，则 <code>brightness_factor</code> 将根据均匀分布从 <code>[min, max]</code> 中采样。</li><li><code>contrast</code>：若为 <code>float</code>，则 <code>contrast_factor</code> 将根据均匀分布从 <code>[max(0, 1 - brightness), 1 + brightness]</code> 中采样，若为 <code>(min, max)</code>，则 <code>contrast_factor</code> 将根据均匀分布从 <code>[min, max]</code> 中采样。</li><li><code>saturation</code>：若为 <code>float</code>，则 <code>saturation_factor</code> 将根据均匀分布从 <code>[max(0, 1 - brightness), 1 + brightness]</code> 中采样，若为 <code>(min, max)</code>，则 <code>saturation_factor</code> 将根据均匀分布从 <code>[min, max]</code> 中采样。</li><li><code>hue</code>：若为 <code>float</code>，则 <code>hue_factor</code> 将根据均匀分布从 <code>[-hue, hue]</code> 中采样，其中 <code>0&lt;= hue &lt;= 0.5</code>，若为 <code>(min, max)</code>，则 <code>hue_factor</code> 将根据均匀分布从 <code>[min, max]</code> 中采样，其中 <code>-0.5 &lt;= min &lt;= max &lt;= 0.5</code>。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">27</span>, dtype=torch.uint8).view(<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2],</span></span><br><span class="line"><span class="string">         [ 3,  4,  5],</span></span><br><span class="line"><span class="string">         [ 6,  7,  8]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 9, 10, 11],</span></span><br><span class="line"><span class="string">         [12, 13, 14],</span></span><br><span class="line"><span class="string">         [15, 16, 17]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[18, 19, 20],</span></span><br><span class="line"><span class="string">         [21, 22, 23],</span></span><br><span class="line"><span class="string">         [24, 25, 26]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.ColorJitter(brightness=<span class="number">0.5</span>, contrast=<span class="number">0.5</span>, saturation=<span class="number">0.5</span>, hue=<span class="number">0.5</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[14, 15, 16],</span></span><br><span class="line"><span class="string">         [16, 17, 18],</span></span><br><span class="line"><span class="string">         [19, 20, 20]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[15, 16, 16],</span></span><br><span class="line"><span class="string">         [17, 18, 19],</span></span><br><span class="line"><span class="string">         [20, 20, 21]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 5,  5,  6],</span></span><br><span class="line"><span class="string">         [ 6,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 10, 11]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002001600.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001600.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.Pad</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:16:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:16:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:18:32" itemprop="dateModified" datetime="2021-10-27T09:18:32+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001600.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001600.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.8k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformspad"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformspad"></a> Pytorch.torchvision.transforms.Pad</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pad</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Pad the given image on all sides with the given &quot;pad&quot; value.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means at most 2 leading dimensions for mode reflect and symmetric, at most 3 leading dimensions for mode edge, and an arbitrary number of leading dimensions for mode constant</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        padding (int or sequence): Padding on each border. If a single int is provided this is used to pad all borders. If sequence of length 2 is provided this is the padding on left/right and top/bottom respectively. If a sequence of length 4 is provided this is the padding for the left, top, right and bottom borders respectively.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	note:</span></span><br><span class="line"><span class="string">		In torchscript mode padding as single int is not supported, use a sequence of length 1: ``[padding, ]``.</span></span><br><span class="line"><span class="string">        fill (number or str or tuple): Pixel fill value for constant fill. Default is 0. If a tuple of length 3, it is used to fill R, G, B channels respectively. This value is only used when the padding_mode is constant. Only number is supported for torch Tensor. Only int or str or tuple value is supported for PIL Image.</span></span><br><span class="line"><span class="string">        padding_mode (str): Type of padding. Should be: constant, edge, reflect or symmetric. Default is constant.</span></span><br><span class="line"><span class="string">            - constant: pads with a constant value, this value is specified with fill</span></span><br><span class="line"><span class="string">            - edge: pads with the last value at the edge of the image. If input a 5D torch Tensor, the last 3 dimensions will be padded instead of the last 2</span></span><br><span class="line"><span class="string">            - reflect: pads with reflection of image without repeating the last value on the edge. For example, padding [1, 2, 3, 4] with 2 elements on both sides in reflect mode will result in [3, 2, 1, 2, 3, 4, 3, 2]</span></span><br><span class="line"><span class="string">            - symmetric: pads with reflection of image repeating the last value on the edge. For example, padding [1, 2, 3, 4] with 2 elements on both sides in symmetric mode will result in [2, 1, 1, 2, 3, 4, 4, 3]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>Pad</code> 将对图片进行填充。</p><p>参数：</p><ul><li><code>padding</code>：表示填充情况，若 <code>padding</code> 为 <code>int</code> 值，则在上下左右都填充 <code>padding</code>，若 <code>padding</code> 为长度为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">2</span></span></span></span> 的序列，则左右填充 <code>padding[0]</code>，上下填充 <code>padding[1]</code>，若 <code>padding</code> 为长度为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">4</span></span></span></span> 的序列，则左上右下分别填充为 <code>padding[0], padding[1], padding[2], padding[3]</code>。注意 <code>padding</code> 为 <code>int</code> 在 <code>torchscript</code> 模式下不支持，建议使用长度为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 的序列 <code>[padding, ]</code>。</li><li><code>fill</code>：表示填充的数值，默认为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>，其仅在 <code>padding_mode=constant</code> 时有效。</li><li><code>padding_mode</code> 为设置填充模式，有如下几种模式：<ul><li><code>constant</code>：将填充为固定值 <code>fill</code>。</li><li><code>edge</code>：将根据边缘值进行填充。</li><li><code>reflect</code>：进行反射填充。</li><li><code>symmetric</code>：进行对称填充。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">16</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3],</span></span><br><span class="line"><span class="string">         [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">         [ 8,  9, 10, 11],</span></span><br><span class="line"><span class="string">         [12, 13, 14, 15]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.Pad(<span class="number">2</span>, fill=<span class="number">255</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[255, 255, 255, 255, 255, 255, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255, 255, 255, 255, 255, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255,   0,   1,   2,   3, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255,   4,   5,   6,   7, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255,   8,   9,  10,  11, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255,  12,  13,  14,  15, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255, 255, 255, 255, 255, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255, 255, 255, 255, 255, 255, 255]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002001500.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001500.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.Normalize</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:15:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:15:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:29:58" itemprop="dateModified" datetime="2021-10-27T09:29:58+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001500.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001500.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.6k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsnormalize"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsnormalize"></a> Pytorch.torchvision.transforms.Normalize</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Normalize</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Normalize a tensor image with mean and standard deviation. This transform does not support PIL Image. Given mean: ``(mean[1],...,mean[n])`` and std: ``(std[1],..,std[n])`` for ``n`` channels, this transform will normalize each channel of the input ``torch.*Tensor`` i.e., ``output[channel] = (input[channel] - mean[channel]) / std[channel]``</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    note:</span></span><br><span class="line"><span class="string">        This transform acts out of place, i.e., it does not mutate the input tensor.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        mean (sequence): Sequence of means for each channel.</span></span><br><span class="line"><span class="string">        std (sequence): Sequence of standard deviations for each channel.</span></span><br><span class="line"><span class="string">        inplace(bool,optional): Bool to make this operation in-place.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>Normalize</code> 将在每个通道上进行操作，<code>output[channel] = (input[channel] - mean[channel]) / std[channel]</code>，若设置 <code>inplace=False</code>，则不会进行就地操作，若设置 <code>inplace=True</code>，则进行就地操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">27</span>, dtype=torch.float32).view(<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0.,  1.,  2.],</span></span><br><span class="line"><span class="string">         [ 3.,  4.,  5.],</span></span><br><span class="line"><span class="string">         [ 6.,  7.,  8.]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 9., 10., 11.],</span></span><br><span class="line"><span class="string">         [12., 13., 14.],</span></span><br><span class="line"><span class="string">         [15., 16., 17.]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[18., 19., 20.],</span></span><br><span class="line"><span class="string">         [21., 22., 23.],</span></span><br><span class="line"><span class="string">         [24., 25., 26.]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ -2.1179,   2.2489,   6.6157],</span></span><br><span class="line"><span class="string">         [ 10.9825,  15.3493,  19.7162],</span></span><br><span class="line"><span class="string">         [ 24.0830,  28.4498,  32.8166]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 38.1429,  42.6071,  47.0714],</span></span><br><span class="line"><span class="string">         [ 51.5357,  56.0000,  60.4643],</span></span><br><span class="line"><span class="string">         [ 64.9286,  69.3929,  73.8571]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 78.1956,  82.6400,  87.0844],</span></span><br><span class="line"><span class="string">         [ 91.5289,  95.9733, 100.4178],</span></span><br><span class="line"><span class="string">         [104.8622, 109.3067, 113.7511]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0.,  1.,  2.],</span></span><br><span class="line"><span class="string">         [ 3.,  4.,  5.],</span></span><br><span class="line"><span class="string">         [ 6.,  7.,  8.]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 9., 10., 11.],</span></span><br><span class="line"><span class="string">         [12., 13., 14.],</span></span><br><span class="line"><span class="string">         [15., 16., 17.]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[18., 19., 20.],</span></span><br><span class="line"><span class="string">         [21., 22., 23.],</span></span><br><span class="line"><span class="string">         [24., 25., 26.]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.Normalize(mean=[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>], std=[<span class="number">0.1</span>, <span class="number">1.</span>, <span class="number">10.</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0.0000, 10.0000, 20.0000],</span></span><br><span class="line"><span class="string">         [30.0000, 40.0000, 50.0000],</span></span><br><span class="line"><span class="string">         [60.0000, 70.0000, 80.0000]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 9.0000, 10.0000, 11.0000],</span></span><br><span class="line"><span class="string">         [12.0000, 13.0000, 14.0000],</span></span><br><span class="line"><span class="string">         [15.0000, 16.0000, 17.0000]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 1.8000,  1.9000,  2.0000],</span></span><br><span class="line"><span class="string">         [ 2.1000,  2.2000,  2.3000],</span></span><br><span class="line"><span class="string">         [ 2.4000,  2.5000,  2.6000]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0.0000, 10.0000, 20.0000],</span></span><br><span class="line"><span class="string">         [30.0000, 40.0000, 50.0000],</span></span><br><span class="line"><span class="string">         [60.0000, 70.0000, 80.0000]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 9.0000, 10.0000, 11.0000],</span></span><br><span class="line"><span class="string">         [12.0000, 13.0000, 14.0000],</span></span><br><span class="line"><span class="string">         [15.0000, 16.0000, 17.0000]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[ 1.8000,  1.9000,  2.0000],</span></span><br><span class="line"><span class="string">         [ 2.1000,  2.2000,  2.3000],</span></span><br><span class="line"><span class="string">         [ 2.4000,  2.5000,  2.6000]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002001400.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001400.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.Resize</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:14:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:14:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:24:06" itemprop="dateModified" datetime="2021-10-27T09:24:06+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001400.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001400.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.8k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsresize"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsresize"></a> Pytorch.torchvision.transforms.Resize</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Resize</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Resize the input image to the given size.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    warning:</span></span><br><span class="line"><span class="string">        The output image might be different depending on its type: when downsampling, the interpolation of PIL images and tensors is slightly different, because PIL applies antialiasing. This may lead to significant differences  in the performance of a network. Therefore, it is preferable to train and serve a model with the same input types.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        size (sequence or int): Desired output size. If size is a sequence like (h, w), output size will be matched to this. If size is an int, smaller edge of the image will be matched to this number. i.e, if height &gt; width, then image will be rescaled to (size * height / width, size).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	note:</span></span><br><span class="line"><span class="string">		In torchscript mode size as single int is not supported, use a sequence of length 1: ``[size, ]``.</span></span><br><span class="line"><span class="string">        interpolation (InterpolationMode): Desired interpolation enum defined by :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.BILINEAR``. If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` and ``InterpolationMode.BICUBIC`` are supported. For backward compatibility integer values (e.g. ``PIL.Image.NEAREST``) are still acceptable.</span></span><br><span class="line"><span class="string">        max_size (int, optional): The maximum allowed for the longer edge of the resized image: if the longer edge of the image is greater than ``max_size`` after being resized according to ``size``, then the image is resized again so that the longer edge is equal to ``max_size``. As a result, ``size`` might be overruled, i.e the smaller edge may be shorter than ``size``. This is only supported if ``size`` is an int (or a sequence of length 1 in torchscript mode).</span></span><br><span class="line"><span class="string">        antialias (bool, optional): antialias flag. If ``img`` is PIL Image, the flag is ignored and anti-alias is always used. If ``img`` is Tensor, the flag is False by default and can be set True for ``InterpolationMode.BILINEAR`` only mode.</span></span><br><span class="line"><span class="string">	&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>Resize</code> 将对输入图片进行放缩，若 <code>size</code> 为 <code>(h, w)</code>，则输出大小为 <code>(h, w)</code>，若 <code>size</code> 为 <code>int</code> 类型，则表示短边为 <code>size</code>，长边将进行放缩，例如 <code>h &gt; w</code> 时，将缩放为 <code>(size * h / w, size)</code>。如果 <code>max_size</code> 为 <code>int</code> 类型，则表示将长放缩后的图片再等比例放缩，使得长边为 <code>max_size</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">150</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">15</span>, <span class="number">10</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9],</span></span><br><span class="line"><span class="string">         [ 10,  11,  12,  13,  14,  15,  16,  17,  18,  19],</span></span><br><span class="line"><span class="string">         [ 20,  21,  22,  23,  24,  25,  26,  27,  28,  29],</span></span><br><span class="line"><span class="string">         [ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39],</span></span><br><span class="line"><span class="string">         [ 40,  41,  42,  43,  44,  45,  46,  47,  48,  49],</span></span><br><span class="line"><span class="string">         [ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59],</span></span><br><span class="line"><span class="string">         [ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69],</span></span><br><span class="line"><span class="string">         [ 70,  71,  72,  73,  74,  75,  76,  77,  78,  79],</span></span><br><span class="line"><span class="string">         [ 80,  81,  82,  83,  84,  85,  86,  87,  88,  89],</span></span><br><span class="line"><span class="string">         [ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99],</span></span><br><span class="line"><span class="string">         [100, 101, 102, 103, 104, 105, 106, 107, 108, 109],</span></span><br><span class="line"><span class="string">         [110, 111, 112, 113, 114, 115, 116, 117, 118, 119],</span></span><br><span class="line"><span class="string">         [120, 121, 122, 123, 124, 125, 126, 127, 128, 129],</span></span><br><span class="line"><span class="string">         [130, 131, 132, 133, 134, 135, 136, 137, 138, 139],</span></span><br><span class="line"><span class="string">         [140, 141, 142, 143, 144, 145, 146, 147, 148, 149]]],</span></span><br><span class="line"><span class="string">       dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.Resize((<span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[  8,   9,  10,  11,  13,  14,  15,  16],</span></span><br><span class="line"><span class="string">         [ 33,  34,  35,  36,  38,  39,  40,  41],</span></span><br><span class="line"><span class="string">         [ 58,  59,  60,  61,  63,  64,  65,  66],</span></span><br><span class="line"><span class="string">         [ 83,  84,  85,  86,  88,  89,  90,  91],</span></span><br><span class="line"><span class="string">         [108, 109, 110, 111, 113, 114, 115, 116],</span></span><br><span class="line"><span class="string">         [133, 134, 135, 136, 138, 139, 140, 141]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.Resize(<span class="number">6</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[  4,   5,   7,   9,  10,  12],</span></span><br><span class="line"><span class="string">         [ 20,  22,  24,  25,  27,  29],</span></span><br><span class="line"><span class="string">         [ 37,  39,  40,  42,  44,  45],</span></span><br><span class="line"><span class="string">         [ 54,  55,  57,  59,  60,  62],</span></span><br><span class="line"><span class="string">         [ 70,  72,  74,  75,  77,  79],</span></span><br><span class="line"><span class="string">         [ 87,  89,  90,  92,  94,  95],</span></span><br><span class="line"><span class="string">         [104, 105, 107, 109, 110, 112],</span></span><br><span class="line"><span class="string">         [120, 122, 124, 125, 127, 129],</span></span><br><span class="line"><span class="string">         [137, 139, 140, 142, 144, 145]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.Resize(<span class="number">6</span>, max_size=<span class="number">8</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[  5,   7,   9,  11,  13],</span></span><br><span class="line"><span class="string">         [ 24,  26,  28,  30,  32],</span></span><br><span class="line"><span class="string">         [ 42,  44,  46,  48,  50],</span></span><br><span class="line"><span class="string">         [ 61,  63,  65,  67,  69],</span></span><br><span class="line"><span class="string">         [ 80,  82,  84,  86,  88],</span></span><br><span class="line"><span class="string">         [ 99, 101, 103, 105, 107],</span></span><br><span class="line"><span class="string">         [117, 119, 121, 123, 125],</span></span><br><span class="line"><span class="string">         [136, 138, 140, 142, 144]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002001300.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001300.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.RandomRotation</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:13:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:13:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:23:20" itemprop="dateModified" datetime="2021-10-27T09:23:20+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001300.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001300.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.6k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsrandomrotation"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsrandomrotation"></a> Pytorch.torchvision.transforms.RandomRotation</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomRotation</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Rotate the image by angle.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        degrees (sequence or number): Range of degrees to select from. If degrees is a number instead of sequence like (min, max), the range of degrees will be (-degrees, +degrees).</span></span><br><span class="line"><span class="string">        interpolation (InterpolationMode): Desired interpolation enum defined by :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.NEAREST``. If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` are supported. For backward compatibility integer values (e.g. ``PIL.Image.NEAREST``) are still acceptable.</span></span><br><span class="line"><span class="string">        expand (bool, optional): Optional expansion flag. If true, expands the output to make it large enough to hold the entire rotated image. If false or omitted, make the output image the same size as the input image. Note that the expand flag assumes rotation around the center and no translation.</span></span><br><span class="line"><span class="string">        center (sequence, optional): Optional center of rotation, (x, y). Origin is the upper left corner. Default is the center of the image.</span></span><br><span class="line"><span class="string">        fill (sequence or number): Pixel fill value for the area outside the rotated image. Default is ``0``. If given a number, the value is used for all bands respectively.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>RandomRotation</code> 将输入图像随机旋转。</p><p>参数：</p><ul><li><code>degrees</code>：表示旋转的角度的最小值和最大值，若为一个数值，则最小值为 <code>-degrees</code>，最大值为 <code>+degrees</code>。</li><li><code>interpolation</code>：表示插值模式。</li><li><code>center</code>：表示旋转中心。</li><li><code>fill</code>：表示填充元素。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">100</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomRotation(degrees=(<span class="number">10</span>, <span class="number">20</span>), center=(<span class="number">1</span>, <span class="number">1</span>), fill=<span class="number">255</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[  0,   1,   2,  13,  14,  15,  26,  27,  28,  29],</span></span><br><span class="line"><span class="string">         [ 10,  11,  12,  23,  24,  25,  26,  37,  38,  39],</span></span><br><span class="line"><span class="string">         [ 20,  21,  22,  32,  33,  34,  35,  46,  47,  48],</span></span><br><span class="line"><span class="string">         [255,  30,  31,  42,  43,  44,  45,  56,  57,  58],</span></span><br><span class="line"><span class="string">         [255,  40,  41,  52,  53,  54,  55,  66,  67,  68],</span></span><br><span class="line"><span class="string">         [255,  50,  51,  62,  63,  64,  65,  76,  76,  77],</span></span><br><span class="line"><span class="string">         [255, 255,  60,  61,  72,  73,  74,  85,  86,  87],</span></span><br><span class="line"><span class="string">         [255, 255,  70,  71,  82,  83,  84,  95,  96,  97],</span></span><br><span class="line"><span class="string">         [255, 255,  80,  81,  92,  93,  94,  95, 255, 255],</span></span><br><span class="line"><span class="string">         [255, 255,  90,  91, 255, 255, 255, 255, 255, 255]]],</span></span><br><span class="line"><span class="string">       dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002001200.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001200.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.RandomVerticalFlip</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:12:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:12:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:23:46" itemprop="dateModified" datetime="2021-10-27T09:23:46+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001200.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001200.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.4k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsrandomverticalflip"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsrandomverticalflip"></a> Pytorch.torchvision.transforms.RandomVerticalFlip</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TenCrop</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crop the given image into four corners and the central crop plus the flipped version of these (horizontal flipping is used by default). If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note:</span></span><br><span class="line"><span class="string">         This transform returns a tuple of images and there may be a mismatch in the number of inputs and targets your Dataset returns. See below for an example of how to deal with this.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        size (sequence or int): Desired output size of the crop. If size is an int instead of sequence like (h, w), a square crop (size, size) is made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).</span></span><br><span class="line"><span class="string">        vertical_flip (bool): Use vertical flipping instead of horizontal</span></span><br><span class="line"><span class="string">	&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>RandomHorizontalFlip</code> 将以概率 <code>p</code> 对图片进行垂直翻转。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">16</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3],</span></span><br><span class="line"><span class="string">         [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">         [ 8,  9, 10, 11],</span></span><br><span class="line"><span class="string">         [12, 13, 14, 15]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomVerticalFlip(p=<span class="number">0.6</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[12, 13, 14, 15],</span></span><br><span class="line"><span class="string">         [ 8,  9, 10, 11],</span></span><br><span class="line"><span class="string">         [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">         [ 0,  1,  2,  3]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002001100.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001100.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.RandomHorizontalFlip</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:11:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:11:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:30:16" itemprop="dateModified" datetime="2021-10-27T09:30:16+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001100.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001100.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.1k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsrandomhorizontalflip"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsrandomhorizontalflip"></a> Pytorch.torchvision.transforms.RandomHorizontalFlip</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomHorizontalFlip</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Horizontally flip the given image randomly with a given probability.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        p (float): probability of the image being flipped. Default value is 0.5</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>RandomHorizontalFlip</code> 将以概率 <code>p</code> 对图片进行水平翻转。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">16</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3],</span></span><br><span class="line"><span class="string">         [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">         [ 8,  9, 10, 11],</span></span><br><span class="line"><span class="string">         [12, 13, 14, 15]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomHorizontalFlip(p=<span class="number">0.6</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 3,  2,  1,  0],</span></span><br><span class="line"><span class="string">         [ 7,  6,  5,  4],</span></span><br><span class="line"><span class="string">         [11, 10,  9,  8],</span></span><br><span class="line"><span class="string">         [15, 14, 13, 12]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><nav class="pagination"><a class="extend prev" rel="prev" href="/page/13/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="page-number" href="/page/13/">13</a><span class="page-number current">14</span><a class="page-number" href="/page/15/">15</a><a class="page-number" href="/page/16/">16</a><span class="space">&hellip;</span><a class="page-number" href="/page/60/">60</a><a class="extend next" rel="next" href="/page/15/"><i class="fa fa-angle-right" aria-label="下一页"></i></a></nav></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="智商为零的小白" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">智商为零的小白</p><div class="site-description" itemprop="description">生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">593</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">32</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">92</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zswldxb" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zswldxb" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:1979938740@qq.com" title="E-Mail → mailto:1979938740@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">智商为零的小白</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="站点总字数">2.4m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">35:44 小时</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-divider">|</span> <span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css"><script>NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'rxJydM3QVoypB9apkSU3e9ML-gzGzoHsz',
      appKey     : 'NqXT8ScfaD1udoMiPk3NQ6MF',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});</script><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><canvas class="fireworks" style="position:fixed;left:0;top:0;z-index:1;pointer-events:none"></canvas><script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script><script type="text/javascript" src="/js/src/fireworks.js"></script></body></html>