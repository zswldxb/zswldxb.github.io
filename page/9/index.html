<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.1.1"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon_logo_2.svg"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon_logo_2.svg"><link rel="mask-icon" href="/images/logo_2.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/themes/blue/pace-theme-minimal.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"zswldxb.github.io",root:"/",scheme:"Mist",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:type" content="website"><meta property="og:title" content="智商为零的小白的博客"><meta property="og:url" content="https://zswldxb.github.io/page/9/index.html"><meta property="og:site_name" content="智商为零的小白的博客"><meta property="og:description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:locale" content="zh_CN"><meta property="article:author" content="智商为零的小白"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://zswldxb.github.io/page/9/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!0,isPost:!1,lang:"zh-CN"}</script><title>智商为零的小白的博客</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">智商为零的小白的博客</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content index posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003003700.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003003700.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.ReplicationPad1d</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:37:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:37:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-20 19:30:52" itemprop="dateModified" datetime="2022-02-20T19:30:52+08:00">2022-02-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003003700.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003003700.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.9k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnreplicationpad1d"><a class="markdownIt-Anchor" href="#pytorchtorchnnreplicationpad1d"></a> Pytorch.torch.nn.ReplicationPad1d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReplicationPad1d</span>(<span class="params">_ReplicationPadNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Pads the input tensor using replication of the input boundary.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        padding (int, tuple): the size of the padding. If is `int`, uses the same</span></span><br><span class="line"><span class="string">            padding in all boundaries. If a 2-`tuple`, uses</span></span><br><span class="line"><span class="string">            (:math:`\text&#123;padding\_left&#125;`, :math:`\text&#123;padding\_right&#125;`)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(C, W_&#123;in&#125;)` or :math:`(N, C, W_&#123;in&#125;)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(C, W_&#123;out&#125;)` or :math:`(N, C, W_&#123;out&#125;)`, where</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`W_&#123;out&#125; = W_&#123;in&#125; + \text&#123;padding\_left&#125; + \text&#123;padding\_right&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ReplicationPad1d(2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.arange(8, dtype=torch.float).reshape(1, 2, 4)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input</span></span><br><span class="line"><span class="string">        tensor([[[0., 1., 2., 3.],</span></span><br><span class="line"><span class="string">                 [4., 5., 6., 7.]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[0., 0., 0., 1., 2., 3., 3., 3.],</span></span><br><span class="line"><span class="string">                 [4., 4., 4., 5., 6., 7., 7., 7.]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # using different paddings for different sides</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ReplicationPad1d((3, 1))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[0., 0., 0., 0., 1., 2., 3., 3.],</span></span><br><span class="line"><span class="string">                 [4., 4., 4., 4., 5., 6., 7., 7.]]])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    padding: Tuple[int, int]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, padding: _size_2_t</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(ReplicationPad1d, self).__init__()</span><br><span class="line">        self.padding = _pair(padding)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReplicationPad1d</mtext></mrow><annotation encoding="application/x-tex">\text{ReplicationPad1d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">ReplicationPad1d</span></span></span></span></span> 网络层为一维复制填充层. 输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 经过网络层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReplicationPad1d</mtext></mrow><annotation encoding="application/x-tex">\text{ReplicationPad1d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">ReplicationPad1d</span></span></span></span></span> 后得到的输出为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span>. 一维复制填充层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReplicationPad1d</mtext></mrow><annotation encoding="application/x-tex">\text{ReplicationPad1d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">ReplicationPad1d</span></span></span></span></span> 要求其输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 为一维或一维以上张量, 且其最后一个维度含义为输入特征维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>in_features</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Input}\in\R^{\cdots\times\text{in\_features}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_features</span></span></span></span></span></span></span></span></span></span></span></span></span>, 其输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span> 维度个数与输入相同, 但形状不相同, 其最后一个维度含义输出特征维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>out_features</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{\cdots\times\text{out\_features}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_features</span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h2 id="一维复制填充层的相关参数"><a class="markdownIt-Anchor" href="#一维复制填充层的相关参数"></a> 一维复制填充层的相关参数</h2><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReplicationPad1d</mtext></mrow><annotation encoding="application/x-tex">\text{ReplicationPad1d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">ReplicationPad1d</span></span></span></span></span> 的 <code>padding</code> 参数将指定其对输入特征维度填充的长度, <code>padding</code> 其可以是整数, 也可以是一个拥有两个整数的元组. 当 <code>padding</code> 为整数时, 其将对输入特征维度的左侧和右侧填充 <code>padding</code> 个数值, 具体数值为边界上的值. 若其为拥有两个整数的元组, 则其将对输入特征维度的左侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[0]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span></span></span></span>, 右侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span></span></span></span> 个数值, 具体数值为边界上的值.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, padding)</span>:</span>
    <span class="hljs-keyword">assert</span> len(input.shape) &gt;= <span class="hljs-number">1</span>, <span class="hljs-string">'input shape error'</span>
    <span class="hljs-keyword">if</span> isinstance(padding, int):
        padding = tuple(repeat(padding, <span class="hljs-number">2</span>))
    <span class="hljs-keyword">assert</span> len(padding) == <span class="hljs-number">2</span>, <span class="hljs-string">'num of padding error'</span>

    layer = nn.ReplicationPad1d(padding)
    y = layer(torch.tensor(input, dtype=torch.float64)).numpy()
    print(y)
    y_hat = np.concatenate((np.repeat(input[..., <span class="hljs-number">0</span>:<span class="hljs-number">1</span>], padding[<span class="hljs-number">0</span>], axis=<span class="hljs-number">-1</span>), input, np.repeat(input[..., <span class="hljs-number">-1</span>:], padding[<span class="hljs-number">1</span>], axis=<span class="hljs-number">-1</span>)), axis=<span class="hljs-number">-1</span>)

    print(<span class="hljs-string">f'output error: <span class="hljs-subst">&#123;np.mean(np.abs((y-y_hat).flatten()))&#125;</span>'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = np.arange(<span class="hljs-number">16</span>).reshape(<span class="hljs-number">2</span>, <span class="hljs-number">8</span>)
    padding = <span class="hljs-number">2</span>
    solve(input, padding)

    input = np.arange(<span class="hljs-number">16</span>).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>)
    padding = (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
    solve(input, padding)
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003003600.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003003600.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.ReflectionPad3d</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:36:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:36:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-20 19:31:46" itemprop="dateModified" datetime="2022-02-20T19:31:46+08:00">2022-02-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003003600.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003003600.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>4.3k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>4 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnreflectionpad3d"><a class="markdownIt-Anchor" href="#pytorchtorchnnreflectionpad3d"></a> Pytorch.torch.nn.ReflectionPad3d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReflectionPad3d</span>(<span class="params">_ReflectionPadNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Pads the input tensor using the reflection of the input boundary.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        padding (int, tuple): the size of the padding. If is `int`, uses the same</span></span><br><span class="line"><span class="string">            padding in all boundaries. If a 6-`tuple`, uses</span></span><br><span class="line"><span class="string">            (:math:`\text&#123;padding\_left&#125;`, :math:`\text&#123;padding\_right&#125;`,</span></span><br><span class="line"><span class="string">            :math:`\text&#123;padding\_top&#125;`, :math:`\text&#123;padding\_bottom&#125;`,</span></span><br><span class="line"><span class="string">            :math:`\text&#123;padding\_front&#125;`, :math:`\text&#123;padding\_back&#125;`)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C, D_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)` or :math:`(C, D_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C, D_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out&#125;)` or :math:`(C, D_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out&#125;)`,</span></span><br><span class="line"><span class="string">          where</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`D_&#123;out&#125; = D_&#123;in&#125; + \text&#123;padding\_front&#125; + \text&#123;padding\_back&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`H_&#123;out&#125; = H_&#123;in&#125; + \text&#123;padding\_top&#125; + \text&#123;padding\_bottom&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`W_&#123;out&#125; = W_&#123;in&#125; + \text&#123;padding\_left&#125; + \text&#123;padding\_right&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ReflectionPad3d(1)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.arange(8, dtype=torch.float).reshape(1, 1, 2, 2, 2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[[[7., 6., 7., 6.],</span></span><br><span class="line"><span class="string">                   [5., 4., 5., 4.],</span></span><br><span class="line"><span class="string">                   [7., 6., 7., 6.],</span></span><br><span class="line"><span class="string">                   [5., 4., 5., 4.]],</span></span><br><span class="line"><span class="string">                  [[3., 2., 3., 2.],</span></span><br><span class="line"><span class="string">                   [1., 0., 1., 0.],</span></span><br><span class="line"><span class="string">                   [3., 2., 3., 2.],</span></span><br><span class="line"><span class="string">                   [1., 0., 1., 0.]],</span></span><br><span class="line"><span class="string">                  [[7., 6., 7., 6.],</span></span><br><span class="line"><span class="string">                   [5., 4., 5., 4.],</span></span><br><span class="line"><span class="string">                   [7., 6., 7., 6.],</span></span><br><span class="line"><span class="string">                   [5., 4., 5., 4.]],</span></span><br><span class="line"><span class="string">                  [[3., 2., 3., 2.],</span></span><br><span class="line"><span class="string">                   [1., 0., 1., 0.],</span></span><br><span class="line"><span class="string">                   [3., 2., 3., 2.],</span></span><br><span class="line"><span class="string">                   [1., 0., 1., 0.]]]]])</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    padding: Tuple[int, int, int, int, int, int]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, padding: _size_6_t</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(ReflectionPad3d, self).__init__()</span><br><span class="line">        self.padding = _ntuple(<span class="number">6</span>)(padding)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReflectionPad3d</mtext></mrow><annotation encoding="application/x-tex">\text{ReflectionPad3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ReflectionPad3d</span></span></span></span></span> 网络层为三维反射填充层. 输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 经过网络层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReflectionPad3d</mtext></mrow><annotation encoding="application/x-tex">\text{ReflectionPad3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ReflectionPad3d</span></span></span></span></span> 后得到的输出为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span>. 三维反射填充层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReflectionPad3d</mtext></mrow><annotation encoding="application/x-tex">\text{ReflectionPad3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ReflectionPad3d</span></span></span></span></span> 要求其输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 为三维或三维以上张量, 且其最后两个维度含义为输入特征深度维度, 输入特征高度维度和输入特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>in_depth</mtext><mo>×</mo><mtext>in_height</mtext><mo>×</mo><mtext>in_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Input}\in\R^{\cdots\times\text{in\_depth}\times\text{in\_height}\times\text{in\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_depth</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_width</span></span></span></span></span></span></span></span></span></span></span></span></span>, 其输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span> 维度个数与输入相同, 但形状不相同, 其最后两个维度含义输出特征深度维度, 输出特征高度维度和输出特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>out_depth</mtext><mo>×</mo><mtext>out_height</mtext><mo>×</mo><mtext>out_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{\cdots\times\text{out\_depth}\times\text{out\_height}\times\text{out\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_depth</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_width</span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h2 id="三维反射填充层的相关参数"><a class="markdownIt-Anchor" href="#三维反射填充层的相关参数"></a> 三维反射填充层的相关参数</h2><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReflectionPad3d</mtext></mrow><annotation encoding="application/x-tex">\text{ReflectionPad3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ReflectionPad3d</span></span></span></span></span> 的 <code>padding</code> 参数将指定其对输入特征维度填充的长度, <code>value</code> 参数指定填充的数值, <code>padding</code> 其可以是整数, 也可以是一个拥有六个整数的元组. 当 <code>padding</code> 为整数时, 其将对输入特征深度维度前侧和后侧, 输入特征高度维度上侧和下侧, 输入特征维度的左侧和右侧填充 <code>padding</code> 个数值, 具体数值将通过镜面变换得到. 若其为拥有六个整数的元组, 则其将对输入特征深度维度的前侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>4</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[4]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">4</span><span class="mclose">]</span></span></span></span>, 后侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>5</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[5]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">5</span><span class="mclose">]</span></span></span></span>, 输入特征高度维度的上侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>2</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">2</span><span class="mclose">]</span></span></span></span>, 下侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>3</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[3]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">3</span><span class="mclose">]</span></span></span></span>, 输入特征宽度维度的左侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[0]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span></span></span></span>, 右侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span></span></span></span> 个数值, 具体数值将通过镜面变换得到.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, padding)</span>:</span>
    <span class="hljs-keyword">if</span> isinstance(padding, int):
        padding = tuple(repeat(padding, <span class="hljs-number">6</span>))
    <span class="hljs-keyword">assert</span> len(padding) == <span class="hljs-number">6</span>, <span class="hljs-string">'num of padding error'</span>

    layer = nn.ReflectionPad3d(padding)
    y = layer(torch.tensor(input, dtype=torch.float64)).numpy()

    input_shape = input.shape
    
    <span class="hljs-comment"># for d_D</span>
    d_d = input_shape[<span class="hljs-number">-3</span>]
    in_ref = input[..., ::<span class="hljs-number">-1</span>, :, :]
    input_whole = np.concatenate((in_ref[..., :<span class="hljs-number">-1</span>, :, :], input, in_ref[..., <span class="hljs-number">1</span>:, :, :]), axis=<span class="hljs-number">-3</span>)
    y_hat = input_whole[..., d_d - padding[<span class="hljs-number">4</span>] - <span class="hljs-number">1</span>:<span class="hljs-number">2</span> * d_d + padding[<span class="hljs-number">5</span>] - <span class="hljs-number">1</span>, :, :]
    <span class="hljs-comment"># for d_H</span>
    d_h = input_shape[<span class="hljs-number">-2</span>]
    in_ref = y_hat[..., ::<span class="hljs-number">-1</span>, :]
    input_whole = np.concatenate((in_ref[..., :<span class="hljs-number">-1</span>, :], y_hat, in_ref[..., <span class="hljs-number">1</span>:, :]), axis=<span class="hljs-number">-2</span>)
    y_hat = input_whole[..., d_h - padding[<span class="hljs-number">2</span>] - <span class="hljs-number">1</span>:<span class="hljs-number">2</span> * d_h + padding[<span class="hljs-number">3</span>] - <span class="hljs-number">1</span>, :]
    <span class="hljs-comment"># for d_W</span>
    d_w = input_shape[<span class="hljs-number">-1</span>]
    in_ref = y_hat[..., ::<span class="hljs-number">-1</span>]
    input_whole = np.concatenate((in_ref[..., :<span class="hljs-number">-1</span>], y_hat, in_ref[..., <span class="hljs-number">1</span>:]), axis=<span class="hljs-number">-1</span>)
    y_hat = input_whole[..., d_w - padding[<span class="hljs-number">0</span>] - <span class="hljs-number">1</span>:<span class="hljs-number">2</span> * d_w + padding[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span>]

    print(y_hat)
    print(<span class="hljs-string">f'output error: <span class="hljs-subst">&#123;np.mean(np.abs((y-y_hat).flatten()))&#125;</span>'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = np.arange(<span class="hljs-number">128</span>).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>)
    print(input)
    padding = <span class="hljs-number">2</span>
    solve(input, padding)

    input = np.arange(<span class="hljs-number">128</span>).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>)
    padding = (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)
    solve(input, padding)
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003003400.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003003400.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.ReflectionPad1d</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:34:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:34:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-20 18:42:08" itemprop="dateModified" datetime="2022-02-20T18:42:08+08:00">2022-02-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003003400.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003003400.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnreflectionpad1d"><a class="markdownIt-Anchor" href="#pytorchtorchnnreflectionpad1d"></a> Pytorch.torch.nn.ReflectionPad1d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReflectionPad1d</span>(<span class="params">_ReflectionPadNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Pads the input tensor using the reflection of the input boundary.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        padding (int, tuple): the size of the padding. If is `int`, uses the same</span></span><br><span class="line"><span class="string">            padding in all boundaries. If a 2-`tuple`, uses</span></span><br><span class="line"><span class="string">            (:math:`\text&#123;padding\_left&#125;`, :math:`\text&#123;padding\_right&#125;`)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(C, W_&#123;in&#125;)` or :math:`(N, C, W_&#123;in&#125;)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(C, W_&#123;out&#125;)` or :math:`(N, C, W_&#123;out&#125;)`, where</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`W_&#123;out&#125; = W_&#123;in&#125; + \text&#123;padding\_left&#125; + \text&#123;padding\_right&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ReflectionPad1d(2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.arange(8, dtype=torch.float).reshape(1, 2, 4)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input</span></span><br><span class="line"><span class="string">        tensor([[[0., 1., 2., 3.],</span></span><br><span class="line"><span class="string">                 [4., 5., 6., 7.]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[2., 1., 0., 1., 2., 3., 2., 1.],</span></span><br><span class="line"><span class="string">                 [6., 5., 4., 5., 6., 7., 6., 5.]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # using different paddings for different sides</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ReflectionPad1d((3, 1))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[3., 2., 1., 0., 1., 2., 3., 2.],</span></span><br><span class="line"><span class="string">                 [7., 6., 5., 4., 5., 6., 7., 6.]]])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    padding: Tuple[int, int]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, padding: _size_2_t</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(ReflectionPad1d, self).__init__()</span><br><span class="line">        self.padding = _pair(padding)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReflectionPad1d</mtext></mrow><annotation encoding="application/x-tex">\text{ReflectionPad1d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ReflectionPad1d</span></span></span></span></span> 网络层为一维反射填充层. 输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 经过网络层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReflectionPad1d</mtext></mrow><annotation encoding="application/x-tex">\text{ReflectionPad1d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ReflectionPad1d</span></span></span></span></span> 后得到的输出为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span>. 一维反射填充层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReflectionPad1d</mtext></mrow><annotation encoding="application/x-tex">\text{ReflectionPad1d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ReflectionPad1d</span></span></span></span></span> 要求其输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 为一维或一维以上张量, 且其最后一个维度含义为输入特征维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>in_features</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Input}\in\R^{\cdots\times\text{in\_features}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_features</span></span></span></span></span></span></span></span></span></span></span></span></span>, 其输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span> 维度个数与输入相同, 但形状不相同, 其最后一个维度含义输出特征维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>out_features</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{\cdots\times\text{out\_features}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_features</span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h2 id="一维反射填充层的相关参数"><a class="markdownIt-Anchor" href="#一维反射填充层的相关参数"></a> 一维反射填充层的相关参数</h2><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReflectionPad1d</mtext></mrow><annotation encoding="application/x-tex">\text{ReflectionPad1d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ReflectionPad1d</span></span></span></span></span> 的 <code>padding</code> 参数将指定其对输入特征维度填充的长度, <code>padding</code> 其可以是整数, 也可以是一个拥有两个整数的元组. 当 <code>padding</code> 为整数时, 其将对输入特征维度的左侧和右侧填充 <code>padding</code> 个数值, 具体数值将通过镜面变换得到. 若其为拥有两个整数的元组, 则其将对输入特征维度的左侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[0]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span></span></span></span>, 右侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span></span></span></span> 个数值, 具体数值将通过镜面变换得到.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, padding)</span>:</span>
    <span class="hljs-keyword">if</span> isinstance(padding, int):
        padding = tuple(repeat(padding, <span class="hljs-number">2</span>))
    <span class="hljs-keyword">assert</span> len(padding) == <span class="hljs-number">2</span>, <span class="hljs-string">'num of padding error'</span>

    layer = nn.ReflectionPad1d(padding)
    y = layer(torch.tensor(input, dtype=torch.float64)).numpy()

    d_f = input.shape[<span class="hljs-number">-1</span>]
    in_ref = input[..., ::<span class="hljs-number">-1</span>]
    input_whole = np.concatenate((in_ref[..., :<span class="hljs-number">-1</span>], input, in_ref[..., <span class="hljs-number">1</span>:]), axis=<span class="hljs-number">-1</span>)
    y_hat = input_whole[..., d_f - padding[<span class="hljs-number">0</span>] - <span class="hljs-number">1</span>:<span class="hljs-number">2</span> * d_f + padding[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span>]
    print(<span class="hljs-string">f'output error: <span class="hljs-subst">&#123;np.mean(np.abs((y-y_hat).flatten()))&#125;</span>'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = np.arange(<span class="hljs-number">16</span>).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>)
    print(input)
    padding = <span class="hljs-number">2</span>
    solve(input, padding)

    input = np.arange(<span class="hljs-number">16</span>).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">8</span>)
    print(input)
    padding = (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
    solve(input, padding)
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003003300.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003003300.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.ConstantPad3d</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:33:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:33:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-20 16:37:26" itemprop="dateModified" datetime="2022-02-20T16:37:26+08:00">2022-02-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003003300.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003003300.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.9k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>4 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnconstantpad3d"><a class="markdownIt-Anchor" href="#pytorchtorchnnconstantpad3d"></a> Pytorch.torch.nn.ConstantPad3d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConstantPad3d</span>(<span class="params">_ConstantPadNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Pads the input tensor boundaries with a constant value.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        padding (int, tuple): the size of the padding. If is `int`, uses the same</span></span><br><span class="line"><span class="string">            padding in all boundaries. If a 6-`tuple`, uses</span></span><br><span class="line"><span class="string">            (:math:`\text&#123;padding\_left&#125;`, :math:`\text&#123;padding\_right&#125;`,</span></span><br><span class="line"><span class="string">            :math:`\text&#123;padding\_top&#125;`, :math:`\text&#123;padding\_bottom&#125;`,</span></span><br><span class="line"><span class="string">            :math:`\text&#123;padding\_front&#125;`, :math:`\text&#123;padding\_back&#125;`)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C, D_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)` or :math:`(C, D_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C, D_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out&#125;)` or</span></span><br><span class="line"><span class="string">          :math:`(C, D_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out&#125;)`, where</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`D_&#123;out&#125; = D_&#123;in&#125; + \text&#123;padding\_front&#125; + \text&#123;padding\_back&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`H_&#123;out&#125; = H_&#123;in&#125; + \text&#123;padding\_top&#125; + \text&#123;padding\_bottom&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`W_&#123;out&#125; = W_&#123;in&#125; + \text&#123;padding\_left&#125; + \text&#123;padding\_right&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ConstantPad3d(3, 3.5)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(16, 3, 10, 20, 30)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # using different paddings for different sides</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ConstantPad3d((3, 3, 6, 6, 0, 1), 3.5)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    padding: Tuple[int, int, int, int, int, int]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, padding: _size_6_t, value: float</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(ConstantPad3d, self).__init__(value)</span><br><span class="line">        self.padding = _ntuple(<span class="number">6</span>)(padding)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ConstantPad3d</mtext></mrow><annotation encoding="application/x-tex">\text{ConstantPad3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ConstantPad3d</span></span></span></span></span> 网络层为三维常数填充层. 输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 经过网络层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ConstantPad3d</mtext></mrow><annotation encoding="application/x-tex">\text{ConstantPad3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ConstantPad3d</span></span></span></span></span> 后得到的输出为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span>. 三维常数填充层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ConstantPad3d</mtext></mrow><annotation encoding="application/x-tex">\text{ConstantPad3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ConstantPad3d</span></span></span></span></span> 要求其输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 为三维或三维以上张量, 且其最后两个维度含义为输入特征深度维度, 输入特征高度维度和输入特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>in_depth</mtext><mo>×</mo><mtext>in_height</mtext><mo>×</mo><mtext>in_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Input}\in\R^{\cdots\times\text{in\_depth}\times\text{in\_height}\times\text{in\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_depth</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_width</span></span></span></span></span></span></span></span></span></span></span></span></span>, 其输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span> 维度个数与输入相同, 但形状不相同, 其最后两个维度含义输出特征深度维度, 输出特征高度维度和输出特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>out_depth</mtext><mo>×</mo><mtext>out_height</mtext><mo>×</mo><mtext>out_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{\cdots\times\text{out\_depth}\times\text{out\_height}\times\text{out\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_depth</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_width</span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h2 id="三维常数填充层的相关参数"><a class="markdownIt-Anchor" href="#三维常数填充层的相关参数"></a> 三维常数填充层的相关参数</h2><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ConstantPad3d</mtext></mrow><annotation encoding="application/x-tex">\text{ConstantPad3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ConstantPad3d</span></span></span></span></span> 的 <code>padding</code> 参数将指定其对输入特征维度填充的长度, <code>value</code> 参数指定填充的数值, <code>padding</code> 其可以是整数, 也可以是一个拥有六个整数的元组. 当 <code>padding</code> 为整数时, 其将对输入特征深度维度前侧和后侧, 输入特征高度维度上侧和下侧, 输入特征维度的左侧和右侧填充 <code>padding</code> 个 <code>value</code>. 若其为拥有六个整数的元组, 则其将对输入特征深度维度的前侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>4</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[4]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">4</span><span class="mclose">]</span></span></span></span>, 后侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>5</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[5]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">5</span><span class="mclose">]</span></span></span></span>, 输入特征高度维度的上侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>2</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">2</span><span class="mclose">]</span></span></span></span>, 下侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>3</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[3]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">3</span><span class="mclose">]</span></span></span></span>, 输入特征宽度维度的左侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[0]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span></span></span></span>, 右侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span></span></span></span> 个 <code>value</code>.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, padding, value)</span>:</span>
    <span class="hljs-keyword">assert</span> len(input.shape) &gt;= <span class="hljs-number">3</span>, <span class="hljs-string">'input shape error'</span>
    <span class="hljs-keyword">if</span> isinstance(padding, int):
        padding = tuple(repeat(padding, <span class="hljs-number">6</span>))
    <span class="hljs-keyword">assert</span> len(padding) == <span class="hljs-number">6</span>, <span class="hljs-string">'num of padding error'</span>

    layer = nn.ConstantPad3d(padding, value)
    y = layer(input).numpy()

    input_shape = input.shape
    pd_shape = [
        input_shape[<span class="hljs-number">-3</span>] + padding[<span class="hljs-number">4</span>] + padding[<span class="hljs-number">5</span>],
        input_shape[<span class="hljs-number">-2</span>] + padding[<span class="hljs-number">2</span>] + padding[<span class="hljs-number">3</span>],
        input_shape[<span class="hljs-number">-1</span>] + padding[<span class="hljs-number">0</span>] + padding[<span class="hljs-number">1</span>]
    ]
    y_hat = np.full((*input_shape[:<span class="hljs-number">-3</span>], *pd_shape), value)
    y_hat[..., padding[<span class="hljs-number">4</span>]:padding[<span class="hljs-number">4</span>] + input_shape[<span class="hljs-number">-3</span>],
          padding[<span class="hljs-number">2</span>]:padding[<span class="hljs-number">2</span>] + input_shape[<span class="hljs-number">-2</span>],
          padding[<span class="hljs-number">0</span>]:padding[<span class="hljs-number">0</span>] + input_shape[<span class="hljs-number">-1</span>]] = input

    print(<span class="hljs-string">f'output error: <span class="hljs-subst">&#123;np.mean(np.abs((y-y_hat).flatten()))&#125;</span>'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)
    padding = <span class="hljs-number">2</span>
    value = <span class="hljs-number">2.5</span>
    solve(input, padding, value)

    input = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)
    padding = (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>)
    value = <span class="hljs-number">2.5</span>
    solve(input, padding, value)
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003003200.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003003200.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.ConstantPad2d</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:32:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:32:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-20 16:37:22" itemprop="dateModified" datetime="2022-02-20T16:37:22+08:00">2022-02-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003003200.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003003200.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.9k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>4 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnconstantpad2d"><a class="markdownIt-Anchor" href="#pytorchtorchnnconstantpad2d"></a> Pytorch.torch.nn.ConstantPad2d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConstantPad2d</span>(<span class="params">_ConstantPadNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Pads the input tensor boundaries with a constant value.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        padding (int, tuple): the size of the padding. If is `int`, uses the same</span></span><br><span class="line"><span class="string">            padding in all boundaries. If a 4-`tuple`, uses (:math:`\text&#123;padding\_left&#125;`,</span></span><br><span class="line"><span class="string">            :math:`\text&#123;padding\_right&#125;`, :math:`\text&#123;padding\_top&#125;`, :math:`\text&#123;padding\_bottom&#125;`)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C, H_&#123;in&#125;, W_&#123;in&#125;)` or :math:`(C, H_&#123;in&#125;, W_&#123;in&#125;)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C, H_&#123;out&#125;, W_&#123;out&#125;)` or :math:`(C, H_&#123;out&#125;, W_&#123;out&#125;)`, where</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`H_&#123;out&#125; = H_&#123;in&#125; + \text&#123;padding\_top&#125; + \text&#123;padding\_bottom&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`W_&#123;out&#125; = W_&#123;in&#125; + \text&#123;padding\_left&#125; + \text&#123;padding\_right&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ConstantPad2d(2, 3.5)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(1, 2, 2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input</span></span><br><span class="line"><span class="string">        tensor([[[ 1.6585,  0.4320],</span></span><br><span class="line"><span class="string">                 [-0.8701, -0.4649]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],</span></span><br><span class="line"><span class="string">                 [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],</span></span><br><span class="line"><span class="string">                 [ 3.5000,  3.5000,  1.6585,  0.4320,  3.5000,  3.5000],</span></span><br><span class="line"><span class="string">                 [ 3.5000,  3.5000, -0.8701, -0.4649,  3.5000,  3.5000],</span></span><br><span class="line"><span class="string">                 [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],</span></span><br><span class="line"><span class="string">                 [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # using different paddings for different sides</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ConstantPad2d((3, 0, 2, 1), 3.5)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],</span></span><br><span class="line"><span class="string">                 [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],</span></span><br><span class="line"><span class="string">                 [ 3.5000,  3.5000,  3.5000,  1.6585,  0.4320],</span></span><br><span class="line"><span class="string">                 [ 3.5000,  3.5000,  3.5000, -0.8701, -0.4649],</span></span><br><span class="line"><span class="string">                 [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000]]])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;padding&#x27;</span>, <span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">    padding: Tuple[int, int, int, int]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, padding: _size_4_t, value: float</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(ConstantPad2d, self).__init__(value)</span><br><span class="line">        self.padding = _quadruple(padding)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ConstantPad2d</mtext></mrow><annotation encoding="application/x-tex">\text{ConstantPad2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ConstantPad2d</span></span></span></span></span> 网络层为二维常数填充层. 输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 经过网络层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ConstantPad2d</mtext></mrow><annotation encoding="application/x-tex">\text{ConstantPad2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ConstantPad2d</span></span></span></span></span> 后得到的输出为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span>. 二维常数填充层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ConstantPad2d</mtext></mrow><annotation encoding="application/x-tex">\text{ConstantPad2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ConstantPad2d</span></span></span></span></span> 要求其输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 为二维或二维以上张量, 且其最后两个维度含义为输入特征高度维度和输入特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>in_height</mtext><mo>×</mo><mtext>in_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Input}\in\R^{\cdots\times\text{in\_height}\times\text{in\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_width</span></span></span></span></span></span></span></span></span></span></span></span></span>, 其输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span> 维度个数与输入相同, 但形状不相同, 其最后两个维度含义输出特征高度维度和输出特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>out_height</mtext><mo>×</mo><mtext>out_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{\cdots\times\text{out\_height}\times\text{out\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_width</span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h2 id="二维常数填充层的相关参数"><a class="markdownIt-Anchor" href="#二维常数填充层的相关参数"></a> 二维常数填充层的相关参数</h2><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ConstantPad2d</mtext></mrow><annotation encoding="application/x-tex">\text{ConstantPad2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ConstantPad2d</span></span></span></span></span> 的 <code>padding</code> 参数将指定其对输入特征维度填充的长度, <code>value</code> 参数指定填充的数值, <code>padding</code> 其可以是整数, 也可以是一个拥有四个整数的元组. 当 <code>padding</code> 为整数时, 其将对输入特征高度维度上侧和下侧, 输入特征维度的左侧和右侧填充 <code>padding</code> 个 <code>value</code>. 若其为拥有四个整数的元组, 则其将对输入特征高度维度的上侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>2</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">2</span><span class="mclose">]</span></span></span></span>, 下侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>3</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[3]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">3</span><span class="mclose">]</span></span></span></span>, 输入特征宽度维度的左侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[0]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span></span></span></span>, 右侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span></span></span></span> 个 <code>value</code>.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, padding, value)</span>:</span>
    <span class="hljs-keyword">assert</span> len(input.shape) &gt;= <span class="hljs-number">2</span>, <span class="hljs-string">'input shape error'</span>
    <span class="hljs-keyword">if</span> isinstance(padding, int):
        padding = tuple(repeat(padding, <span class="hljs-number">4</span>))
    <span class="hljs-keyword">assert</span> len(padding) == <span class="hljs-number">4</span>, <span class="hljs-string">'num of padding error'</span>

    layer = nn.ConstantPad2d(padding, value)
    y = layer(input).numpy()

    input_shape = input.shape
    pd_shape = [
        input_shape[<span class="hljs-number">-2</span>] + padding[<span class="hljs-number">2</span>] + padding[<span class="hljs-number">3</span>],
        input_shape[<span class="hljs-number">-1</span>] + padding[<span class="hljs-number">0</span>] + padding[<span class="hljs-number">1</span>]
    ]
    y_hat = np.full((*input_shape[:<span class="hljs-number">-2</span>], *pd_shape), value)
    y_hat[..., padding[<span class="hljs-number">2</span>]:padding[<span class="hljs-number">2</span>] + input_shape[<span class="hljs-number">-2</span>],
          padding[<span class="hljs-number">0</span>]:padding[<span class="hljs-number">0</span>] + input_shape[<span class="hljs-number">-1</span>]] = input

    print(<span class="hljs-string">f'output error: <span class="hljs-subst">&#123;np.mean(np.abs((y-y_hat).flatten()))&#125;</span>'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)
    padding = <span class="hljs-number">2</span>
    value = <span class="hljs-number">2.5</span>
    solve(input, padding, value)

    input = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)
    padding = (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)
    value = <span class="hljs-number">2.5</span>
    solve(input, padding, value)
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003003100.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003003100.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.ConstantPad1d</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:31:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:31:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-20 16:38:44" itemprop="dateModified" datetime="2022-02-20T16:38:44+08:00">2022-02-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003003100.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003003100.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.4k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnconstantpad1d"><a class="markdownIt-Anchor" href="#pytorchtorchnnconstantpad1d"></a> Pytorch.torch.nn.ConstantPad1d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConstantPad1d</span>(<span class="params">_ConstantPadNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Pads the input tensor boundaries with a constant value.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        padding (int, tuple): the size of the padding. If is `int`, uses the same</span></span><br><span class="line"><span class="string">            padding in both boundaries. If a 2-`tuple`, uses</span></span><br><span class="line"><span class="string">            (:math:`\text&#123;padding\_left&#125;`, :math:`\text&#123;padding\_right&#125;`)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(C, W_&#123;in&#125;)` or :math:`(N, C, W_&#123;in&#125;)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(C, W_&#123;out&#125;)` or :math:`(N, C, W_&#123;out&#125;)`, where</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`W_&#123;out&#125; = W_&#123;in&#125; + \text&#123;padding\_left&#125; + \text&#123;padding\_right&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ConstantPad1d(2, 3.5)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(1, 2, 4)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input</span></span><br><span class="line"><span class="string">        tensor([[[-1.0491, -0.7152, -0.0749,  0.8530],</span></span><br><span class="line"><span class="string">                 [-1.3287,  1.8966,  0.1466, -0.2771]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[ 3.5000,  3.5000, -1.0491, -0.7152, -0.0749,  0.8530,  3.5000,</span></span><br><span class="line"><span class="string">                   3.5000],</span></span><br><span class="line"><span class="string">                 [ 3.5000,  3.5000, -1.3287,  1.8966,  0.1466, -0.2771,  3.5000,</span></span><br><span class="line"><span class="string">                   3.5000]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ConstantPad1d(2, 3.5)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(1, 2, 3)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input</span></span><br><span class="line"><span class="string">        tensor([[[ 1.6616,  1.4523, -1.1255],</span></span><br><span class="line"><span class="string">                 [-3.6372,  0.1182, -1.8652]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[ 3.5000,  3.5000,  1.6616,  1.4523, -1.1255,  3.5000,  3.5000],</span></span><br><span class="line"><span class="string">                 [ 3.5000,  3.5000, -3.6372,  0.1182, -1.8652,  3.5000,  3.5000]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # using different paddings for different sides</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ConstantPad1d((3, 1), 3.5)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[ 3.5000,  3.5000,  3.5000,  1.6616,  1.4523, -1.1255,  3.5000],</span></span><br><span class="line"><span class="string">                 [ 3.5000,  3.5000,  3.5000, -3.6372,  0.1182, -1.8652,  3.5000]]])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    padding: Tuple[int, int]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, padding: _size_2_t, value: float</span>):</span></span><br><span class="line">        super(ConstantPad1d, self).__init__(value)</span><br><span class="line">        self.padding = _pair(padding)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ConstantPad1d</mtext></mrow><annotation encoding="application/x-tex">\text{ConstantPad1d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ConstantPad1d</span></span></span></span></span> 网络层为一维常数填充层. 输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 经过网络层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ConstantPad1d</mtext></mrow><annotation encoding="application/x-tex">\text{ConstantPad1d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ConstantPad1d</span></span></span></span></span> 后得到的输出为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span>. 一维常数填充层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ConstantPad1d</mtext></mrow><annotation encoding="application/x-tex">\text{ConstantPad1d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ConstantPad1d</span></span></span></span></span> 要求其输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 为一维或一维以上张量, 且其最后一个维度含义为输入特征维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>in_features</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Input}\in\R^{\cdots\times\text{in\_features}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_features</span></span></span></span></span></span></span></span></span></span></span></span></span>, 其输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span> 维度个数与输入相同, 但形状不相同, 其最后一个维度含义输出特征维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>out_features</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{\cdots\times\text{out\_features}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_features</span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h2 id="一维常数填充层的相关参数"><a class="markdownIt-Anchor" href="#一维常数填充层的相关参数"></a> 一维常数填充层的相关参数</h2><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ConstantPad1d</mtext></mrow><annotation encoding="application/x-tex">\text{ConstantPad1d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ConstantPad1d</span></span></span></span></span> 的 <code>padding</code> 参数将指定其对输入特征维度填充的长度, <code>value</code> 参数指定填充的数值, <code>padding</code> 其可以是整数, 也可以是一个拥有两个整数的元组. 当 <code>padding</code> 为整数时, 其将对输入特征维度的左侧和右侧填充 <code>padding</code> 个 <code>value</code>. 若其为拥有两个整数的元组, 则其将对输入特征维度的左侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[0]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span></span></span></span>, 右侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span></span></span></span> 个 <code>value</code>.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, padding, value)</span>:</span>
    <span class="hljs-keyword">assert</span> len(input.shape) &gt;= <span class="hljs-number">1</span>, <span class="hljs-string">'input shape error'</span>
    <span class="hljs-keyword">if</span> isinstance(padding, int):
        padding = tuple(repeat(padding, <span class="hljs-number">2</span>))
    <span class="hljs-keyword">assert</span> len(padding) == <span class="hljs-number">2</span>, <span class="hljs-string">'num of padding error'</span>

    layer = nn.ConstantPad1d(padding, value)
    y = layer(input).numpy()

    input_shape = input.shape
    pd_shape = [input_shape[<span class="hljs-number">-1</span>] + padding[<span class="hljs-number">0</span>] + padding[<span class="hljs-number">1</span>], ]
    y_hat = np.full((*input_shape[:<span class="hljs-number">-1</span>], *pd_shape), value)
    y_hat[..., padding[<span class="hljs-number">0</span>]:padding[<span class="hljs-number">0</span>] + input_shape[<span class="hljs-number">-1</span>]] = input

    print(<span class="hljs-string">f'output error: <span class="hljs-subst">&#123;np.mean(np.abs((y-y_hat).flatten()))&#125;</span>'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = torch.randn(<span class="hljs-number">1</span>)
    padding = <span class="hljs-number">2</span>
    value = <span class="hljs-number">2.5</span>
    solve(input, padding, value)

    input = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)
    padding = (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
    value = <span class="hljs-number">2.5</span>
    solve(input, padding, value)
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003003000.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003003000.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.ZeroPad2d</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:30:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:30:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-20 15:50:26" itemprop="dateModified" datetime="2022-02-20T15:50:26+08:00">2022-02-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003003000.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003003000.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.8k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnzeropad2d"><a class="markdownIt-Anchor" href="#pytorchtorchnnzeropad2d"></a> Pytorch.torch.nn.ZeroPad2d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZeroPad2d</span>(<span class="params">ConstantPad2d</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Pads the input tensor boundaries with zero.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        padding (int, tuple): the size of the padding. If is `int`, uses the same</span></span><br><span class="line"><span class="string">            padding in all boundaries. If a 4-`tuple`, uses (:math:`\text&#123;padding\_left&#125;`,</span></span><br><span class="line"><span class="string">            :math:`\text&#123;padding\_right&#125;`, :math:`\text&#123;padding\_top&#125;`, :math:`\text&#123;padding\_bottom&#125;`)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C, H_&#123;in&#125;, W_&#123;in&#125;)` or :math:`(C, H_&#123;in&#125;, W_&#123;in&#125;)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C, H_&#123;out&#125;, W_&#123;out&#125;)` or :math:`(C, H_&#123;out&#125;, W_&#123;out&#125;)`, where</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`H_&#123;out&#125; = H_&#123;in&#125; + \text&#123;padding\_top&#125; + \text&#123;padding\_bottom&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`W_&#123;out&#125; = W_&#123;in&#125; + \text&#123;padding\_left&#125; + \text&#123;padding\_right&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ZeroPad2d(2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(1, 1, 3, 3)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input</span></span><br><span class="line"><span class="string">        tensor([[[[-0.1678, -0.4418,  1.9466],</span></span><br><span class="line"><span class="string">                  [ 0.9604, -0.4219, -0.5241],</span></span><br><span class="line"><span class="string">                  [-0.9162, -0.5436, -0.6446]]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],</span></span><br><span class="line"><span class="string">                  [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],</span></span><br><span class="line"><span class="string">                  [ 0.0000,  0.0000, -0.1678, -0.4418,  1.9466,  0.0000,  0.0000],</span></span><br><span class="line"><span class="string">                  [ 0.0000,  0.0000,  0.9604, -0.4219, -0.5241,  0.0000,  0.0000],</span></span><br><span class="line"><span class="string">                  [ 0.0000,  0.0000, -0.9162, -0.5436, -0.6446,  0.0000,  0.0000],</span></span><br><span class="line"><span class="string">                  [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],</span></span><br><span class="line"><span class="string">                  [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # using different paddings for different sides</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ZeroPad2d((1, 1, 2, 0))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],</span></span><br><span class="line"><span class="string">                  [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],</span></span><br><span class="line"><span class="string">                  [ 0.0000, -0.1678, -0.4418,  1.9466,  0.0000],</span></span><br><span class="line"><span class="string">                  [ 0.0000,  0.9604, -0.4219, -0.5241,  0.0000],</span></span><br><span class="line"><span class="string">                  [ 0.0000, -0.9162, -0.5436, -0.6446,  0.0000]]]])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    padding: Tuple[int, int, int, int]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, padding: _size_4_t</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(ZeroPad2d, self).__init__(padding, <span class="number">0.</span>)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ZeroPad2d</mtext></mrow><annotation encoding="application/x-tex">\text{ZeroPad2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ZeroPad2d</span></span></span></span></span> 网络层为二维零填充层. 输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 经过网络层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ZeroPad2d</mtext></mrow><annotation encoding="application/x-tex">\text{ZeroPad2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ZeroPad2d</span></span></span></span></span> 后得到的输出为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span>. 二维零填充层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ZeroPad2d</mtext></mrow><annotation encoding="application/x-tex">\text{ZeroPad2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ZeroPad2d</span></span></span></span></span> 要求其输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 为二维或二维以上张量, 且其最后两个维度含义依次输入特征高度维度和输入特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>in_height</mtext><mo>×</mo><mtext>in_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Input}\in\R^{\cdots\times\text{in\_height}\times\text{in\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_width</span></span></span></span></span></span></span></span></span></span></span></span></span>, 其输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span> 维度个数与输入相同, 但形状不相同, 其最后两个维度含义输出特征高度维度和输出特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>out_height</mtext><mo>×</mo><mtext>out_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{\cdots\times\text{out\_height}\times\text{out\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_width</span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h2 id="二维零填充层的相关参数"><a class="markdownIt-Anchor" href="#二维零填充层的相关参数"></a> 二维零填充层的相关参数</h2><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ZeroPad2d</mtext></mrow><annotation encoding="application/x-tex">\text{ZeroPad2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ZeroPad2d</span></span></span></span></span> 的 <code>padding</code> 参数将指定其对输入特征高度维度和输入特征宽度维度填充的长度. 其可以是整数, 也可以是一个拥有四个整数的元组. 当 <code>padding</code> 为整数时, 其将对输入特征高度维度的上侧和下侧, 输入特征宽度维度的左侧和右侧均填充 <code>padding</code> 个 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>. 若其为拥有四个整数的元组, 则其将对输入特征高度维度的上侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>2</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">2</span><span class="mclose">]</span></span></span></span>, 下侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>3</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[3]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">3</span><span class="mclose">]</span></span></span></span>, 输入特征宽度维度的左侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[0]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span></span></span></span>, 右侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span></span></span></span> 个 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, padding)</span>:</span>
    <span class="hljs-keyword">assert</span> len(input.shape) &gt;= <span class="hljs-number">2</span>, <span class="hljs-string">'input shape error'</span>
    <span class="hljs-keyword">if</span> isinstance(padding, int):
        padding = tuple(repeat(padding, <span class="hljs-number">4</span>))
    <span class="hljs-keyword">assert</span> len(padding) == <span class="hljs-number">4</span>, <span class="hljs-string">'num of padding error'</span>

    layer = nn.ZeroPad2d(padding)
    y = layer(input).numpy()

    input_shape = input.shape
    pd_shape = (input_shape[<span class="hljs-number">-2</span>] + padding[<span class="hljs-number">2</span>] + padding[<span class="hljs-number">3</span>],
                input_shape[<span class="hljs-number">-1</span>] + padding[<span class="hljs-number">0</span>] + padding[<span class="hljs-number">1</span>])
    y_hat = np.zeros((*input_shape[:<span class="hljs-number">-2</span>], *pd_shape))
    y_hat[..., padding[<span class="hljs-number">2</span>]:padding[<span class="hljs-number">2</span>] + input_shape[<span class="hljs-number">-2</span>],
          padding[<span class="hljs-number">0</span>]:padding[<span class="hljs-number">0</span>] + input_shape[<span class="hljs-number">-1</span>]] = input

    print(<span class="hljs-string">f'output error: <span class="hljs-subst">&#123;np.mean(np.abs((y-y_hat).flatten()))&#125;</span>'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)
    padding = <span class="hljs-number">2</span>
    solve(input, padding)

    input = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)
    padding = (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)
    solve(input, padding)
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003002900.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003002900.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.Activation</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:29:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:29:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-04-09 13:56:22" itemprop="dateModified" datetime="2022-04-09T13:56:22+08:00">2022-04-09</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003002900.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003002900.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>11k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>10 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnactivation"><a class="markdownIt-Anchor" href="#pytorchtorchnnactivation"></a> Pytorch.torch.nn.Activation</h1><h2 id="引言"><a class="markdownIt-Anchor" href="#引言"></a> 引言</h2><p>激活函数对于神经网络十分重要. 激活函数通常都是非线性函数, 使用激活函数给神经网络引入了非线性因素. 根据万能近似定理, 神经网络可以任意逼近任何非线性函数, 这样神经网络就可以应用到众多的非线性模型中.</p><p>使用不同的激活函数可以实现不同的效果. 本文将介绍多种激活函数: <code>Threshold</code>, <code>Sigmoid</code>, <code>LogSigmoid</code>, <code>Tanh</code>, <code>Softsign</code>, <code>Hardsigmoid</code>, <code>Hardtanh</code>, <code>ReLU</code>, <code>LeakyReLU</code>, <code>PReLU</code>, <code>ReLU6</code>, <code>RReLU</code>, <code>ELU</code>, <code>SELU</code>, <code>CELU</code>, <code>Softplus</code>, <code>Hardshrink</code>, <code>Softshrink</code>, <code>Tanhshrink</code>, <code>GELU</code>, <code>SiLU</code>, <code>Hardswish</code>, <code>Mish</code>.</p><h2 id="激活函数的用途"><a class="markdownIt-Anchor" href="#激活函数的用途"></a> 激活函数的用途</h2><p>对于某个激活层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Activation</mtext></mrow><annotation encoding="application/x-tex">\text{Activation}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">Activation</span></span></span></span></span>. 假设其输入张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>X</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>X</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">X=(X_{1},X_{2},\cdots,X_{n})\in\R^{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.68889em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.664392em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>, 输出张量为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>Y</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>Y</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>Y</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">Y=(Y_{1},Y_{2},\cdots,Y_{n})\in\R^{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.22222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.22222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.22222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.68889em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.664392em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>(由于激活层的函数是对每个元素进行非线性变换, 因此不改变张量的形状). 可以得到输出与输入的关系为</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi><mo>=</mo><mtext>Activation</mtext><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>Activation</mtext><mo stretchy="false">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mrow><mn>1</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Y=\text{Activation}(X)=\begin{bmatrix}\text{Activation}(X_{i})\end{bmatrix}_{1\leq i\leq n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">Activation</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.3448890000000002em;vertical-align:-.494889em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size1">[</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8500000000000001em"><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord">Activation</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.35000000000000003em"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size1">]</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.061953999999999954em"><span style="top:-2.30029em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">≤</span><span class="mord mathdefault mtight">i</span><span class="mrel mtight">≤</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.494889em"><span></span></span></span></span></span></span></span></span></span></span></p><p>激活函数有以下多种性质:</p><ul><li><p>非线性: 激活函数为非线性激活函数的时候, 基本上两层的神经网络就可以模拟大多数函数. 但是如果没有激活函数的时候, 对多层的神经网络来说只是做到了一个基本向量空间的线性变换, 这与单层的神经网络是等价的.</p></li><li><p>可微性: 在进行梯度优化和计算的时候, 必须满足函数可微性的这一个条件以方便进行求导运算.</p></li><li><p>单调性: 当激活函数是单调函数的时候, 单层的神经网络能够保持是凸函数.</p></li><li><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>≈</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">f(x)\approx x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">x</span></span></span></span>: 激活函数满足这个值主要为的是设置参数的初始化, 以提高神经网络的训练效果.</p></li><li><p>输出的范围: 激活函数输出范围值是一个重要的参数, 当输出的范围是有限的时候, 基于梯度的优化方法会更加稳定, 因为特征量表示受到有限权值的影响会更加显著. 当输出范围是一个无限值的时候, 模型训练更加有效果.</p></li></ul><h2 id="threshold-函数"><a class="markdownIt-Anchor" href="#threshold-函数"></a> Threshold 函数</h2><div class="post-button"><a class="btn" href="/posts/20211003002900.html#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003002800.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003002800.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.AdaptiveMaxPool3d</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:28:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:28:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-19 20:58:14" itemprop="dateModified" datetime="2022-02-19T20:58:14+08:00">2022-02-19</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003002800.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003002800.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.8k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnadaptivemaxpool3d"><a class="markdownIt-Anchor" href="#pytorchtorchnnadaptivemaxpool3d"></a> Pytorch.torch.nn.AdaptiveMaxPool3d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdaptiveAvgPool3d</span>(<span class="params">_AdaptiveAvgPoolNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Applies a 3D adaptive average pooling over an input signal composed of several input planes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The output is of size D x H x W, for any input size.</span></span><br><span class="line"><span class="string">    The number of output features is equal to the number of input planes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        output_size: the target output size of the form D x H x W.</span></span><br><span class="line"><span class="string">                     Can be a tuple (D, H, W) or a single number D for a cube D x D x D.</span></span><br><span class="line"><span class="string">                     D, H and W can be either a ``int``, or ``None`` which means the size will</span></span><br><span class="line"><span class="string">                     be the same as that of the input.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C, H_&#123;in&#125;, W_&#123;in&#125;)` or :math:`(C, H_&#123;in&#125;, W_&#123;in&#125;)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C, S_&#123;0&#125;, S_&#123;1&#125;, S_&#123;2&#125;)` or :math:`(C, S_&#123;0&#125;, S_&#123;1&#125;, S_&#123;2&#125;)`,</span></span><br><span class="line"><span class="string">          where :math:`S=\text&#123;output\_size&#125;`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples:</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # target output size of 5x7x9</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.AdaptiveAvgPool3d((5,7,9))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(1, 64, 8, 9, 10)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # target output size of 7x7x7 (cube)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.AdaptiveAvgPool3d(7)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(1, 64, 10, 9, 8)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # target output size of 7x9x8</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.AdaptiveAvgPool3d((7, None, None))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(1, 64, 10, 9, 8)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    output_size: _size_3_opt_t</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.adaptive_avg_pool3d(input, self.output_size)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AdaptiveAvgPool3d</mtext></mrow><annotation encoding="application/x-tex">\text{AdaptiveAvgPool3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AdaptiveAvgPool3d</span></span></span></span></span> 网络层为三维自适应平均池化层. 输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 经过网络层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AdaptiveAvgPool3d</mtext></mrow><annotation encoding="application/x-tex">\text{AdaptiveAvgPool3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AdaptiveAvgPool3d</span></span></span></span></span> 后得到的输出为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span>. 三维自适应平均池化层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AdaptiveAvgPool3d</mtext></mrow><annotation encoding="application/x-tex">\text{AdaptiveAvgPool3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AdaptiveAvgPool3d</span></span></span></span></span> 要求其输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 为五维张量, 且其维度含义依次为小批量维度, 输入通道维度, 输入特征深度维度, 输入特征高度维度和输入特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mtext>batch_size</mtext><mo>×</mo><mtext>in_channels</mtext><mo>×</mo><mtext>in_depth</mtext><mo>×</mo><mtext>in_height</mtext><mo>×</mo><mtext>in_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Input}\in\R^{\text{batch\_size}\times\text{in\_channels}\times\text{in\_depth}\times\text{in\_height}\times\text{in\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">batch_size</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_channels</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_depth</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_width</span></span></span></span></span></span></span></span></span></span></span></span></span>, 其输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span> 为五维张量, 其维度含义依次为小批量维度, 输出通道维度, 输出特征深度维度, 输出特征高度维度和输出特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mtext>batch_size</mtext><mo>×</mo><mtext>out_channels</mtext><mo>×</mo><mtext>out_depth</mtext><mo>×</mo><mtext>out_height</mtext><mo>×</mo><mtext>out_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{\text{batch\_size}\times\text{out\_channels}\times\text{out\_depth}\times\text{out\_height}\times\text{out\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">batch_size</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_channels</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_depth</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_width</span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AdaptiveAvgPool3d</mtext></mrow><annotation encoding="application/x-tex">\text{AdaptiveAvgPool3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AdaptiveAvgPool3d</span></span></span></span></span> 网络层的 <code>__init__()</code> 函数参数为 <code>output_size</code>. <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AdaptiveAvgPool3d</mtext></mrow><annotation encoding="application/x-tex">\text{AdaptiveAvgPool3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AdaptiveAvgPool3d</span></span></span></span></span> 网络层主要应用于输入特征数任意, 但是输出特征数确定的情况, 这样拥有 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AdaptiveAvgPool3d</mtext></mrow><annotation encoding="application/x-tex">\text{AdaptiveAvgPool3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AdaptiveAvgPool3d</span></span></span></span></span> 的网络即可处理任意尺寸的输入数据.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># torch version: 1.10.2</span></span><br><span class="line"></span><br><span class="line">layer = nn.AdaptiveMaxPool3d((<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">input = torch.randn(<span class="number">1</span>, <span class="number">64</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">output = layer(input)</span><br><span class="line">print(output.shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 64, 5, 5, 5])</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003002700.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003002700.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.AdaptiveAvgPool2d</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:27:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:27:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-19 20:56:36" itemprop="dateModified" datetime="2022-02-19T20:56:36+08:00">2022-02-19</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003002700.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003002700.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.7k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnadaptiveavgpool2d"><a class="markdownIt-Anchor" href="#pytorchtorchnnadaptiveavgpool2d"></a> Pytorch.torch.nn.AdaptiveAvgPool2d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdaptiveAvgPool2d</span>(<span class="params">_AdaptiveAvgPoolNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Applies a 2D adaptive average pooling over an input signal composed of several input planes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The output is of size H x W, for any input size.</span></span><br><span class="line"><span class="string">    The number of output features is equal to the number of input planes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        output_size: the target output size of the image of the form H x W.</span></span><br><span class="line"><span class="string">                     Can be a tuple (H, W) or a single H for a square image H x H.</span></span><br><span class="line"><span class="string">                     H and W can be either a ``int``, or ``None`` which means the size will</span></span><br><span class="line"><span class="string">                     be the same as that of the input.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C, H_&#123;in&#125;, W_&#123;in&#125;)` or :math:`(C, H_&#123;in&#125;, W_&#123;in&#125;)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C, S_&#123;0&#125;, S_&#123;1&#125;)` or :math:`(C, S_&#123;0&#125;, S_&#123;1&#125;)`, where</span></span><br><span class="line"><span class="string">          :math:`S=\text&#123;output\_size&#125;`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples:</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # target output size of 5x7</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.AdaptiveAvgPool2d((5,7))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(1, 64, 8, 9)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # target output size of 7x7 (square)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.AdaptiveAvgPool2d(7)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(1, 64, 10, 9)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # target output size of 10x7</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.AdaptiveAvgPool2d((None, 7))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(1, 64, 10, 9)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    output_size: _size_2_opt_t</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.adaptive_avg_pool2d(input, self.output_size)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AdaptiveAvgPool2d</mtext></mrow><annotation encoding="application/x-tex">\text{AdaptiveAvgPool2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AdaptiveAvgPool2d</span></span></span></span></span> 网络层为二维自适应平均池化层. 输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 经过网络层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AdaptiveAvgPool2d</mtext></mrow><annotation encoding="application/x-tex">\text{AdaptiveAvgPool2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AdaptiveAvgPool2d</span></span></span></span></span> 后得到的输出为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span>. 二维自适应平均池化层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AdaptiveAvgPool2d</mtext></mrow><annotation encoding="application/x-tex">\text{AdaptiveAvgPool2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AdaptiveAvgPool2d</span></span></span></span></span> 要求其输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 为四维张量, 且其维度含义依次为小批量维度, 输入通道维度, 输入特征高度维度和输入特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mtext>batch_size</mtext><mo>×</mo><mtext>in_channels</mtext><mo>×</mo><mtext>in_height</mtext><mo>×</mo><mtext>in_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Input}\in\R^{\text{batch\_size}\times\text{in\_channels}\times\text{in\_height}\times\text{in\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">batch_size</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_channels</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_width</span></span></span></span></span></span></span></span></span></span></span></span></span>, 其输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span> 为四维张量, 其维度含义依次为小批量维度, 输出通道维度, 输出特征高度维度和输出特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mtext>batch_size</mtext><mo>×</mo><mtext>out_channels</mtext><mo>×</mo><mtext>out_height</mtext><mo>×</mo><mtext>out_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{\text{batch\_size}\times\text{out\_channels}\times\text{out\_height}\times\text{out\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">batch_size</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_channels</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_width</span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AdaptiveAvgPool2d</mtext></mrow><annotation encoding="application/x-tex">\text{AdaptiveAvgPool2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AdaptiveAvgPool2d</span></span></span></span></span> 网络层的 <code>__init__()</code> 函数参数为 <code>output_size</code>. <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AdaptiveAvgPool2d</mtext></mrow><annotation encoding="application/x-tex">\text{AdaptiveAvgPool2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AdaptiveAvgPool2d</span></span></span></span></span> 网络层主要应用于输入特征数任意, 但是输出特征数确定的情况, 这样拥有 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AdaptiveAvgPool2d</mtext></mrow><annotation encoding="application/x-tex">\text{AdaptiveAvgPool2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AdaptiveAvgPool2d</span></span></span></span></span> 的网络即可处理任意尺寸的输入数据.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="comment"># torch version: 1.10.2</span></span><br><span class="line"></span><br><span class="line">layer = nn.AdaptiveAvgPool2d((<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">input = torch.randn(<span class="number">1</span>, <span class="number">64</span>, <span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">output = layer(input)</span><br><span class="line">print(output.shape)</span><br><span class="line"><span class="comment"># torch.Size([1, 64, 5, 5])</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><nav class="pagination"><a class="extend prev" rel="prev" href="/page/8/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span><a class="page-number" href="/page/10/">10</a><a class="page-number" href="/page/11/">11</a><span class="space">&hellip;</span><a class="page-number" href="/page/60/">60</a><a class="extend next" rel="next" href="/page/10/"><i class="fa fa-angle-right" aria-label="下一页"></i></a></nav></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="智商为零的小白" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">智商为零的小白</p><div class="site-description" itemprop="description">生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">593</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">32</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">92</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zswldxb" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zswldxb" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:1979938740@qq.com" title="E-Mail → mailto:1979938740@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">智商为零的小白</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="站点总字数">2.4m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">35:44 小时</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-divider">|</span> <span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css"><script>NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'rxJydM3QVoypB9apkSU3e9ML-gzGzoHsz',
      appKey     : 'NqXT8ScfaD1udoMiPk3NQ6MF',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});</script><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><canvas class="fireworks" style="position:fixed;left:0;top:0;z-index:1;pointer-events:none"></canvas><script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script><script type="text/javascript" src="/js/src/fireworks.js"></script></body></html>