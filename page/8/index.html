<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.1.1"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon_logo_2.svg"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon_logo_2.svg"><link rel="mask-icon" href="/images/logo_2.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/themes/blue/pace-theme-minimal.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"zswldxb.github.io",root:"/",scheme:"Mist",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:type" content="website"><meta property="og:title" content="智商为零的小白的博客"><meta property="og:url" content="https://zswldxb.github.io/page/8/index.html"><meta property="og:site_name" content="智商为零的小白的博客"><meta property="og:description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:locale" content="zh_CN"><meta property="article:author" content="智商为零的小白"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://zswldxb.github.io/page/8/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!0,isPost:!1,lang:"zh-CN"}</script><title>智商为零的小白的博客</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">智商为零的小白的博客</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content index posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003004700.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003004700.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.ChannelShuffle</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:47:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:47:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-22 19:07:58" itemprop="dateModified" datetime="2022-02-22T19:07:58+08:00">2022-02-22</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003004700.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003004700.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.9k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnchannelshuffle"><a class="markdownIt-Anchor" href="#pytorchtorchnnchannelshuffle"></a> Pytorch.torch.nn.ChannelShuffle</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChannelShuffle</span>(<span class="params">Module</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Divide the channels in a tensor of shape :math:`(*, C , H, W)`</span></span><br><span class="line"><span class="string">    into g groups and rearrange them as :math:`(*, C \frac g, g, H, W)`,</span></span><br><span class="line"><span class="string">    while keeping the original tensor shape.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        groups (int): number of groups to divide channels in.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; channel_shuffle = nn.ChannelShuffle(2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(1, 4, 2, 2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; print(input)</span></span><br><span class="line"><span class="string">        [[[[1, 2],</span></span><br><span class="line"><span class="string">           [3, 4]],</span></span><br><span class="line"><span class="string">          [[5, 6],</span></span><br><span class="line"><span class="string">           [7, 8]],</span></span><br><span class="line"><span class="string">          [[9, 10],</span></span><br><span class="line"><span class="string">           [11, 12]],</span></span><br><span class="line"><span class="string">          [[13, 14],</span></span><br><span class="line"><span class="string">           [15, 16]],</span></span><br><span class="line"><span class="string">         ]]</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = channel_shuffle(input)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; print(output)</span></span><br><span class="line"><span class="string">        [[[[1, 2],</span></span><br><span class="line"><span class="string">           [3, 4]],</span></span><br><span class="line"><span class="string">          [[9, 10],</span></span><br><span class="line"><span class="string">           [11, 12]],</span></span><br><span class="line"><span class="string">          [[5, 6],</span></span><br><span class="line"><span class="string">           [7, 8]],</span></span><br><span class="line"><span class="string">          [[13, 14],</span></span><br><span class="line"><span class="string">           [15, 16]],</span></span><br><span class="line"><span class="string">         ]]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;groups&#x27;</span>]</span><br><span class="line">    groups: int</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, groups: int</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(ChannelShuffle, self).__init__()</span><br><span class="line">        self.groups = groups</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.channel_shuffle(input, self.groups)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">extra_repr</span>(<span class="params">self</span>) -&gt; str:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;groups=&#123;&#125;&#x27;</span>.format(self.groups)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ChannelShuffle</mtext></mrow><annotation encoding="application/x-tex">\text{ChannelShuffle}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ChannelShuffle</span></span></span></span></span> 网络层为通道重组层. 对于四维输入张量, 其维度含义分别为小批量维度, 通道维度, 特征高度维度, 特征宽度维度, 即 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mtext>batch_size</mtext><mo>×</mo><mtext>channels</mtext><mo>×</mo><mtext>in_height</mtext><mo>×</mo><mtext>in_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Input}\in\R^{\text{batch\_size}\times\text{channels}\times\text{in\_height}\times\text{in\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">batch_size</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">channels</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_width</span></span></span></span></span></span></span></span></span></span></span></span></span>, 组数为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>groups</mtext></mrow><annotation encoding="application/x-tex">\text{groups}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">groups</span></span></span></span></span>. <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ChannelShuffle</mtext></mrow><annotation encoding="application/x-tex">\text{ChannelShuffle}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">ChannelShuffle</span></span></span></span></span> 将首先将输入变为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Hidden</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mtext>batch_size</mtext><mo>×</mo><mtext>groups</mtext><mo>×</mo><mfrac><mtext>channels</mtext><mtext>groups</mtext></mfrac><mo>×</mo><mtext>in_height</mtext><mo>×</mo><mtext>in_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Hidden}\in\R^{\text{batch\_size}\times\text{groups}\times\frac{\text{channels}}{\text{groups}}\times\text{in\_height}\times\text{in\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.73354em;vertical-align:-.0391em"></span><span class="mord text"><span class="mord">Hidden</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.0617899999999998em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0617899999999998em"><span style="top:-3.44577em;margin-right:.05em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">batch_size</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">groups</span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8800285714285714em"><span style="top:-2.656em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">groups</span></span></span></span></span><span style="top:-3.2255000000000003em"><span class="pstrut" style="height:3em"></span><span class="frac-line mtight" style="border-bottom-width:.049em"></span></span><span style="top:-3.384em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">channels</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.48288571428571425em"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_width</span></span></span></span></span></span></span></span></span></span></span></span></span>, 其维度含义依次为小批量维度, 通道维度, 组维度, 特征高度维度, 特征宽度维度, 然后转置通道维度和组维度, 变为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mtext>Hidden</mtext><msup><mrow></mrow><mo mathvariant="normal">′</mo></msup></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mtext>batch_size</mtext><mo>×</mo><mfrac><mtext>channels</mtext><mtext>groups</mtext></mfrac><mo>×</mo><mtext>groups</mtext><mo>×</mo><mtext>in_height</mtext><mo>×</mo><mtext>in_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Hidden}^{&#x27;}\in\R^{\text{batch\_size}\times\frac{\text{channels}}{\text{groups}}\times\text{groups}\times\text{in\_height}\times\text{in\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0659199999999998em;vertical-align:-.0391em"></span><span class="mord"><span class="mord text"><span class="mord">Hidden</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0268199999999998em"><span style="top:-3.0268200000000003em;margin-right:.05em"><span class="pstrut" style="height:2.57948em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8278285714285715em"><span style="top:-2.931em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.0617899999999998em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0617899999999998em"><span style="top:-3.44577em;margin-right:.05em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">batch_size</span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8800285714285714em"><span style="top:-2.656em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">groups</span></span></span></span></span><span style="top:-3.2255000000000003em"><span class="pstrut" style="height:3em"></span><span class="frac-line mtight" style="border-bottom-width:.049em"></span></span><span style="top:-3.384em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">channels</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.48288571428571425em"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">groups</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_width</span></span></span></span></span></span></span></span></span></span></span></span></span>, 然后将组维度和通道维度合并得到输出为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mtext>batch_size</mtext><mo>×</mo><mtext>channels</mtext><mo>×</mo><mtext>in_height</mtext><mo>×</mo><mtext>in_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{\text{batch\_size}\times\text{channels}\times\text{in\_height}\times\text{in\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">batch_size</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">channels</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_width</span></span></span></span></span></span></span></span></span></span></span></span></span>. 其过程如下图所示.</p><div><center><img src="/images/Pytorch/Pytorch.torch.nn.ChannelShuffle_figure_1.SVG" style="zoom:200%"><br>图 1</center></div><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, groups)</span>:</span>
    layer = nn.ChannelShuffle(groups)
    y = layer(torch.tensor(input)).numpy()

    input_shape = input.shape
    <span class="hljs-keyword">assert</span> input_shape[<span class="hljs-number">1</span>] % groups == <span class="hljs-number">0</span>, <span class="hljs-string">'The channels must be divided by the groups.'</span>
    y_hat = np.copy(input)
    y_hat = y_hat.reshape(*input_shape[:<span class="hljs-number">1</span>], groups, input_shape[<span class="hljs-number">1</span>] // groups, *input_shape[<span class="hljs-number">2</span>:])
    y_hat = y_hat.swapaxes(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
    y_hat = y_hat.reshape(*input_shape)
    print(<span class="hljs-string">f'output error: <span class="hljs-subst">&#123;np.mean(np.abs((y-y_hat).flatten()))&#125;</span>'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = np.arange(<span class="hljs-number">128</span>, dtype=np.float64).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
    groups = <span class="hljs-number">2</span>
    solve(input, groups)
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003004600.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003004600.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.FeatureAlphaDropout</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:46:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:46:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-21 21:52:06" itemprop="dateModified" datetime="2022-02-21T21:52:06+08:00">2022-02-21</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003004600.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003004600.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.3k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnfeaturealphadropout"><a class="markdownIt-Anchor" href="#pytorchtorchnnfeaturealphadropout"></a> Pytorch.torch.nn.FeatureAlphaDropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeatureAlphaDropout</span>(<span class="params">_DropoutNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Randomly masks out entire channels (a channel is a feature map,</span></span><br><span class="line"><span class="string">    e.g. the :math:`j`-th channel of the :math:`i`-th sample in the batch input</span></span><br><span class="line"><span class="string">    is a tensor :math:`\text&#123;input&#125;[i, j]`) of the input tensor). Instead of</span></span><br><span class="line"><span class="string">    setting activations to zero, as in regular Dropout, the activations are set</span></span><br><span class="line"><span class="string">    to the negative saturation value of the SELU activation function. More details</span></span><br><span class="line"><span class="string">    can be found in the paper `Self-Normalizing Neural Networks`_ .</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Each element will be masked independently for each sample on every forward</span></span><br><span class="line"><span class="string">    call with probability :attr:`p` using samples from a Bernoulli distribution.</span></span><br><span class="line"><span class="string">    The elements to be masked are randomized on every forward call, and scaled</span></span><br><span class="line"><span class="string">    and shifted to maintain zero mean and unit variance.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Usually the input comes from :class:`nn.AlphaDropout` modules.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    As described in the paper</span></span><br><span class="line"><span class="string">    `Efficient Object Localization Using Convolutional Networks`_ ,</span></span><br><span class="line"><span class="string">    if adjacent pixels within feature maps are strongly correlated</span></span><br><span class="line"><span class="string">    (as is normally the case in early convolution layers) then i.i.d. dropout</span></span><br><span class="line"><span class="string">    will not regularize the activations and will otherwise just result</span></span><br><span class="line"><span class="string">    in an effective learning rate decrease.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    In this case, :func:`nn.AlphaDropout` will help promote independence between</span></span><br><span class="line"><span class="string">    feature maps and should be used instead.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        p (float, optional): probability of an element to be zeroed. Default: 0.5</span></span><br><span class="line"><span class="string">        inplace (bool, optional): If set to ``True``, will do this operation</span></span><br><span class="line"><span class="string">            in-place</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)` (same shape as input).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.FeatureAlphaDropout(p=0.2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(20, 16, 4, 32, 32)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. _Self-Normalizing Neural Networks: https://arxiv.org/abs/1706.02515</span></span><br><span class="line"><span class="string">    .. _Efficient Object Localization Using Convolutional Networks:</span></span><br><span class="line"><span class="string">       https://arxiv.org/abs/1411.4280</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.feature_alpha_dropout(input, self.p, self.training)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>FeatureAlphaDropout</mtext></mrow><annotation encoding="application/x-tex">\text{FeatureAlphaDropout}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">FeatureAlphaDropout</span></span></span></span></span> 与 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AlphaDropout</mtext></mrow><annotation encoding="application/x-tex">\text{AlphaDropout}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AlphaDropout</span></span></span></span></span> 网络层类似, 在训练时对于每个批次的每个通道的所有数据将以概率 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 将这些数据都置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi><msup><mi>α</mi><msup><mrow></mrow><mo mathvariant="normal">′</mo></msup></msup><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">a\alpha^{&#x27;}+b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0258099999999999em;vertical-align:-.08333em"></span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault" style="margin-right:.0037em">α</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.94248em"><span style="top:-2.94248em;margin-right:.05em"><span class="pstrut" style="height:2.57948em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8278285714285715em"><span style="top:-2.931em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathdefault">b</span></span></span></span>, 以 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">1-p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 的概率将这些数据都乘以 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">ax+b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.66666em;vertical-align:-.08333em"></span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathdefault">b</span></span></span></span>. 具体数值见 <a href="/posts/20211003004500.html">Pytorch.torch.nn.AlphaDropout</a>.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, p)</span>:</span>
    layer = nn.FeatureAlphaDropout(p)
    alpha = <span class="hljs-number">-1.6732632423543772848170429916717</span> * <span class="hljs-number">1.0507009873554804934193349852946</span>
    q = <span class="hljs-number">1</span> - p
    a = (q + alpha**<span class="hljs-number">2</span> * q * (<span class="hljs-number">1</span> - q))**(<span class="hljs-number">-0.5</span>)
    b = -a * ((<span class="hljs-number">1</span> - q) * alpha)
    print(<span class="hljs-string">f'a * alpha + b: <span class="hljs-subst">&#123;a * alpha + b&#125;</span>'</span>)
    print(<span class="hljs-string">f'a * 1 + b: <span class="hljs-subst">&#123;a * <span class="hljs-number">1</span> + b&#125;</span>'</span>)

    y = layer(torch.tensor(input)).numpy()
    print(<span class="hljs-string">f'output: <span class="hljs-subst">&#123;y&#125;</span>'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = np.arange((<span class="hljs-number">32</span>), dtype=np.float64).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>)
    input = np.ones((<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>))
    p = <span class="hljs-number">0.5</span>
    print(<span class="hljs-string">f'input: <span class="hljs-subst">&#123;input&#125;</span>'</span>)
    solve(input, p)
    <span class="hljs-comment"># input: [[[[1. 1. 1. 1.]</span>
    <span class="hljs-comment">#    [1. 1. 1. 1.]</span>
    <span class="hljs-comment">#    [1. 1. 1. 1.]</span>
    <span class="hljs-comment">#    [1. 1. 1. 1.]]</span>

    <span class="hljs-comment">#   [[1. 1. 1. 1.]</span>
    <span class="hljs-comment">#    [1. 1. 1. 1.]</span>
    <span class="hljs-comment">#    [1. 1. 1. 1.]</span>
    <span class="hljs-comment">#    [1. 1. 1. 1.]]]]</span>
    <span class="hljs-comment"># a * alpha + b: -0.7791939305180317</span>
    <span class="hljs-comment"># a * 1 + b: 1.6655988251839635</span>
    <span class="hljs-comment"># output: [[[[-0.77919393 -0.77919393 -0.77919393 -0.77919393]</span>
    <span class="hljs-comment">#    [-0.77919393 -0.77919393 -0.77919393 -0.77919393]</span>
    <span class="hljs-comment">#    [-0.77919393 -0.77919393 -0.77919393 -0.77919393]</span>
    <span class="hljs-comment">#    [-0.77919393 -0.77919393 -0.77919393 -0.77919393]]</span>

    <span class="hljs-comment">#   [[ 1.66559883  1.66559883  1.66559883  1.66559883]</span>
    <span class="hljs-comment">#    [ 1.66559883  1.66559883  1.66559883  1.66559883]</span>
    <span class="hljs-comment">#    [ 1.66559883  1.66559883  1.66559883  1.66559883]</span>
    <span class="hljs-comment">#    [ 1.66559883  1.66559883  1.66559883  1.66559883]]]]</span>
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003004500.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003004500.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.AlphaDropout</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:45:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:45:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-21 21:00:36" itemprop="dateModified" datetime="2022-02-21T21:00:36+08:00">2022-02-21</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003004500.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003004500.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>7.3k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>7 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnalphadropout"><a class="markdownIt-Anchor" href="#pytorchtorchnnalphadropout"></a> Pytorch.torch.nn.AlphaDropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AlphaDropout</span>(<span class="params">_DropoutNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Applies Alpha Dropout over the input.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Alpha Dropout is a type of Dropout that maintains the self-normalizing</span></span><br><span class="line"><span class="string">    property.</span></span><br><span class="line"><span class="string">    For an input with zero mean and unit standard deviation, the output of</span></span><br><span class="line"><span class="string">    Alpha Dropout maintains the original mean and standard deviation of the</span></span><br><span class="line"><span class="string">    input.</span></span><br><span class="line"><span class="string">    Alpha Dropout goes hand-in-hand with SELU activation function, which ensures</span></span><br><span class="line"><span class="string">    that the outputs have zero mean and unit standard deviation.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    During training, it randomly masks some of the elements of the input</span></span><br><span class="line"><span class="string">    tensor with probability *p* using samples from a bernoulli distribution.</span></span><br><span class="line"><span class="string">    The elements to masked are randomized on every forward call, and scaled</span></span><br><span class="line"><span class="string">    and shifted to maintain zero mean and unit standard deviation.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    During evaluation the module simply computes an identity function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    More details can be found in the paper `Self-Normalizing Neural Networks`_ .</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        p (float): probability of an element to be dropped. Default: 0.5</span></span><br><span class="line"><span class="string">        inplace (bool, optional): If set to ``True``, will do this operation</span></span><br><span class="line"><span class="string">            in-place</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(*)`. Input can be of any shape</span></span><br><span class="line"><span class="string">        - Output: :math:`(*)`. Output is of the same shape as input</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.AlphaDropout(p=0.2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(20, 16)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. _Self-Normalizing Neural Networks: https://arxiv.org/abs/1706.02515</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.alpha_dropout(input, self.p, self.training)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AlphaDropout</mtext></mrow><annotation encoding="application/x-tex">\text{AlphaDropout}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AlphaDropout</span></span></span></span></span> 网络层在训练时, 假设其输入样本的均值为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>, 方差为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span>. 经过 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AlphaDropout</mtext></mrow><annotation encoding="application/x-tex">\text{AlphaDropout}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AlphaDropout</span></span></span></span></span> 后其输出样本的均值为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>, 方差为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span>. <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>AlphaDropout</mtext></mrow><annotation encoding="application/x-tex">\text{AlphaDropout}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">AlphaDropout</span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>SELU</mtext></mrow><annotation encoding="application/x-tex">\text{SELU}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">SELU</span></span></span></span></span> 成对出现, 一起使用.</p><p>这里考虑一般情况, 对于输入样本 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">x</span></span></span></span>, 均值为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>E</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>μ</mi></mrow><annotation encoding="application/x-tex">\text{E}(x)=\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">E</span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">μ</span></span></span></span>, 方差为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Var</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>ν</mi></mrow><annotation encoding="application/x-tex">\text{Var}(x)=\nu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">Var</span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.06366em">ν</span></span></span></span>, 设随机变量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathdefault">d</span></span></span></span> 服从一重伯努利分布 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>B</mi><mo stretchy="false">(</mo><mn>1</mn><mo separator="true">,</mo><mi>q</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">B(1,q)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.05017em">B</span><span class="mopen">(</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.03588em">q</span><span class="mclose">)</span></span></span></span>, 且独立于其余随机变量, 对于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout</span></span></span></span></span> 其以概率 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>−</mo><mi>q</mi></mrow><annotation encoding="application/x-tex">1-q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.03588em">q</span></span></span></span> 将元素置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>, 概率 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.03588em">q</span></span></span></span> 将元素扩大为原来的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mn>1</mn><mi>q</mi></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\dfrac{1}{q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-.8804400000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">q</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 倍.</p><p>因此变换后的均值为</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>E</mtext><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>d</mi><mo stretchy="false">)</mo><mo>+</mo><mi>x</mi><mi>d</mi><mfrac><mn>1</mn><mi>q</mi></mfrac><mo stretchy="false">)</mo><mo>=</mo><mi>μ</mi></mrow><annotation encoding="application/x-tex">\text{E}(0(1-d)+xd\dfrac{1}{q})=\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">E</span></span><span class="mopen">(</span><span class="mord">0</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault">d</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-.8804400000000001em"></span><span class="mord mathdefault">x</span><span class="mord mathdefault">d</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">q</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">μ</span></span></span></span></span></p><p>, 变换后的方差为</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Var</mtext><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>d</mi><mo stretchy="false">)</mo><mo>+</mo><mi>x</mi><mi>d</mi><mfrac><mn>1</mn><mi>q</mi></mfrac><mo stretchy="false">)</mo><mo>=</mo><mtext>E</mtext><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>x</mi><mi>d</mi><mfrac><mn>1</mn><mi>q</mi></mfrac><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">)</mo><mo>−</mo><mo stretchy="false">(</mo><mtext>E</mtext><mo stretchy="false">(</mo><mi>x</mi><mi>d</mi><mfrac><mn>1</mn><mi>q</mi></mfrac><mo stretchy="false">)</mo><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>=</mo><mfrac><mn>1</mn><msup><mi>q</mi><mn>2</mn></msup></mfrac><mtext>E</mtext><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mi>E</mi><mo stretchy="false">(</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mo>−</mo><msup><mi>μ</mi><mn>2</mn></msup><mo>=</mo><mfrac><mrow><mi>ν</mi><mi>q</mi><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>q</mi><mo stretchy="false">)</mo></mrow><msup><mi>q</mi><mn>2</mn></msup></mfrac><mo>−</mo><msup><mi>μ</mi><mn>2</mn></msup><mo>=</mo><mfrac><mrow><mn>1</mn><mo>−</mo><mi>q</mi></mrow><mi>q</mi></mfrac><mi>ν</mi><mo>−</mo><msup><mi>μ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\text{Var}(0(1-d)+xd\dfrac{1}{q})=\text{E}((xd\dfrac{1}{q})^{2})-(\text{E}(xd\dfrac{1}{q}))^{2}=\dfrac{1}{q^{2}}\text{E}(x^2)E(d^{2})-\mu^{2}=\dfrac{\nu q(1-q)}{q^{2}}-\mu^{2}=\dfrac{1-q}{q}\nu-\mu^{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">Var</span></span><span class="mopen">(</span><span class="mord">0</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault">d</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-.8804400000000001em"></span><span class="mord mathdefault">x</span><span class="mord mathdefault">d</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">q</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-.8804400000000001em"></span><span class="mord text"><span class="mord">E</span></span><span class="mopen">(</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mord mathdefault">d</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">q</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-.8804400000000001em"></span><span class="mopen">(</span><span class="mord text"><span class="mord">E</span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mord mathdefault">d</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">q</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-.8804400000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord text"><span class="mord">E</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:.05764em">E</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.0585479999999998em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.30744em;vertical-align:-.8804400000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.06366em">ν</span><span class="mord mathdefault" style="margin-right:.03588em">q</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault" style="margin-right:.03588em">q</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.0585479999999998em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-.8804400000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">q</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault" style="margin-right:.03588em">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault" style="margin-right:.06366em">ν</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.0585479999999998em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathdefault">μ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span></p><p>. 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout</span></span></span></span></span> 保持变换前后的均值不变.</p><p>对于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>SELU</mtext></mrow><annotation encoding="application/x-tex">\text{SELU}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">SELU</span></span></span></span></span>, 其定义如下:</p><div class="post-button"><a class="btn" href="/posts/20211003004500.html#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003004400.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003004400.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.Dropout3d</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:44:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:44:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-21 19:00:08" itemprop="dateModified" datetime="2022-02-21T19:00:08+08:00">2022-02-21</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003004400.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003004400.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.8k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnndropout3d"><a class="markdownIt-Anchor" href="#pytorchtorchnndropout3d"></a> Pytorch.torch.nn.Dropout3d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dropout3d</span>(<span class="params">_DropoutNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Randomly zero out entire channels (a channel is a 3D feature map,</span></span><br><span class="line"><span class="string">    e.g., the :math:`j`-th channel of the :math:`i`-th sample in the</span></span><br><span class="line"><span class="string">    batched input is a 3D tensor :math:`\text&#123;input&#125;[i, j]`).</span></span><br><span class="line"><span class="string">    Each channel will be zeroed out independently on every forward call with</span></span><br><span class="line"><span class="string">    probability :attr:`p` using samples from a Bernoulli distribution.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Usually the input comes from :class:`nn.Conv3d` modules.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    As described in the paper</span></span><br><span class="line"><span class="string">    `Efficient Object Localization Using Convolutional Networks`_ ,</span></span><br><span class="line"><span class="string">    if adjacent pixels within feature maps are strongly correlated</span></span><br><span class="line"><span class="string">    (as is normally the case in early convolution layers) then i.i.d. dropout</span></span><br><span class="line"><span class="string">    will not regularize the activations and will otherwise just result</span></span><br><span class="line"><span class="string">    in an effective learning rate decrease.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    In this case, :func:`nn.Dropout3d` will help promote independence between</span></span><br><span class="line"><span class="string">    feature maps and should be used instead.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        p (float, optional): probability of an element to be zeroed.</span></span><br><span class="line"><span class="string">        inplace (bool, optional): If set to ``True``, will do this operation</span></span><br><span class="line"><span class="string">            in-place</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C, D, H, W)` or :math:`(C, D, H, W)` (same shape as input).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.Dropout3d(p=0.2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(20, 16, 4, 32, 32)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. _Efficient Object Localization Using Convolutional Networks:</span></span><br><span class="line"><span class="string">       https://arxiv.org/abs/1411.4280</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.dropout3d(input, self.p, self.training, self.inplace)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout3d</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout3d</span></span></span></span></span> 网络层在训练时对于每个批次的每个通道的所有数据将以概率 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 将这些数据都置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>, 以 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">1-p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 的概率将这些数据都乘以 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mn>1</mn><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\dfrac{1}{1-p}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-.8804400000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">p</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>. 因此对于这些元素 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">x</span></span></span></span> 设样本空间 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ω</mi></mrow><annotation encoding="application/x-tex">\Omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord">Ω</span></span></span></span> 为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">{</mo><msub><mi>ω</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>ω</mi><mn>2</mn></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\omega_{1},\omega_{2}\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span>, 其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ω</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\omega_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 为将这些元素都置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ω</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\omega_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 为将这些元素扩大为原来的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mn>1</mn><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\dfrac{1}{1-p}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-.8804400000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">p</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>, 设随机变量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07153em">Z</span></span></span></span>, 其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi><mo>=</mo><msub><mi>ω</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Z=\omega_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07153em">Z</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 的概率为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi><mo>=</mo><msub><mi>ω</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Z=\omega_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07153em">Z</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 的概率为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">1-p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span>, 对于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">x</span></span></span></span> 经过 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout3d</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout3d</span></span></span></span></span> 后得到 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.03588em">y</span></span></span></span>. 因此经过 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout3d</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout3d</span></span></span></span></span> 操作后得到的期望为</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn><mo>×</mo><mi>p</mi><mo>+</mo><mfrac><mi>x</mi><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow></mfrac><mo>×</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">E(Z)=0\times p+\dfrac{x}{1-p}\times(1-p)=x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.05764em">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.07153em">Z</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">0</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.7777700000000001em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.9880000000000002em;vertical-align:-.8804400000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.10756em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">p</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">x</span></span></span></span></span></p><p>因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout3d</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout3d</span></span></span></span></span> 不改变变换前后的期望. 值得注意的是在 <code>Pytorch</code> 中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 为将某数值置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span> 的概率, 在 <code>Tensorflow</code> 中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">1-p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 为将某数值置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span> 的概率.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, p)</span>:</span>
    layer = nn.Dropout3d(p)
    y = layer(torch.tensor(input)).numpy()
    print(<span class="hljs-string">f'output: <span class="hljs-subst">&#123;y&#125;</span>'</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = np.arange((<span class="hljs-number">32</span>), dtype=np.float64).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
    p = <span class="hljs-number">0.5</span>
    print(<span class="hljs-string">f'input: <span class="hljs-subst">&#123;input&#125;</span>'</span>)
    solve(input, p)
    <span class="hljs-comment"># input: [[[[[ 0.  1.]</span>
    <span class="hljs-comment">#     [ 2.  3.]]</span>

    <span class="hljs-comment">#    [[ 4.  5.]</span>
    <span class="hljs-comment">#     [ 6.  7.]]]</span>


    <span class="hljs-comment">#   [[[ 8.  9.]</span>
    <span class="hljs-comment">#     [10. 11.]]</span>

    <span class="hljs-comment">#    [[12. 13.]</span>
    <span class="hljs-comment">#     [14. 15.]]]</span>


    <span class="hljs-comment">#   [[[16. 17.]</span>
    <span class="hljs-comment">#     [18. 19.]]</span>

    <span class="hljs-comment">#    [[20. 21.]</span>
    <span class="hljs-comment">#     [22. 23.]]]</span>


    <span class="hljs-comment">#   [[[24. 25.]</span>
    <span class="hljs-comment">#     [26. 27.]]</span>

    <span class="hljs-comment">#    [[28. 29.]</span>
    <span class="hljs-comment">#     [30. 31.]]]]]</span>
    <span class="hljs-comment"># output: [[[[[ 0.  2.]</span>
    <span class="hljs-comment">#     [ 4.  6.]]</span>

    <span class="hljs-comment">#    [[ 8. 10.]</span>
    <span class="hljs-comment">#     [12. 14.]]]</span>


    <span class="hljs-comment">#   [[[ 0.  0.]</span>
    <span class="hljs-comment">#     [ 0.  0.]]</span>

    <span class="hljs-comment">#    [[ 0.  0.]</span>
    <span class="hljs-comment">#     [ 0.  0.]]]</span>


    <span class="hljs-comment">#   [[[32. 34.]</span>
    <span class="hljs-comment">#     [36. 38.]]</span>

    <span class="hljs-comment">#    [[40. 42.]</span>
    <span class="hljs-comment">#     [44. 46.]]]</span>


    <span class="hljs-comment">#   [[[48. 50.]</span>
    <span class="hljs-comment">#     [52. 54.]]</span>

    <span class="hljs-comment">#    [[56. 58.]</span>
    <span class="hljs-comment">#     [60. 62.]]]]]</span>
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003004300.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003004300.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.Dropout2d</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:43:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:43:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-21 18:59:54" itemprop="dateModified" datetime="2022-02-21T18:59:54+08:00">2022-02-21</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003004300.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003004300.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.8k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnndropout2d"><a class="markdownIt-Anchor" href="#pytorchtorchnndropout2d"></a> Pytorch.torch.nn.Dropout2d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dropout2d</span>(<span class="params">_DropoutNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Randomly zero out entire channels (a channel is a 2D feature map,</span></span><br><span class="line"><span class="string">    e.g., the :math:`j`-th channel of the :math:`i`-th sample in the</span></span><br><span class="line"><span class="string">    batched input is a 2D tensor :math:`\text&#123;input&#125;[i, j]`).</span></span><br><span class="line"><span class="string">    Each channel will be zeroed out independently on every forward call with</span></span><br><span class="line"><span class="string">    probability :attr:`p` using samples from a Bernoulli distribution.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Usually the input comes from :class:`nn.Conv2d` modules.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    As described in the paper</span></span><br><span class="line"><span class="string">    `Efficient Object Localization Using Convolutional Networks`_ ,</span></span><br><span class="line"><span class="string">    if adjacent pixels within feature maps are strongly correlated</span></span><br><span class="line"><span class="string">    (as is normally the case in early convolution layers) then i.i.d. dropout</span></span><br><span class="line"><span class="string">    will not regularize the activations and will otherwise just result</span></span><br><span class="line"><span class="string">    in an effective learning rate decrease.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    In this case, :func:`nn.Dropout2d` will help promote independence between</span></span><br><span class="line"><span class="string">    feature maps and should be used instead.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        p (float, optional): probability of an element to be zero-ed.</span></span><br><span class="line"><span class="string">        inplace (bool, optional): If set to ``True``, will do this operation</span></span><br><span class="line"><span class="string">            in-place</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C, H, W)` or :math:`(C, H, W)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C, H, W)` or :math:`(C, H, W)` (same shape as input).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.Dropout2d(p=0.2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(20, 16, 32, 32)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. _Efficient Object Localization Using Convolutional Networks:</span></span><br><span class="line"><span class="string">       https://arxiv.org/abs/1411.4280</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.dropout2d(input, self.p, self.training, self.inplace)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout2d</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout2d</span></span></span></span></span> 网络层在训练时对于每个批次的每个通道的所有数据将以概率 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 将这些数据都置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>, 以 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">1-p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 的概率将这些数据都乘以 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mn>1</mn><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\dfrac{1}{1-p}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-.8804400000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">p</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>. 因此对于这些元素 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">x</span></span></span></span> 设样本空间 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ω</mi></mrow><annotation encoding="application/x-tex">\Omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord">Ω</span></span></span></span> 为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">{</mo><msub><mi>ω</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>ω</mi><mn>2</mn></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\omega_{1},\omega_{2}\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span>, 其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ω</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\omega_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 为将这些元素都置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ω</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\omega_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 为将这些元素扩大为原来的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mn>1</mn><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\dfrac{1}{1-p}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-.8804400000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">p</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>, 设随机变量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07153em">Z</span></span></span></span>, 其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi><mo>=</mo><msub><mi>ω</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Z=\omega_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07153em">Z</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 的概率为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi><mo>=</mo><msub><mi>ω</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Z=\omega_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07153em">Z</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 的概率为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">1-p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span>, 对于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">x</span></span></span></span> 经过 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout2d</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout2d</span></span></span></span></span> 后得到 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.03588em">y</span></span></span></span>. 因此经过 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout2d</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout2d</span></span></span></span></span> 操作后得到的期望为</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn><mo>×</mo><mi>p</mi><mo>+</mo><mfrac><mi>x</mi><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow></mfrac><mo>×</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">E(Z)=0\times p+\dfrac{x}{1-p}\times(1-p)=x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.05764em">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.07153em">Z</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">0</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.7777700000000001em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.9880000000000002em;vertical-align:-.8804400000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.10756em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">p</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">x</span></span></span></span></span></p><p>因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout2d</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout2d</span></span></span></span></span> 不改变变换前后的期望. 值得注意的是在 <code>Pytorch</code> 中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 为将某数值置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span> 的概率, 在 <code>Tensorflow</code> 中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">1-p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 为将某数值置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span> 的概率.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, p)</span>:</span>
    layer = nn.Dropout2d(p)
    y = layer(torch.tensor(input)).numpy()
    print(<span class="hljs-string">f'output: <span class="hljs-subst">&#123;y&#125;</span>'</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = np.arange((<span class="hljs-number">32</span>), dtype=np.float64).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">2</span>)
    p = <span class="hljs-number">0.5</span>
    print(<span class="hljs-string">f'input: <span class="hljs-subst">&#123;input&#125;</span>'</span>)
    solve(input, p)
    <span class="hljs-comment"># input: [[[[ 0.  1.]</span>
    <span class="hljs-comment">#    [ 2.  3.]</span>
    <span class="hljs-comment">#    [ 4.  5.]</span>
    <span class="hljs-comment">#    [ 6.  7.]]</span>

    <span class="hljs-comment">#   [[ 8.  9.]</span>
    <span class="hljs-comment">#    [10. 11.]</span>
    <span class="hljs-comment">#    [12. 13.]</span>
    <span class="hljs-comment">#    [14. 15.]]</span>

    <span class="hljs-comment">#   [[16. 17.]</span>
    <span class="hljs-comment">#    [18. 19.]</span>
    <span class="hljs-comment">#    [20. 21.]</span>
    <span class="hljs-comment">#    [22. 23.]]</span>

    <span class="hljs-comment">#   [[24. 25.]</span>
    <span class="hljs-comment">#    [26. 27.]</span>
    <span class="hljs-comment">#    [28. 29.]</span>
    <span class="hljs-comment">#    [30. 31.]]]]</span>
    <span class="hljs-comment"># output: [[[[ 0.  2.]</span>
    <span class="hljs-comment">#    [ 4.  6.]</span>
    <span class="hljs-comment">#    [ 8. 10.]</span>
    <span class="hljs-comment">#    [12. 14.]]</span>

    <span class="hljs-comment">#   [[16. 18.]</span>
    <span class="hljs-comment">#    [20. 22.]</span>
    <span class="hljs-comment">#    [24. 26.]</span>
    <span class="hljs-comment">#    [28. 30.]]</span>

    <span class="hljs-comment">#   [[ 0.  0.]</span>
    <span class="hljs-comment">#    [ 0.  0.]</span>
    <span class="hljs-comment">#    [ 0.  0.]</span>
    <span class="hljs-comment">#    [ 0.  0.]]</span>

    <span class="hljs-comment">#   [[ 0.  0.]</span>
    <span class="hljs-comment">#    [ 0.  0.]</span>
    <span class="hljs-comment">#    [ 0.  0.]</span>
    <span class="hljs-comment">#    [ 0.  0.]]]]</span>
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003004200.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003004200.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.Dropout</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:42:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:42:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-21 18:59:44" itemprop="dateModified" datetime="2022-02-21T18:59:44+08:00">2022-02-21</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003004200.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003004200.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.5k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnndropout"><a class="markdownIt-Anchor" href="#pytorchtorchnndropout"></a> Pytorch.torch.nn.Dropout</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dropout</span>(<span class="params">_DropoutNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;During training, randomly zeroes some of the elements of the input</span></span><br><span class="line"><span class="string">    tensor with probability :attr:`p` using samples from a Bernoulli</span></span><br><span class="line"><span class="string">    distribution. Each channel will be zeroed out independently on every forward</span></span><br><span class="line"><span class="string">    call.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    This has proven to be an effective technique for regularization and</span></span><br><span class="line"><span class="string">    preventing the co-adaptation of neurons as described in the paper</span></span><br><span class="line"><span class="string">    `Improving neural networks by preventing co-adaptation of feature</span></span><br><span class="line"><span class="string">    detectors`_ .</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Furthermore, the outputs are scaled by a factor of :math:`\frac&#123;1&#125;&#123;1-p&#125;` during</span></span><br><span class="line"><span class="string">    training. This means that during evaluation the module simply computes an</span></span><br><span class="line"><span class="string">    identity function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        p: probability of an element to be zeroed. Default: 0.5</span></span><br><span class="line"><span class="string">        inplace: If set to ``True``, will do this operation in-place. Default: ``False``</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(*)`. Input can be of any shape</span></span><br><span class="line"><span class="string">        - Output: :math:`(*)`. Output is of the same shape as input</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.Dropout(p=0.2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(20, 16)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. _Improving neural networks by preventing co-adaptation of feature</span></span><br><span class="line"><span class="string">        detectors: https://arxiv.org/abs/1207.0580</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.dropout(input, self.p, self.training, self.inplace)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout</span></span></span></span></span> 网络层在训练时对于每个元素将以概率 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 将该元素置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>, 以 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">1-p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 的概率将该元素乘以 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mn>1</mn><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\dfrac{1}{1-p}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-.8804400000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">p</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>. 因此对于每个元素 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">x</span></span></span></span> 设样本空间 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ω</mi></mrow><annotation encoding="application/x-tex">\Omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord">Ω</span></span></span></span> 为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">{</mo><msub><mi>ω</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>ω</mi><mn>2</mn></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\omega_{1},\omega_{2}\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span>, 其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ω</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\omega_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 为将该元素置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>ω</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\omega_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 为将该元素扩大为原来的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mn>1</mn><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\dfrac{1}{1-p}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.20188em;vertical-align:-.8804400000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">p</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>, 设随机变量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07153em">Z</span></span></span></span>, 其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi><mo>=</mo><msub><mi>ω</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Z=\omega_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07153em">Z</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 的概率为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi><mo>=</mo><msub><mi>ω</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Z=\omega_{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07153em">Z</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 的概率为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">1-p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span>, 对于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">x</span></span></span></span> 经过 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout</span></span></span></span></span> 后得到 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.03588em">y</span></span></span></span>. 因此经过 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout</span></span></span></span></span> 操作后得到的期望为</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi><mo stretchy="false">(</mo><mi>Z</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn><mo>×</mo><mi>p</mi><mo>+</mo><mfrac><mi>x</mi><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow></mfrac><mo>×</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">E(Z)=0\times p+\dfrac{x}{1-p}\times(1-p)=x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.05764em">E</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.07153em">Z</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">0</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.7777700000000001em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.9880000000000002em;vertical-align:-.8804400000000001em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.10756em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">p</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">x</span></span></span></span></span></p><p>因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Dropout</mtext></mrow><annotation encoding="application/x-tex">\text{Dropout}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Dropout</span></span></span></span></span> 不改变变换前后的期望. 值得注意的是在 <code>Pytorch</code> 中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 为将某数值置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span> 的概率, 在 <code>Tensorflow</code> 中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>−</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">1-p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault">p</span></span></span></span> 为将某数值置为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span> 的概率.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, p)</span>:</span>
    layer = nn.Dropout(p)
    y = layer(torch.tensor(input)).numpy()
    print(<span class="hljs-string">f'output: <span class="hljs-subst">&#123;y&#125;</span>'</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = np.arange((<span class="hljs-number">32</span>), dtype=np.float64).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>)
    p = <span class="hljs-number">0.5</span>
    print(<span class="hljs-string">f'input: <span class="hljs-subst">&#123;input&#125;</span>'</span>)
    solve(input, p)
    <span class="hljs-comment"># input: [[[[ 0.  1.  2.  3.]</span>
    <span class="hljs-comment">#    [ 4.  5.  6.  7.]</span>
    <span class="hljs-comment">#    [ 8.  9. 10. 11.]</span>
    <span class="hljs-comment">#    [12. 13. 14. 15.]]</span>

    <span class="hljs-comment">#   [[16. 17. 18. 19.]</span>
    <span class="hljs-comment">#    [20. 21. 22. 23.]</span>
    <span class="hljs-comment">#    [24. 25. 26. 27.]</span>
    <span class="hljs-comment">#    [28. 29. 30. 31.]]]]</span>

    <span class="hljs-comment"># output: [[[[ 0.  2.  4.  6.]</span>
    <span class="hljs-comment">#    [ 0. 10. 12.  0.]</span>
    <span class="hljs-comment">#    [16. 18. 20. 22.]</span>
    <span class="hljs-comment">#    [24. 26. 28. 30.]]</span>

    <span class="hljs-comment">#   [[32.  0.  0.  0.]</span>
    <span class="hljs-comment">#    [40. 42. 44. 46.]</span>
    <span class="hljs-comment">#    [48.  0.  0. 54.]</span>
    <span class="hljs-comment">#    [ 0.  0. 60.  0.]]]]</span>
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003004100.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003004100.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.Unflatten</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:41:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:41:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-21 16:13:24" itemprop="dateModified" datetime="2022-02-21T16:13:24+08:00">2022-02-21</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003004100.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003004100.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>4.9k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>4 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnunflatten"><a class="markdownIt-Anchor" href="#pytorchtorchnnunflatten"></a> Pytorch.torch.nn.Unflatten</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Unflatten</span>(<span class="params">Module</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Unflattens a tensor dim expanding it to a desired shape. For use with :class:`~nn.Sequential`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    * :attr:`dim` specifies the dimension of the input tensor to be unflattened, and it can</span></span><br><span class="line"><span class="string">      be either `int` or `str` when `Tensor` or `NamedTensor` is used, respectively.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    * :attr:`unflattened_size` is the new shape of the unflattened dimension of the tensor and it can be</span></span><br><span class="line"><span class="string">      a `tuple` of ints or a `list` of ints or `torch.Size` for `Tensor` input;  a `NamedShape`</span></span><br><span class="line"><span class="string">      (tuple of `(name, size)` tuples) for `NamedTensor` input.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(*, S_&#123;\text&#123;dim&#125;&#125;, *)`, where :math:`S_&#123;\text&#123;dim&#125;&#125;` is the size at</span></span><br><span class="line"><span class="string">          dimension :attr:`dim` and :math:`*` means any number of dimensions including none.</span></span><br><span class="line"><span class="string">        - Output: :math:`(*, U_1, ..., U_n, *)`, where :math:`U` = :attr:`unflattened_size` and</span></span><br><span class="line"><span class="string">          :math:`\prod_&#123;i=1&#125;^n U_i = S_&#123;\text&#123;dim&#125;&#125;`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dim (Union[int, str]): Dimension to be unflattened</span></span><br><span class="line"><span class="string">        unflattened_size (Union[torch.Size, Tuple, List, NamedShape]): New shape of the unflattened dimension</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples:</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(2, 50)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # With tuple of ints</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.Sequential(</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt;     nn.Linear(50, 50),</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt;     nn.Unflatten(1, (2, 5, 5))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; )</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output.size()</span></span><br><span class="line"><span class="string">        torch.Size([2, 2, 5, 5])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # With torch.Size</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.Sequential(</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt;     nn.Linear(50, 50),</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt;     nn.Unflatten(1, torch.Size([2, 5, 5]))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; )</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output.size()</span></span><br><span class="line"><span class="string">        torch.Size([2, 2, 5, 5])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # With namedshape (tuple of tuples)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(2, 50, names=(&#x27;N&#x27;, &#x27;features&#x27;))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; unflatten = nn.Unflatten(&#x27;features&#x27;, ((&#x27;C&#x27;, 2), (&#x27;H&#x27;, 5), (&#x27;W&#x27;, 5)))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = unflatten(input)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output.size()</span></span><br><span class="line"><span class="string">        torch.Size([2, 2, 5, 5])</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    NamedShape = Tuple[Tuple[str, int]]</span><br><span class="line"></span><br><span class="line">    __constants__ = [<span class="string">&#x27;dim&#x27;</span>, <span class="string">&#x27;unflattened_size&#x27;</span>]</span><br><span class="line">    dim: Union[int, str]</span><br><span class="line">    unflattened_size: Union[_size, NamedShape]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim: Union[int, str], unflattened_size: Union[_size, NamedShape]</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(Unflatten, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> isinstance(dim, int):</span><br><span class="line">            self._require_tuple_int(unflattened_size)</span><br><span class="line">        <span class="keyword">elif</span> isinstance(dim, str):</span><br><span class="line">            self._require_tuple_tuple(unflattened_size)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">&quot;invalid argument type for dim parameter&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.unflattened_size = unflattened_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_require_tuple_tuple</span>(<span class="params">self, input</span>):</span></span><br><span class="line">        <span class="keyword">if</span> (isinstance(input, tuple)):</span><br><span class="line">            <span class="keyword">for</span> idx, elem <span class="keyword">in</span> enumerate(input):</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> isinstance(elem, tuple):</span><br><span class="line">                    <span class="keyword">raise</span> TypeError(<span class="string">&quot;unflattened_size must be tuple of tuples, &quot;</span> +</span><br><span class="line">                                    <span class="string">&quot;but found element of type &#123;&#125; at pos &#123;&#125;&quot;</span>.format(type(elem).__name__, idx))</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">&quot;unflattened_size must be a tuple of tuples, &quot;</span> +</span><br><span class="line">                        <span class="string">&quot;but found type &#123;&#125;&quot;</span>.format(type(input).__name__))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_require_tuple_int</span>(<span class="params">self, input</span>):</span></span><br><span class="line">        <span class="keyword">if</span> (isinstance(input, (tuple, list))):</span><br><span class="line">            <span class="keyword">for</span> idx, elem <span class="keyword">in</span> enumerate(input):</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> isinstance(elem, int):</span><br><span class="line">                    <span class="keyword">raise</span> TypeError(<span class="string">&quot;unflattened_size must be tuple of ints, &quot;</span> +</span><br><span class="line">                                    <span class="string">&quot;but found element of type &#123;&#125; at pos &#123;&#125;&quot;</span>.format(type(elem).__name__, idx))</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">raise</span> TypeError(<span class="string">&quot;unflattened_size must be a tuple of ints, but found type &#123;&#125;&quot;</span>.format(type(input).__name__))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> input.unflatten(self.dim, self.unflattened_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">extra_repr</span>(<span class="params">self</span>) -&gt; str:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;dim=&#123;&#125;, unflattened_size=&#123;&#125;&#x27;</span>.format(self.dim, self.unflattened_size)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Unflatten</mtext></mrow><annotation encoding="application/x-tex">\text{Unflatten}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">Unflatten</span></span></span></span></span> 网络层为逆展平层. 对于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">n</span></span></span></span> 维输入张量, 假设其形状为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub><mo>×</mo><mo>⋯</mo><mo>×</mo><msub><mi>d</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></msup></mrow><annotation encoding="application/x-tex">\text{input}\in\R^{d_{0}\times d_{1}\times\cdots\times d_{n-1}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8623000000000001em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8491079999999999em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8491079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173142857142857em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.20252142857142857em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>, 若设置 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>dim</mtext><mo>=</mo><msub><mi>d</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{dim}=d_{i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">dim</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>unflattened_size</mtext><mo>=</mo><mo stretchy="false">(</mo><msub><mi>u</mi><mn>0</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>u</mi><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{unflattened\_size}=(u_{0},\cdots,u_{m-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-.31em"></span><span class="mord text"><span class="mord">unflattened_size</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, 则将输入张量的第 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">d_{i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 维分为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">m</span></span></span></span> 维, 每个维度的数据长度依次为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>u</mi><mn>0</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>u</mi><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">u_{0},\cdots,u_{m-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.638891em;vertical-align:-.208331em"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span></span></span></span>, 因此输出张量的形状为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><mo>⋯</mo><msub><mi>d</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>×</mo><msub><mi>u</mi><mn>0</mn></msub><mo>×</mo><mo>⋯</mo><msub><mi>u</mi><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>×</mo><msub><mi>d</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>×</mo><msub><mi>d</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{d_{0}\times\cdots d_{i-1}\times u_{0}\times\cdots u_{m-1}\times d_{i+1}\times d_{n-1}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8491079999999999em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8491079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32808571428571426em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.20252142857142857em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mord mtight"><span class="mord mathdefault mtight">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173142857142857em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.20252142857142857em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32808571428571426em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.20252142857142857em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173142857142857em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.20252142857142857em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>. 这里需要满足 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>i</mi></msub><mo>=</mo><msubsup><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow></msubsup><msub><mi>u</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_{i}=\prod_{k=0}^{m-1}u_{k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.253718em;vertical-align:-.29971000000000003em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-.0000050000000000050004em">∏</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.954008em"><span style="top:-2.40029em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.03148em">k</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.29971000000000003em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.03148em">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, dim, unflattened_size)</span>:</span>

    layer = nn.Unflatten(dim, unflattened_size)
    y = layer(torch.tensor(input)).numpy()
    print(<span class="hljs-string">f'output.shape: <span class="hljs-subst">&#123;y.shape&#125;</span>'</span>)

    input_shape = input.shape
    shape = input_shape[dim]
    <span class="hljs-keyword">assert</span> shape == np.prod(unflattened_size), <span class="hljs-string">'error'</span>
    y_hat = input.reshape(*input_shape[:dim], *unflattened_size,
                          *input_shape[dim + <span class="hljs-number">1</span>:])

    print(<span class="hljs-string">f'output error: <span class="hljs-subst">&#123;np.mean(np.abs((y-y_hat).flatten()))&#125;</span>'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = np.random.randn(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">27</span>, <span class="hljs-number">3</span>)
    print(<span class="hljs-string">f'input.shape: <span class="hljs-subst">&#123;input.shape&#125;</span>'</span>)
    dim, unflattened_size = <span class="hljs-number">2</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)
    solve(input, dim, unflattened_size)
    <span class="hljs-comment"># input.shape: (1, 2, 27, 3)</span>
    <span class="hljs-comment"># output.shape: (1, 2, 3, 3, 3, 3)</span>
    <span class="hljs-comment"># output error: 0.0</span>
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003004000.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003004000.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.Flatten</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:40:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:40:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-21 14:57:24" itemprop="dateModified" datetime="2022-02-21T14:57:24+08:00">2022-02-21</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003004000.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003004000.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.8k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnflatten"><a class="markdownIt-Anchor" href="#pytorchtorchnnflatten"></a> Pytorch.torch.nn.Flatten</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Flatten</span>(<span class="params">Module</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Flattens a contiguous range of dims into a tensor. For use with :class:`~nn.Sequential`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(*, S_&#123;\text&#123;start&#125;&#125;,..., S_&#123;i&#125;, ..., S_&#123;\text&#123;end&#125;&#125;, *)`,&#x27;</span></span><br><span class="line"><span class="string">          where :math:`S_&#123;i&#125;` is the size at dimension :math:`i` and :math:`*` means any</span></span><br><span class="line"><span class="string">          number of dimensions including none.</span></span><br><span class="line"><span class="string">        - Output: :math:`(*, \prod_&#123;i=\text&#123;start&#125;&#125;^&#123;\text&#123;end&#125;&#125; S_&#123;i&#125;, *)`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        start_dim: first dim to flatten (default = 1).</span></span><br><span class="line"><span class="string">        end_dim: last dim to flatten (default = -1).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(32, 1, 5, 5)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.Sequential(</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt;     nn.Conv2d(1, 32, 5, 1, 1),</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt;     nn.Flatten()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; )</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output.size()</span></span><br><span class="line"><span class="string">        torch.Size([32, 288])</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;start_dim&#x27;</span>, <span class="string">&#x27;end_dim&#x27;</span>]</span><br><span class="line">    start_dim: int</span><br><span class="line">    end_dim: int</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, start_dim: int = <span class="number">1</span>, end_dim: int = <span class="number">-1</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(Flatten, self).__init__()</span><br><span class="line">        self.start_dim = start_dim</span><br><span class="line">        self.end_dim = end_dim</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> input.flatten(self.start_dim, self.end_dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">extra_repr</span>(<span class="params">self</span>) -&gt; str:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;start_dim=&#123;&#125;, end_dim=&#123;&#125;&#x27;</span>.format(</span><br><span class="line">            self.start_dim, self.end_dim</span><br><span class="line">        )</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Flatten</mtext></mrow><annotation encoding="application/x-tex">\text{Flatten}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">Flatten</span></span></span></span></span> 网络层为展平层. 对于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">n</span></span></span></span> 维输入张量, 假设其形状为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub><mo>×</mo><mo>⋯</mo><mo>×</mo><msub><mi>d</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></msup></mrow><annotation encoding="application/x-tex">\text{input}\in\R^{d_{0}\times d_{1}\times\cdots\times d_{n-1}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8623000000000001em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8491079999999999em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8491079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173142857142857em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.20252142857142857em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>, 若设置 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>start_dim</mtext><mo>=</mo><msub><mi>d</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{start\_dim}=d_{i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-.31em"></span><span class="mord text"><span class="mord">start_dim</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>end_dim</mtext><mo>=</mo><msub><mi>d</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\text{end\_dim}=d_{j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-.31em"></span><span class="mord text"><span class="mord">end_dim</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.980548em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span>, 则将输入张量的第 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">d_{i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.84444em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 维至第 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">d_{j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.980548em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> 展平为一维, 因此输出张量的形状为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mn>0</mn></msub><mo>×</mo><mo>⋯</mo><msub><mi>d</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>×</mo><mo stretchy="false">(</mo><msubsup><mo>∏</mo><mrow><mi>k</mi><mo>=</mo><mi>i</mi></mrow><mi>j</mi></msubsup><msub><mi>d</mi><mi>k</mi></msub><mo stretchy="false">)</mo><mo>×</mo><msub><mi>d</mi><mrow><mi>j</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>×</mo><msub><mi>d</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{d_{0}\times\cdots d_{i-1}\times(\prod_{k=i}^{j}d_{k})\times d_{j+1}\times d_{n-1}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.03134em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.03134em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32808571428571426em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.20252142857142857em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mopen mtight">(</span><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:-.0000050000000000050004em">∏</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.9547714285714286em"><span style="top:-2.1527714285714286em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.03148em">k</span><span class="mrel mtight">=</span><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-2.9836857142857145em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3472285714285714em"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:.19516666666666668em"></span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.3487714285714287em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.03148em">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15122857142857138em"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3280857142857143em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.05724em">j</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2818857142857143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173142857142857em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.20252142857142857em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, start_dim, end_dim)</span>:</span>

    layer = nn.Flatten(start_dim, end_dim)
    y = layer(torch.tensor(input)).numpy()
    print(<span class="hljs-string">f'output.shape: <span class="hljs-subst">&#123;y.shape&#125;</span>'</span>)

    input_shape = input.shape
    len_shape = len(input_shape)
    <span class="hljs-keyword">assert</span> -len_shape &lt;= start_dim <span class="hljs-keyword">and</span> start_dim &lt;= len_shape - <span class="hljs-number">1</span>, <span class="hljs-string">'error'</span>
    <span class="hljs-keyword">assert</span> -len_shape &lt;= end_dim <span class="hljs-keyword">and</span> end_dim &lt;= len_shape - <span class="hljs-number">1</span>, <span class="hljs-string">'error'</span>
    start_dim += len(input_shape) <span class="hljs-keyword">if</span> start_dim &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>
    end_dim += len(input_shape) <span class="hljs-keyword">if</span> end_dim &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>
    <span class="hljs-keyword">assert</span> start_dim &lt;= end_dim, <span class="hljs-string">'error'</span>
    y_hat = input.reshape(*input_shape[:start_dim], <span class="hljs-number">-1</span>,
                          *input_shape[end_dim + <span class="hljs-number">1</span>:])

    print(<span class="hljs-string">f'output error: <span class="hljs-subst">&#123;np.mean(np.abs((y-y_hat).flatten()))&#125;</span>'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = np.random.randn(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)
    print(<span class="hljs-string">f'input.shape: <span class="hljs-subst">&#123;input.shape&#125;</span>'</span>)
    start_dim, end_dim = <span class="hljs-number">1</span>, <span class="hljs-number">3</span>
    solve(input, start_dim, end_dim)
    <span class="hljs-comment"># input.shape: (1, 2, 3, 3, 3)</span>
    <span class="hljs-comment"># output.shape: (1, 18, 3)</span>
    <span class="hljs-comment"># output error: 0.0</span>
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003003900.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003003900.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.ReplicationPad3d</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:39:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:39:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-20 19:30:44" itemprop="dateModified" datetime="2022-02-20T19:30:44+08:00">2022-02-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003003900.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003003900.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>4.2k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>4 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnreplicationpad3d"><a class="markdownIt-Anchor" href="#pytorchtorchnnreplicationpad3d"></a> Pytorch.torch.nn.ReplicationPad3d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReplicationPad3d</span>(<span class="params">_ReplicationPadNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Pads the input tensor using replication of the input boundary.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        padding (int, tuple): the size of the padding. If is `int`, uses the same</span></span><br><span class="line"><span class="string">            padding in all boundaries. If a 6-`tuple`, uses</span></span><br><span class="line"><span class="string">            (:math:`\text&#123;padding\_left&#125;`, :math:`\text&#123;padding\_right&#125;`,</span></span><br><span class="line"><span class="string">            :math:`\text&#123;padding\_top&#125;`, :math:`\text&#123;padding\_bottom&#125;`,</span></span><br><span class="line"><span class="string">            :math:`\text&#123;padding\_front&#125;`, :math:`\text&#123;padding\_back&#125;`)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C, D_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)` or :math:`(C, D_&#123;in&#125;, H_&#123;in&#125;, W_&#123;in&#125;)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C, D_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out&#125;)` or :math:`(C, D_&#123;out&#125;, H_&#123;out&#125;, W_&#123;out&#125;)`,</span></span><br><span class="line"><span class="string">          where</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`D_&#123;out&#125; = D_&#123;in&#125; + \text&#123;padding\_front&#125; + \text&#123;padding\_back&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`H_&#123;out&#125; = H_&#123;in&#125; + \text&#123;padding\_top&#125; + \text&#123;padding\_bottom&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`W_&#123;out&#125; = W_&#123;in&#125; + \text&#123;padding\_left&#125; + \text&#123;padding\_right&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ReplicationPad3d(3)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(16, 3, 8, 320, 480)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # using different paddings for different sides</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ReplicationPad3d((3, 3, 6, 6, 1, 1))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = m(input)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    padding: Tuple[int, int, int, int, int, int]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, padding: _size_6_t</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(ReplicationPad3d, self).__init__()</span><br><span class="line">        self.padding = _ntuple(<span class="number">6</span>)(padding)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReplicationPad3d</mtext></mrow><annotation encoding="application/x-tex">\text{ReplicationPad3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">ReplicationPad3d</span></span></span></span></span> 网络层为三维复制填充层. 输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 经过网络层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReplicationPad3d</mtext></mrow><annotation encoding="application/x-tex">\text{ReplicationPad3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">ReplicationPad3d</span></span></span></span></span> 后得到的输出为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span>. 三维复制填充层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReplicationPad3d</mtext></mrow><annotation encoding="application/x-tex">\text{ReplicationPad3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">ReplicationPad3d</span></span></span></span></span> 要求其输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 为三维或三维以上张量, 且其最后两个维度含义为输入特征深度维度, 输入特征高度维度和输入特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>in_depth</mtext><mo>×</mo><mtext>in_height</mtext><mo>×</mo><mtext>in_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Input}\in\R^{\cdots\times\text{in\_depth}\times\text{in\_height}\times\text{in\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_depth</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_width</span></span></span></span></span></span></span></span></span></span></span></span></span>, 其输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span> 维度个数与输入相同, 但形状不相同, 其最后两个维度含义输出特征深度维度, 输出特征高度维度和输出特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>out_depth</mtext><mo>×</mo><mtext>out_height</mtext><mo>×</mo><mtext>out_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{\cdots\times\text{out\_depth}\times\text{out\_height}\times\text{out\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_depth</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_width</span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h2 id="三维复制填充层的相关参数"><a class="markdownIt-Anchor" href="#三维复制填充层的相关参数"></a> 三维复制填充层的相关参数</h2><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReplicationPad3d</mtext></mrow><annotation encoding="application/x-tex">\text{ReplicationPad3d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">ReplicationPad3d</span></span></span></span></span> 的 <code>padding</code> 参数将指定其对输入特征维度填充的长度, <code>value</code> 参数指定填充的数值, <code>padding</code> 其可以是整数, 也可以是一个拥有六个整数的元组. 当 <code>padding</code> 为整数时, 其将对输入特征深度维度前侧和后侧, 输入特征高度维度上侧和下侧, 输入特征维度的左侧和右侧填充 <code>padding</code> 个数值, 具体数值为边界上的值. 若其为拥有六个整数的元组, 则其将对输入特征深度维度的前侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>4</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[4]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">4</span><span class="mclose">]</span></span></span></span>, 后侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>5</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[5]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">5</span><span class="mclose">]</span></span></span></span>, 输入特征高度维度的上侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>2</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">2</span><span class="mclose">]</span></span></span></span>, 下侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>3</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[3]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">3</span><span class="mclose">]</span></span></span></span>, 输入特征宽度维度的左侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[0]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span></span></span></span>, 右侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span></span></span></span> 个数值, 具体数值为边界上的值.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, padding)</span>:</span>
    <span class="hljs-keyword">if</span> isinstance(padding, int):
        padding = tuple(repeat(padding, <span class="hljs-number">6</span>))
    <span class="hljs-keyword">assert</span> len(padding) == <span class="hljs-number">6</span>, <span class="hljs-string">'num of padding error'</span>

    layer = nn.ReflectionPad3d(padding)
    y = layer(torch.tensor(input, dtype=torch.float64)).numpy()

    input_shape = input.shape
    
    <span class="hljs-comment"># for d_D</span>
    d_d = input_shape[<span class="hljs-number">-3</span>]
    in_ref = input[..., ::<span class="hljs-number">-1</span>, :, :]
    input_whole = np.concatenate((in_ref[..., :<span class="hljs-number">-1</span>, :, :], input, in_ref[..., <span class="hljs-number">1</span>:, :, :]), axis=<span class="hljs-number">-3</span>)
    y_hat = input_whole[..., d_d - padding[<span class="hljs-number">4</span>] - <span class="hljs-number">1</span>:<span class="hljs-number">2</span> * d_d + padding[<span class="hljs-number">5</span>] - <span class="hljs-number">1</span>, :, :]
    <span class="hljs-comment"># for d_H</span>
    d_h = input_shape[<span class="hljs-number">-2</span>]
    in_ref = y_hat[..., ::<span class="hljs-number">-1</span>, :]
    input_whole = np.concatenate((in_ref[..., :<span class="hljs-number">-1</span>, :], y_hat, in_ref[..., <span class="hljs-number">1</span>:, :]), axis=<span class="hljs-number">-2</span>)
    y_hat = input_whole[..., d_h - padding[<span class="hljs-number">2</span>] - <span class="hljs-number">1</span>:<span class="hljs-number">2</span> * d_h + padding[<span class="hljs-number">3</span>] - <span class="hljs-number">1</span>, :]
    <span class="hljs-comment"># for d_W</span>
    d_w = input_shape[<span class="hljs-number">-1</span>]
    in_ref = y_hat[..., ::<span class="hljs-number">-1</span>]
    input_whole = np.concatenate((in_ref[..., :<span class="hljs-number">-1</span>], y_hat, in_ref[..., <span class="hljs-number">1</span>:]), axis=<span class="hljs-number">-1</span>)
    y_hat = input_whole[..., d_w - padding[<span class="hljs-number">0</span>] - <span class="hljs-number">1</span>:<span class="hljs-number">2</span> * d_w + padding[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span>]

    print(y_hat)
    print(<span class="hljs-string">f'output error: <span class="hljs-subst">&#123;np.mean(np.abs((y-y_hat).flatten()))&#125;</span>'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = np.arange(<span class="hljs-number">128</span>).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>)
    print(input)
    padding = <span class="hljs-number">2</span>
    solve(input, padding)

    input = np.arange(<span class="hljs-number">128</span>).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>)
    padding = (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)
    solve(input, padding)
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003003800.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003003800.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.ReplicationPad2d</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 00:38:00" itemprop="dateCreated datePublished" datetime="2021-10-03T00:38:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-20 19:30:56" itemprop="dateModified" datetime="2022-02-20T19:30:56+08:00">2022-02-20</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003003800.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003003800.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.7k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnreplicationpad2d"><a class="markdownIt-Anchor" href="#pytorchtorchnnreplicationpad2d"></a> Pytorch.torch.nn.ReplicationPad2d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReplicationPad2d</span>(<span class="params">_ReplicationPadNd</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Pads the input tensor using replication of the input boundary.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For `N`-dimensional padding, use :func:`torch.nn.functional.pad()`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        padding (int, tuple): the size of the padding. If is `int`, uses the same</span></span><br><span class="line"><span class="string">            padding in all boundaries. If a 4-`tuple`, uses (:math:`\text&#123;padding\_left&#125;`,</span></span><br><span class="line"><span class="string">            :math:`\text&#123;padding\_right&#125;`, :math:`\text&#123;padding\_top&#125;`, :math:`\text&#123;padding\_bottom&#125;`)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C, H_&#123;in&#125;, W_&#123;in&#125;)` or :math:`(C, H_&#123;in&#125;, W_&#123;in&#125;)`.</span></span><br><span class="line"><span class="string">        - Output: :math:`(N, C, H_&#123;out&#125;, W_&#123;out&#125;)` or :math:`(C, H_&#123;out&#125;, W_&#123;out&#125;)`, where</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`H_&#123;out&#125; = H_&#123;in&#125; + \text&#123;padding\_top&#125; + \text&#123;padding\_bottom&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">          :math:`W_&#123;out&#125; = W_&#123;in&#125; + \text&#123;padding\_left&#125; + \text&#123;padding\_right&#125;`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ReplicationPad2d(2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.arange(9, dtype=torch.float).reshape(1, 1, 3, 3)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input</span></span><br><span class="line"><span class="string">        tensor([[[[0., 1., 2.],</span></span><br><span class="line"><span class="string">                  [3., 4., 5.],</span></span><br><span class="line"><span class="string">                  [6., 7., 8.]]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[[0., 0., 0., 1., 2., 2., 2.],</span></span><br><span class="line"><span class="string">                  [0., 0., 0., 1., 2., 2., 2.],</span></span><br><span class="line"><span class="string">                  [0., 0., 0., 1., 2., 2., 2.],</span></span><br><span class="line"><span class="string">                  [3., 3., 3., 4., 5., 5., 5.],</span></span><br><span class="line"><span class="string">                  [6., 6., 6., 7., 8., 8., 8.],</span></span><br><span class="line"><span class="string">                  [6., 6., 6., 7., 8., 8., 8.],</span></span><br><span class="line"><span class="string">                  [6., 6., 6., 7., 8., 8., 8.]]]])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # using different paddings for different sides</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.ReplicationPad2d((1, 1, 2, 0))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m(input)</span></span><br><span class="line"><span class="string">        tensor([[[[0., 0., 1., 2., 2.],</span></span><br><span class="line"><span class="string">                  [0., 0., 1., 2., 2.],</span></span><br><span class="line"><span class="string">                  [0., 0., 1., 2., 2.],</span></span><br><span class="line"><span class="string">                  [3., 3., 4., 5., 5.],</span></span><br><span class="line"><span class="string">                  [6., 6., 7., 8., 8.]]]])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    padding: Tuple[int, int, int, int]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, padding: _size_4_t</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(ReplicationPad2d, self).__init__()</span><br><span class="line">        self.padding = _quadruple(padding)</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReplicationPad2d</mtext></mrow><annotation encoding="application/x-tex">\text{ReplicationPad2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">ReplicationPad2d</span></span></span></span></span> 网络层为二维复制填充层. 输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 经过网络层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReplicationPad2d</mtext></mrow><annotation encoding="application/x-tex">\text{ReplicationPad2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">ReplicationPad2d</span></span></span></span></span> 后得到的输出为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span>. 二维复制填充层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReplicationPad2d</mtext></mrow><annotation encoding="application/x-tex">\text{ReplicationPad2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">ReplicationPad2d</span></span></span></span></span> 要求其输入 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext></mrow><annotation encoding="application/x-tex">\text{Input}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span></span></span></span> 为二维或二维以上张量, 且其最后两个维度含义为输入特征高度维度和输入特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Input</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>in_height</mtext><mo>×</mo><mtext>in_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Input}\in\R^{\cdots\times\text{in\_height}\times\text{in\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Input</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">in_width</span></span></span></span></span></span></span></span></span></span></span></span></span>, 其输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext></mrow><annotation encoding="application/x-tex">\text{Output}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span></span></span></span> 维度个数与输入相同, 但形状不相同, 其最后两个维度含义输出特征高度维度和输出特征宽度维度, 因此 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Output</mtext><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo>⋯</mo><mo>×</mo><mtext>out_height</mtext><mo>×</mo><mtext>out_width</mtext></mrow></msup></mrow><annotation encoding="application/x-tex">\text{Output}\in\R^{\cdots\times\text{out\_height}\times\text{out\_width}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">Output</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_height</span></span><span class="mbin mtight">×</span><span class="mord text mtight"><span class="mord mtight">out_width</span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h2 id="二维复制填充层的相关参数"><a class="markdownIt-Anchor" href="#二维复制填充层的相关参数"></a> 二维复制填充层的相关参数</h2><p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>ReplicationPad2d</mtext></mrow><annotation encoding="application/x-tex">\text{ReplicationPad2d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">ReplicationPad2d</span></span></span></span></span> 的 <code>padding</code> 参数将指定其对输入特征维度填充的长度 <code>padding</code> 其可以是整数, 也可以是一个拥有四个整数的元组. 当 <code>padding</code> 为整数时, 其将对输入特征高度维度上侧和下侧, 输入特征维度的左侧和右侧填充 <code>padding</code> 个数值, 具体数值为边界上的值. 若其为拥有四个整数的元组, 则其将对输入特征高度维度的上侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>2</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">2</span><span class="mclose">]</span></span></span></span>, 下侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>3</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[3]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">3</span><span class="mclose">]</span></span></span></span>, 输入特征宽度维度的左侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[0]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">0</span><span class="mclose">]</span></span></span></span>, 右侧填充 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>padding</mtext><mo stretchy="false">[</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{padding}[1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">padding</span></span><span class="mopen">[</span><span class="mord">1</span><span class="mclose">]</span></span></span></span> 个数值, 具体数值为边界上的值.</p><h2 id="示例"><a class="markdownIt-Anchor" href="#示例"></a> 示例</h2><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span> repeat

print(<span class="hljs-string">f'torch version: <span class="hljs-subst">&#123;torch.__version__&#125;</span>'</span>)
<span class="hljs-comment"># torch version: 1.10.2</span>

torch.set_printoptions(sci_mode=<span class="hljs-literal">False</span>)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solve</span><span class="hljs-params">(input, padding)</span>:</span>
    <span class="hljs-keyword">assert</span> len(input.shape) &gt;= <span class="hljs-number">1</span>, <span class="hljs-string">'input shape error'</span>
    <span class="hljs-keyword">if</span> isinstance(padding, int):
        padding = tuple(repeat(padding, <span class="hljs-number">4</span>))
    <span class="hljs-keyword">assert</span> len(padding) == <span class="hljs-number">4</span>, <span class="hljs-string">'num of padding error'</span>

    layer = nn.ReplicationPad2d(padding)
    y = layer(torch.tensor(input, dtype=torch.float64)).numpy()

    y_hat = np.concatenate((np.repeat(input[..., <span class="hljs-number">0</span>:<span class="hljs-number">1</span>, :], padding[<span class="hljs-number">2</span>], axis=<span class="hljs-number">-2</span>), input, np.repeat(input[..., <span class="hljs-number">-1</span>:, :], padding[<span class="hljs-number">3</span>], axis=<span class="hljs-number">-2</span>)), axis=<span class="hljs-number">-2</span>)
    y_hat = np.concatenate((np.repeat(y_hat[..., <span class="hljs-number">0</span>:<span class="hljs-number">1</span>], padding[<span class="hljs-number">0</span>], axis=<span class="hljs-number">-1</span>), y_hat, np.repeat(y_hat[..., <span class="hljs-number">-1</span>:], padding[<span class="hljs-number">1</span>], axis=<span class="hljs-number">-1</span>)), axis=<span class="hljs-number">-1</span>)

    print(<span class="hljs-string">f'output error: <span class="hljs-subst">&#123;np.mean(np.abs((y-y_hat).flatten()))&#125;</span>'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    input = np.arange(<span class="hljs-number">32</span>).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>)
    padding = <span class="hljs-number">2</span>
    solve(input, padding)

    input = np.arange(<span class="hljs-number">32</span>).reshape(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>)
    padding = (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
    solve(input, padding)
</code></pre></div><footer class="post-footer"><div class="post-eof"></div></footer></article><nav class="pagination"><a class="extend prev" rel="prev" href="/page/7/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><span class="space">&hellip;</span><a class="page-number" href="/page/60/">60</a><a class="extend next" rel="next" href="/page/9/"><i class="fa fa-angle-right" aria-label="下一页"></i></a></nav></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="智商为零的小白" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">智商为零的小白</p><div class="site-description" itemprop="description">生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">593</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">32</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">92</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zswldxb" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zswldxb" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:1979938740@qq.com" title="E-Mail → mailto:1979938740@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">智商为零的小白</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="站点总字数">2.4m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">35:44 小时</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-divider">|</span> <span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css"><script>NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'rxJydM3QVoypB9apkSU3e9ML-gzGzoHsz',
      appKey     : 'NqXT8ScfaD1udoMiPk3NQ6MF',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});</script><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><canvas class="fireworks" style="position:fixed;left:0;top:0;z-index:1;pointer-events:none"></canvas><script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script><script type="text/javascript" src="/js/src/fireworks.js"></script></body></html>