<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.1.1"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon_logo_2.svg"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon_logo_2.svg"><link rel="mask-icon" href="/images/logo_2.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/themes/blue/pace-theme-minimal.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"zswldxb.github.io",root:"/",scheme:"Mist",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:type" content="website"><meta property="og:title" content="智商为零的小白的博客"><meta property="og:url" content="https://zswldxb.github.io/page/5/index.html"><meta property="og:site_name" content="智商为零的小白的博客"><meta property="og:description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:locale" content="zh_CN"><meta property="article:author" content="智商为零的小白"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://zswldxb.github.io/page/5/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!0,isPost:!1,lang:"zh-CN"}</script><title>智商为零的小白的博客</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">智商为零的小白的博客</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content index posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003011800.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003011800.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.CosineEmbeddingLoss</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 01:18:00" itemprop="dateCreated datePublished" datetime="2021-10-03T01:18:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-27 22:27:32" itemprop="dateModified" datetime="2022-02-27T22:27:32+08:00">2022-02-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003011800.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003011800.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>6.1k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>6 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnncosineembeddingloss"><a class="markdownIt-Anchor" href="#pytorchtorchnncosineembeddingloss"></a> Pytorch.torch.nn.CosineEmbeddingLoss</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CosineEmbeddingLoss</span>(<span class="params">_Loss</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Creates a criterion that measures the loss given input tensors</span></span><br><span class="line"><span class="string">    :math:`x_1`, :math:`x_2` and a `Tensor` label :math:`y` with values 1 or -1.</span></span><br><span class="line"><span class="string">    This is used for measuring whether two inputs are similar or dissimilar,</span></span><br><span class="line"><span class="string">    using the cosine distance, and is typically used for learning nonlinear</span></span><br><span class="line"><span class="string">    embeddings or semi-supervised learning.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The loss function for each sample is:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \text&#123;loss&#125;(x, y) =</span></span><br><span class="line"><span class="string">        \begin&#123;cases&#125;</span></span><br><span class="line"><span class="string">        1 - \cos(x_1, x_2), &amp; \text&#123;if &#125; y = 1 \\</span></span><br><span class="line"><span class="string">        \max(0, \cos(x_1, x_2) - \text&#123;margin&#125;), &amp; \text&#123;if &#125; y = -1</span></span><br><span class="line"><span class="string">        \end&#123;cases&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        margin (float, optional): Should be a number from :math:`-1` to :math:`1`,</span></span><br><span class="line"><span class="string">            :math:`0` to :math:`0.5` is suggested. If :attr:`margin` is missing, the</span></span><br><span class="line"><span class="string">            default value is :math:`0`.</span></span><br><span class="line"><span class="string">        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,</span></span><br><span class="line"><span class="string">            the losses are averaged over each loss element in the batch. Note that for</span></span><br><span class="line"><span class="string">            some losses, there are multiple elements per sample. If the field :attr:`size_average`</span></span><br><span class="line"><span class="string">            is set to ``False``, the losses are instead summed for each minibatch. Ignored</span></span><br><span class="line"><span class="string">            when :attr:`reduce` is ``False``. Default: ``True``</span></span><br><span class="line"><span class="string">        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the</span></span><br><span class="line"><span class="string">            losses are averaged or summed over observations for each minibatch depending</span></span><br><span class="line"><span class="string">            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per</span></span><br><span class="line"><span class="string">            batch element instead and ignores :attr:`size_average`. Default: ``True``</span></span><br><span class="line"><span class="string">        reduction (string, optional): Specifies the reduction to apply to the output:</span></span><br><span class="line"><span class="string">            ``&#x27;none&#x27;`` | ``&#x27;mean&#x27;`` | ``&#x27;sum&#x27;``. ``&#x27;none&#x27;``: no reduction will be applied,</span></span><br><span class="line"><span class="string">            ``&#x27;mean&#x27;``: the sum of the output will be divided by the number of</span></span><br><span class="line"><span class="string">            elements in the output, ``&#x27;sum&#x27;``: the output will be summed. Note: :attr:`size_average`</span></span><br><span class="line"><span class="string">            and :attr:`reduce` are in the process of being deprecated, and in the meantime,</span></span><br><span class="line"><span class="string">            specifying either of those two args will override :attr:`reduction`. Default: ``&#x27;mean&#x27;``</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input1: :math:`(N, D)` or :math:`(D)`, where `N` is the batch size and `D` is the embedding dimension.</span></span><br><span class="line"><span class="string">        - Input2: :math:`(N, D)` or :math:`(D)`, same shape as Input1.</span></span><br><span class="line"><span class="string">        - Target: :math:`(N)` or :math:`()`.</span></span><br><span class="line"><span class="string">        - Output: If :attr:`reduction` is ``&#x27;none&#x27;``, then :math:`(N)`, otherwise scalar.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;margin&#x27;</span>, <span class="string">&#x27;reduction&#x27;</span>]</span><br><span class="line">    margin: float</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, margin: float = <span class="number">0.</span>, size_average=None, reduce=None, reduction: str = <span class="string">&#x27;mean&#x27;</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(CosineEmbeddingLoss, self).__init__(size_average, reduce, reduction)</span><br><span class="line">        self.margin = margin</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input1: Tensor, input2: Tensor, target: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.cosine_embedding_loss(input1, input2, target, margin=self.margin, reduction=self.reduction)</span><br></pre></td></tr></table></figure><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>CosineEmbeddingLoss</mtext></mrow><annotation encoding="application/x-tex">\text{CosineEmbeddingLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">CosineEmbeddingLoss</span></span></span></span></span> 为余弦相似度损失函数. 损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>CosineEmbeddingLoss</mtext></mrow><annotation encoding="application/x-tex">\text{CosineEmbeddingLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">CosineEmbeddingLoss</span></span></span></span></span> 其要求标签张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span></span></span></span> 为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 维张量, 输入张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07153em">Z</span></span></span></span> 为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">2</span></span></span></span> 维张量, 且 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>N</mi></msup></mrow><annotation encoding="application/x-tex">Y\in\R^{N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72243em;vertical-align:-.0391em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.10903em">N</span></span></span></span></span></span></span></span></span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo separator="true">,</mo><mi>Z</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><mi>D</mi></mrow></msup></mrow><annotation encoding="application/x-tex">X,Z\in\R^{N\times D}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.07153em">Z</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.10903em">N</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right:.02778em">D</span></span></span></span></span></span></span></span></span></span></span></span>. <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span></span></span></span> 的每个元素取值集合为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">{</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{-1,1\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">{</span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">1</span><span class="mclose">}</span></span></span></span>.</p><p>对于两个向量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>U</mi><mo separator="true">,</mo><mi>V</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>D</mi></msup></mrow><annotation encoding="application/x-tex">U,V\in\R^{D}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.10903em">U</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">V</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.02778em">D</span></span></span></span></span></span></span></span></span></span></span></span>, 其余弦相似度计算公式如下:</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>CosineSimilarity</mtext><mo stretchy="false">(</mo><mi>U</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∑</mo><mrow><mi>d</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>D</mi><mo>−</mo><mn>1</mn></mrow></munderover><msub><mi>U</mi><mi>d</mi></msub><mo>⋅</mo><msub><mi>V</mi><mi>d</mi></msub></mstyle><mrow><msqrt><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∑</mo><mrow><mi>d</mi><mo>=</mo><mn>0</mn></mrow><mi>D</mi></munderover><msubsup><mi>U</mi><mi>d</mi><mn>2</mn></msubsup></mstyle></msqrt><msqrt><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∑</mo><mrow><mi>d</mi><mo>=</mo><mn>0</mn></mrow><mi>D</mi></munderover><msubsup><mi>V</mi><mi>d</mi><mn>2</mn></msubsup></mstyle></msqrt></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{CosineSimilarity}(U,V)=\dfrac{\displaystyle\sum_{d=0}^{D-1}U_{d}\cdot V_{d}}{\sqrt{\displaystyle\sum_{d=0}^{D}U_{d}^{2}}\sqrt{\displaystyle\sum_{d=0}^{D}V_{d}^{2}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">CosineSimilarity</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.10903em">U</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:6.670898em;vertical-align:-3.150449em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.520449em"><span style="top:-2.1100000000000003em"><span class="pstrut" style="height:3.958336em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9583360000000003em"><span class="svg-align" style="top:-5.220449em"><span class="pstrut" style="height:5.220449em"></span><span class="mord" style="padding-left:1.056em"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em"><span style="top:-1.8478869999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.02778em">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.10903em">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-2.4530000000000003em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span></span></span><span style="top:-3.918336em"><span class="pstrut" style="height:5.220449em"></span><span class="hide-tail" style="min-width:.742em;height:3.3004490000000004em"><svg width="400em" height="3.3004490000000004em" viewBox="0 0 400000 3300" preserveAspectRatio="xMinYMin slice"><path d="M702 80H400000v40H742v3166l-4 4-4 4c-.667.7
-2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1h-12l-28-84c-16.667-52-96.667
-294.333-240-727l-212 -643 -85 170c-4-3.333-8.333-7.667-13 -13l-13-13l77-155
 77-156c66 199.333 139 419.667 219 661 l218 661zM702 80H400000v40H742z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em"><span></span></span></span></span></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9583360000000003em"><span class="svg-align" style="top:-5.220449em"><span class="pstrut" style="height:5.220449em"></span><span class="mord" style="padding-left:1.056em"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em"><span style="top:-1.8478869999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.02778em">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.22222em">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-2.4530000000000003em;margin-left:-.22222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span></span></span><span style="top:-3.918336em"><span class="pstrut" style="height:5.220449em"></span><span class="hide-tail" style="min-width:.742em;height:3.3004490000000004em"><svg width="400em" height="3.3004490000000004em" viewBox="0 0 400000 3300" preserveAspectRatio="xMinYMin slice"><path d="M702 80H400000v40H742v3166l-4 4-4 4c-.667.7
-2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1h-12l-28-84c-16.667-52-96.667
-294.333-240-727l-212 -643 -85 170c-4-3.333-8.333-7.667-13 -13l-13-13l77-155
 77-156c66 199.333 139 419.667 219 661 l218 661zM702 80H400000v40H742z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em"><span></span></span></span></span></span></span></span><span style="top:-4.188336em"><span class="pstrut" style="height:3.958336em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-5.650449em"><span class="pstrut" style="height:3.958336em"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em"><span style="top:-1.8478869999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.02778em">D</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.10903em">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.10903em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.22222em">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.22222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.150449em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><h3 id="margin-参数"><a class="markdownIt-Anchor" href="#margin-参数"></a> margin 参数</h3><p><code>margin</code> 参数表示间隔, 用于区分正类与负类之间的距离.</p><h3 id="reduction-参数"><a class="markdownIt-Anchor" href="#reduction-参数"></a> reduction 参数</h3><p><code>reduction</code>: 用于指定计算的模式, <code>'none'</code>, <code>'mean'</code>, <code>'sum'</code> 或 <code>'batchmean'</code>. 默认为 <code>'mean'</code>.</p><p>当 <code>reduction='none'</code> 时, 计算过程如下:</p><div class="post-button"><a class="btn" href="/posts/20211003011800.html#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003011700.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003011700.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.BCEWithLogitsLoss</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 01:17:00" itemprop="dateCreated datePublished" datetime="2021-10-03T01:17:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-27 20:43:58" itemprop="dateModified" datetime="2022-02-27T20:43:58+08:00">2022-02-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003011700.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003011700.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>8.2k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>7 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnbcewithlogitsloss"><a class="markdownIt-Anchor" href="#pytorchtorchnnbcewithlogitsloss"></a> Pytorch.torch.nn.BCEWithLogitsLoss</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BCEWithLogitsLoss</span>(<span class="params">_Loss</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;This loss combines a `Sigmoid` layer and the `BCELoss` in one single</span></span><br><span class="line"><span class="string">    class. This version is more numerically stable than using a plain `Sigmoid`</span></span><br><span class="line"><span class="string">    followed by a `BCELoss` as, by combining the operations into one layer,</span></span><br><span class="line"><span class="string">    we take advantage of the log-sum-exp trick for numerical stability.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The unreduced (i.e. with :attr:`reduction` set to ``&#x27;none&#x27;``) loss can be described as:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \ell(x, y) = L = \&#123;l_1,\dots,l_N\&#125;^\top, \quad</span></span><br><span class="line"><span class="string">        l_n = - w_n \left[ y_n \cdot \log \sigma(x_n)</span></span><br><span class="line"><span class="string">        + (1 - y_n) \cdot \log (1 - \sigma(x_n)) \right],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    where :math:`N` is the batch size. If :attr:`reduction` is not ``&#x27;none&#x27;``</span></span><br><span class="line"><span class="string">    (default ``&#x27;mean&#x27;``), then</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \ell(x, y) = \begin&#123;cases&#125;</span></span><br><span class="line"><span class="string">            \operatorname&#123;mean&#125;(L), &amp; \text&#123;if reduction&#125; = \text&#123;`mean&#x27;;&#125;\\</span></span><br><span class="line"><span class="string">            \operatorname&#123;sum&#125;(L),  &amp; \text&#123;if reduction&#125; = \text&#123;`sum&#x27;.&#125;</span></span><br><span class="line"><span class="string">        \end&#123;cases&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    This is used for measuring the error of a reconstruction in for example</span></span><br><span class="line"><span class="string">    an auto-encoder. Note that the targets `t[i]` should be numbers</span></span><br><span class="line"><span class="string">    between 0 and 1.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    It&#x27;s possible to trade off recall and precision by adding weights to positive examples.</span></span><br><span class="line"><span class="string">    In the case of multi-label classification the loss can be described as:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \ell_c(x, y) = L_c = \&#123;l_&#123;1,c&#125;,\dots,l_&#123;N,c&#125;\&#125;^\top, \quad</span></span><br><span class="line"><span class="string">        l_&#123;n,c&#125; = - w_&#123;n,c&#125; \left[ p_c y_&#123;n,c&#125; \cdot \log \sigma(x_&#123;n,c&#125;)</span></span><br><span class="line"><span class="string">        + (1 - y_&#123;n,c&#125;) \cdot \log (1 - \sigma(x_&#123;n,c&#125;)) \right],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    where :math:`c` is the class number (:math:`c &gt; 1` for multi-label binary classification,</span></span><br><span class="line"><span class="string">    :math:`c = 1` for single-label binary classification),</span></span><br><span class="line"><span class="string">    :math:`n` is the number of the sample in the batch and</span></span><br><span class="line"><span class="string">    :math:`p_c` is the weight of the positive answer for the class :math:`c`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :math:`p_c &gt; 1` increases the recall, :math:`p_c &lt; 1` increases the precision.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For example, if a dataset contains 100 positive and 300 negative examples of a single class,</span></span><br><span class="line"><span class="string">    then `pos_weight` for the class should be equal to :math:`\frac&#123;300&#125;&#123;100&#125;=3`.</span></span><br><span class="line"><span class="string">    The loss would act as if the dataset contains :math:`3\times 100=300` positive examples.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; target = torch.ones([10, 64], dtype=torch.float32)  # 64 classes, batch size = 10</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = torch.full([10, 64], 1.5)  # A prediction (logit)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; pos_weight = torch.ones([64])  # All weights are equal to 1</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; criterion(output, target)  # -log(sigmoid(1.5))</span></span><br><span class="line"><span class="string">        tensor(0.2014)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        weight (Tensor, optional): a manual rescaling weight given to the loss</span></span><br><span class="line"><span class="string">            of each batch element. If given, has to be a Tensor of size `nbatch`.</span></span><br><span class="line"><span class="string">        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,</span></span><br><span class="line"><span class="string">            the losses are averaged over each loss element in the batch. Note that for</span></span><br><span class="line"><span class="string">            some losses, there are multiple elements per sample. If the field :attr:`size_average`</span></span><br><span class="line"><span class="string">            is set to ``False``, the losses are instead summed for each minibatch. Ignored</span></span><br><span class="line"><span class="string">            when :attr:`reduce` is ``False``. Default: ``True``</span></span><br><span class="line"><span class="string">        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the</span></span><br><span class="line"><span class="string">            losses are averaged or summed over observations for each minibatch depending</span></span><br><span class="line"><span class="string">            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per</span></span><br><span class="line"><span class="string">            batch element instead and ignores :attr:`size_average`. Default: ``True``</span></span><br><span class="line"><span class="string">        reduction (string, optional): Specifies the reduction to apply to the output:</span></span><br><span class="line"><span class="string">            ``&#x27;none&#x27;`` | ``&#x27;mean&#x27;`` | ``&#x27;sum&#x27;``. ``&#x27;none&#x27;``: no reduction will be applied,</span></span><br><span class="line"><span class="string">            ``&#x27;mean&#x27;``: the sum of the output will be divided by the number of</span></span><br><span class="line"><span class="string">            elements in the output, ``&#x27;sum&#x27;``: the output will be summed. Note: :attr:`size_average`</span></span><br><span class="line"><span class="string">            and :attr:`reduce` are in the process of being deprecated, and in the meantime,</span></span><br><span class="line"><span class="string">            specifying either of those two args will override :attr:`reduction`. Default: ``&#x27;mean&#x27;``</span></span><br><span class="line"><span class="string">        pos_weight (Tensor, optional): a weight of positive examples.</span></span><br><span class="line"><span class="string">                Must be a vector with length equal to the number of classes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.</span></span><br><span class="line"><span class="string">        - Target: :math:`(*)`, same shape as the input.</span></span><br><span class="line"><span class="string">        - Output: scalar. If :attr:`reduction` is ``&#x27;none&#x27;``, then :math:`(*)`, same</span></span><br><span class="line"><span class="string">          shape as input.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; loss = nn.BCEWithLogitsLoss()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(3, requires_grad=True)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; target = torch.empty(3).random_(2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = loss(input, target)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output.backward()</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, weight: Optional[Tensor] = None, size_average=None, reduce=None, reduction: str = <span class="string">&#x27;mean&#x27;</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 pos_weight: Optional[Tensor] = None</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(BCEWithLogitsLoss, self).__init__(size_average, reduce, reduction)</span><br><span class="line">        self.register_buffer(<span class="string">&#x27;weight&#x27;</span>, weight)</span><br><span class="line">        self.register_buffer(<span class="string">&#x27;pos_weight&#x27;</span>, pos_weight)</span><br><span class="line">        self.weight: Optional[Tensor]</span><br><span class="line">        self.pos_weight: Optional[Tensor]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor, target: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.binary_cross_entropy_with_logits(input, target,</span><br><span class="line">                                                  self.weight,</span><br><span class="line">                                                  pos_weight=self.pos_weight,</span><br><span class="line">                                                  reduction=self.reduction)</span><br></pre></td></tr></table></figure><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>BCEWithLogitsLoss</mtext></mrow><annotation encoding="application/x-tex">\text{BCEWithLogitsLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">BCEWithLogitsLoss</span></span></span></span></span> 为带逻辑回归函数的二分类交叉熵损失函数. 损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>BCEWithLogitsLoss</mtext></mrow><annotation encoding="application/x-tex">\text{BCEWithLogitsLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">BCEWithLogitsLoss</span></span></span></span></span> 其要求标签张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span></span></span></span>, 输入张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span></span></span></span> 均为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">n</span></span></span></span> 维张量, 且 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>×</mo><mo>⋯</mo><mo>×</mo><msub><mi>d</mi><mi>n</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">X,Y\in\R^{d_{1}\times\cdots\times d_{n}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>. 且 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span></span></span></span> 的每个元素取值集合为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{0,1\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">1</span><span class="mclose">}</span></span></span></span>.</p><p>对于标签为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.03588em">y</span></span></span></span>, 预测为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">x</span></span></span></span>, 二分类交叉熵定义如下:</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mo stretchy="false">(</mo><mi>y</mi><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>y</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">l(x,y)=-(y\log {(x)}+(1-y)\log{(1-x)})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.01968em">l</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">−</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">x</span><span class="mclose">)</span></span><span class="mclose">)</span></span></span></span></span></p><p>这里以 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><mi>C</mi></mrow></msup></mrow><annotation encoding="application/x-tex">X,Y\in\R^{N\times C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.10903em">N</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right:.07153em">C</span></span></span></span></span></span></span></span></span></span></span></span>, 其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.10903em">N</span></span></span></span> 表示样本数, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07153em">C</span></span></span></span> 表示标签个数.</p><h3 id="weight-参数"><a class="markdownIt-Anchor" href="#weight-参数"></a> weight 参数</h3><p><code>weight</code> 参数用于加权每个元素的权重. <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><mi>C</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W\in\R^{N\times C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72243em;vertical-align:-.0391em"></span><span class="mord mathdefault" style="margin-right:.13889em">W</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.10903em">N</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right:.07153em">C</span></span></span></span></span></span></span></span></span></span></span></span>.</p><h3 id="pos_weight-参数"><a class="markdownIt-Anchor" href="#pos_weight-参数"></a> pos_weight 参数</h3><p><code>pos_weight</code> 参数用于表示需要对正样本的加权比例, 其计算公式为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mtext>反例数</mtext><mtext>正例数</mtext></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\dfrac{\text{反例数}}{\text{正例数}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.04633em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord cjk_fallback">正例数</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord cjk_fallback">反例数</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>. <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>U</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>C</mi></msup></mrow><annotation encoding="application/x-tex">U\in\R^{C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72243em;vertical-align:-.0391em"></span><span class="mord mathdefault" style="margin-right:.10903em">U</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.07153em">C</span></span></span></span></span></span></span></span></span></span></span></span></p><div class="post-button"><a class="btn" href="/posts/20211003011700.html#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003011600.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003011600.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.BCELoss</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 01:16:00" itemprop="dateCreated datePublished" datetime="2021-10-03T01:16:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-27 20:00:26" itemprop="dateModified" datetime="2022-02-27T20:00:26+08:00">2022-02-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003011600.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003011600.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>6.8k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>6 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnbceloss"><a class="markdownIt-Anchor" href="#pytorchtorchnnbceloss"></a> Pytorch.torch.nn.BCELoss</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BCELoss</span>(<span class="params">_WeightedLoss</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Creates a criterion that measures the Binary Cross Entropy between the target and</span></span><br><span class="line"><span class="string">    the input probabilities:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The unreduced (i.e. with :attr:`reduction` set to ``&#x27;none&#x27;``) loss can be described as:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \ell(x, y) = L = \&#123;l_1,\dots,l_N\&#125;^\top, \quad</span></span><br><span class="line"><span class="string">        l_n = - w_n \left[ y_n \cdot \log x_n + (1 - y_n) \cdot \log (1 - x_n) \right],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    where :math:`N` is the batch size. If :attr:`reduction` is not ``&#x27;none&#x27;``</span></span><br><span class="line"><span class="string">    (default ``&#x27;mean&#x27;``), then</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \ell(x, y) = \begin&#123;cases&#125;</span></span><br><span class="line"><span class="string">            \operatorname&#123;mean&#125;(L), &amp; \text&#123;if reduction&#125; = \text&#123;`mean&#x27;;&#125;\\</span></span><br><span class="line"><span class="string">            \operatorname&#123;sum&#125;(L),  &amp; \text&#123;if reduction&#125; = \text&#123;`sum&#x27;.&#125;</span></span><br><span class="line"><span class="string">        \end&#123;cases&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    This is used for measuring the error of a reconstruction in for example</span></span><br><span class="line"><span class="string">    an auto-encoder. Note that the targets :math:`y` should be numbers</span></span><br><span class="line"><span class="string">    between 0 and 1.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Notice that if :math:`x_n` is either 0 or 1, one of the log terms would be</span></span><br><span class="line"><span class="string">    mathematically undefined in the above loss equation. PyTorch chooses to set</span></span><br><span class="line"><span class="string">    :math:`\log (0) = -\infty`, since :math:`\lim_&#123;x\to 0&#125; \log (x) = -\infty`.</span></span><br><span class="line"><span class="string">    However, an infinite term in the loss equation is not desirable for several reasons.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For one, if either :math:`y_n = 0` or :math:`(1 - y_n) = 0`, then we would be</span></span><br><span class="line"><span class="string">    multiplying 0 with infinity. Secondly, if we have an infinite loss value, then</span></span><br><span class="line"><span class="string">    we would also have an infinite term in our gradient, since</span></span><br><span class="line"><span class="string">    :math:`\lim_&#123;x\to 0&#125; \frac&#123;d&#125;&#123;dx&#125; \log (x) = \infty`.</span></span><br><span class="line"><span class="string">    This would make BCELoss&#x27;s backward method nonlinear with respect to :math:`x_n`,</span></span><br><span class="line"><span class="string">    and using it for things like linear regression would not be straight-forward.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Our solution is that BCELoss clamps its log function outputs to be greater than</span></span><br><span class="line"><span class="string">    or equal to -100. This way, we can always have a finite loss value and a linear</span></span><br><span class="line"><span class="string">    backward method.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        weight (Tensor, optional): a manual rescaling weight given to the loss</span></span><br><span class="line"><span class="string">            of each batch element. If given, has to be a Tensor of size `nbatch`.</span></span><br><span class="line"><span class="string">        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,</span></span><br><span class="line"><span class="string">            the losses are averaged over each loss element in the batch. Note that for</span></span><br><span class="line"><span class="string">            some losses, there are multiple elements per sample. If the field :attr:`size_average`</span></span><br><span class="line"><span class="string">            is set to ``False``, the losses are instead summed for each minibatch. Ignored</span></span><br><span class="line"><span class="string">            when :attr:`reduce` is ``False``. Default: ``True``</span></span><br><span class="line"><span class="string">        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the</span></span><br><span class="line"><span class="string">            losses are averaged or summed over observations for each minibatch depending</span></span><br><span class="line"><span class="string">            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per</span></span><br><span class="line"><span class="string">            batch element instead and ignores :attr:`size_average`. Default: ``True``</span></span><br><span class="line"><span class="string">        reduction (string, optional): Specifies the reduction to apply to the output:</span></span><br><span class="line"><span class="string">            ``&#x27;none&#x27;`` | ``&#x27;mean&#x27;`` | ``&#x27;sum&#x27;``. ``&#x27;none&#x27;``: no reduction will be applied,</span></span><br><span class="line"><span class="string">            ``&#x27;mean&#x27;``: the sum of the output will be divided by the number of</span></span><br><span class="line"><span class="string">            elements in the output, ``&#x27;sum&#x27;``: the output will be summed. Note: :attr:`size_average`</span></span><br><span class="line"><span class="string">            and :attr:`reduce` are in the process of being deprecated, and in the meantime,</span></span><br><span class="line"><span class="string">            specifying either of those two args will override :attr:`reduction`. Default: ``&#x27;mean&#x27;``</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.</span></span><br><span class="line"><span class="string">        - Target: :math:`(*)`, same shape as the input.</span></span><br><span class="line"><span class="string">        - Output: scalar. If :attr:`reduction` is ``&#x27;none&#x27;``, then :math:`(*)`, same</span></span><br><span class="line"><span class="string">          shape as input.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.Sigmoid()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; loss = nn.BCELoss()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(3, requires_grad=True)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; target = torch.empty(3).random_(2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = loss(m(input), target)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output.backward()</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;reduction&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, weight: Optional[Tensor] = None, size_average=None, reduce=None, reduction: str = <span class="string">&#x27;mean&#x27;</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(BCELoss, self).__init__(weight, size_average, reduce, reduction)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor, target: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)</span><br></pre></td></tr></table></figure><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>BCELoss</mtext></mrow><annotation encoding="application/x-tex">\text{BCELoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">BCELoss</span></span></span></span></span> 为二分类交叉熵损失函数. 损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>BCELoss</mtext></mrow><annotation encoding="application/x-tex">\text{BCELoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">BCELoss</span></span></span></span></span> 其要求标签张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span></span></span></span>, 输入张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span></span></span></span> 均为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">n</span></span></span></span> 维张量, 且 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>×</mo><mo>⋯</mo><mo>×</mo><msub><mi>d</mi><mi>n</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">X,Y\in\R^{d_{1}\times\cdots\times d_{n}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>. 且 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span></span></span></span> 的每个元素取值集合为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{0,1\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">1</span><span class="mclose">}</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span></span></span></span> 的每个元素的取值范围为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0,1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>.</p><p>值得注意的是, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>x</mi><mo>→</mo><msup><mn>0</mn><mo>+</mo></msup></mrow></msub><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">\lim_{x\rightarrow 0^{+}}\log(x)=-\infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop"><span class="mop">lim</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.341865em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mrel mtight">→</span><span class="mord mtight"><span class="mord mtight">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7026642857142857em"><span style="top:-2.786em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.66666em;vertical-align:-.08333em"></span><span class="mord">−</span><span class="mord">∞</span></span></span></span>, 因此实现时将 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><mo>&lt;</mo><mo>−</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">\log{(X)}&lt;-100</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mclose">)</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">−</span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span></span></span></span> 的数变为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>−</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">-100</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">−</span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span></span></span></span>.</p><p>对于标签为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.03588em">y</span></span></span></span>, 预测为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">x</span></span></span></span>, 二分类交叉熵定义如下:</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mo stretchy="false">(</mo><mi>y</mi><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>y</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">l(x,y)=-(y\log {(x)}+(1-y)\log{(1-x)})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.01968em">l</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">−</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">x</span><span class="mclose">)</span></span><span class="mclose">)</span></span></span></span></span></p><h3 id="weight-参数"><a class="markdownIt-Anchor" href="#weight-参数"></a> weight 参数</h3><p><code>weight</code> 参数用于加权每个元素的权重. <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>×</mo><mo>⋯</mo><mo>×</mo><msub><mi>d</mi><mi>n</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">W\in\R^{d_{1}\times\cdots\times d_{n}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72243em;vertical-align:-.0391em"></span><span class="mord mathdefault" style="margin-right:.13889em">W</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h3 id="reduction-参数"><a class="markdownIt-Anchor" href="#reduction-参数"></a> reduction 参数</h3><p><code>reduction</code>: 用于指定计算的模式, <code>'none'</code>, <code>'mean'</code>, <code>'sum'</code> 或 <code>'batchmean'</code>. 默认为 <code>'mean'</code>. 以后 <code>'mean'</code> 的计算过程将与 <code>'batchmean'</code> 相同.</p><div class="post-button"><a class="btn" href="/posts/20211003011600.html#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003011500.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003011500.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.KLDivLoss</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 01:15:00" itemprop="dateCreated datePublished" datetime="2021-10-03T01:15:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-27 19:57:58" itemprop="dateModified" datetime="2022-02-27T19:57:58+08:00">2022-02-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003011500.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003011500.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>7.4k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>7 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnkldivloss"><a class="markdownIt-Anchor" href="#pytorchtorchnnkldivloss"></a> Pytorch.torch.nn.KLDivLoss</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KLDivLoss</span>(<span class="params">_Loss</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;The Kullback-Leibler divergence loss measure</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    `Kullback-Leibler divergence`_ is a useful distance measure for continuous</span></span><br><span class="line"><span class="string">    distributions and is often useful when performing direct regression over</span></span><br><span class="line"><span class="string">    the space of (discretely sampled) continuous output distributions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    As with :class:`~torch.nn.NLLLoss`, the `input` given is expected to contain</span></span><br><span class="line"><span class="string">    *log-probabilities* and is not restricted to a 2D Tensor.</span></span><br><span class="line"><span class="string">    The targets are interpreted as *probabilities* by default, but could be considered</span></span><br><span class="line"><span class="string">    as *log-probabilities* with :attr:`log_target` set to ``True``.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    This criterion expects a `target` `Tensor` of the same size as the</span></span><br><span class="line"><span class="string">    `input` `Tensor`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The unreduced (i.e. with :attr:`reduction` set to ``&#x27;none&#x27;``) loss can be described as:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        l(x,y) = L = \&#123; l_1,\dots,l_N \&#125;, \quad</span></span><br><span class="line"><span class="string">        l_n = y_n \cdot \left( \log y_n - x_n \right)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    where the index :math:`N` spans all dimensions of ``input`` and :math:`L` has the same</span></span><br><span class="line"><span class="string">    shape as ``input``. If :attr:`reduction` is not ``&#x27;none&#x27;`` (default ``&#x27;mean&#x27;``), then:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \ell(x, y) = \begin&#123;cases&#125;</span></span><br><span class="line"><span class="string">            \operatorname&#123;mean&#125;(L), &amp; \text&#123;if reduction&#125; = \text&#123;`mean&#x27;;&#125; \\</span></span><br><span class="line"><span class="string">            \operatorname&#123;sum&#125;(L),  &amp; \text&#123;if reduction&#125; = \text&#123;`sum&#x27;.&#125;</span></span><br><span class="line"><span class="string">        \end&#123;cases&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    In default :attr:`reduction` mode ``&#x27;mean&#x27;``, the losses are averaged for each minibatch over observations</span></span><br><span class="line"><span class="string">    **as well as** over dimensions. ``&#x27;batchmean&#x27;`` mode gives the correct KL divergence where losses</span></span><br><span class="line"><span class="string">    are averaged over batch dimension only. ``&#x27;mean&#x27;`` mode&#x27;s behavior will be changed to the same as</span></span><br><span class="line"><span class="string">    ``&#x27;batchmean&#x27;`` in the next major release.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. _`kullback-leibler divergence`: https://en.wikipedia.org/wiki/Kullback-Leibler_divergence</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,</span></span><br><span class="line"><span class="string">            the losses are averaged over each loss element in the batch. Note that for</span></span><br><span class="line"><span class="string">            some losses, there are multiple elements per sample. If the field :attr:`size_average`</span></span><br><span class="line"><span class="string">            is set to ``False``, the losses are instead summed for each minibatch. Ignored</span></span><br><span class="line"><span class="string">            when :attr:`reduce` is ``False``. Default: ``True``</span></span><br><span class="line"><span class="string">        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the</span></span><br><span class="line"><span class="string">            losses are averaged or summed over observations for each minibatch depending</span></span><br><span class="line"><span class="string">            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per</span></span><br><span class="line"><span class="string">            batch element instead and ignores :attr:`size_average`. Default: ``True``</span></span><br><span class="line"><span class="string">        reduction (string, optional): Specifies the reduction to apply to the output:</span></span><br><span class="line"><span class="string">            ``&#x27;none&#x27;`` | ``&#x27;batchmean&#x27;`` | ``&#x27;sum&#x27;`` | ``&#x27;mean&#x27;``.</span></span><br><span class="line"><span class="string">            ``&#x27;none&#x27;``: no reduction will be applied.</span></span><br><span class="line"><span class="string">            ``&#x27;batchmean&#x27;``: the sum of the output will be divided by batchsize.</span></span><br><span class="line"><span class="string">            ``&#x27;sum&#x27;``: the output will be summed.</span></span><br><span class="line"><span class="string">            ``&#x27;mean&#x27;``: the output will be divided by the number of elements in the output.</span></span><br><span class="line"><span class="string">            Default: ``&#x27;mean&#x27;``</span></span><br><span class="line"><span class="string">        log_target (bool, optional): Specifies whether `target` is passed in the log space.</span></span><br><span class="line"><span class="string">            Default: ``False``</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. note::</span></span><br><span class="line"><span class="string">        :attr:`size_average` and :attr:`reduce` are in the process of being deprecated,</span></span><br><span class="line"><span class="string">        and in the meantime, specifying either of those two args will override :attr:`reduction`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. note::</span></span><br><span class="line"><span class="string">        :attr:`reduction` = ``&#x27;mean&#x27;`` doesn&#x27;t return the true kl divergence value, please use</span></span><br><span class="line"><span class="string">        :attr:`reduction` = ``&#x27;batchmean&#x27;`` which aligns with KL math definition.</span></span><br><span class="line"><span class="string">        In the next major release, ``&#x27;mean&#x27;`` will be changed to be the same as ``&#x27;batchmean&#x27;``.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.</span></span><br><span class="line"><span class="string">        - Target: :math:`(*)`, same shape as the input.</span></span><br><span class="line"><span class="string">        - Output: scalar by default. If :attr:``reduction`` is ``&#x27;none&#x27;``, then :math:`(*)`,</span></span><br><span class="line"><span class="string">          same shape as the input.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;reduction&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, size_average=None, reduce=None, reduction: str = <span class="string">&#x27;mean&#x27;</span>, log_target: bool = False</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(KLDivLoss, self).__init__(size_average, reduce, reduction)</span><br><span class="line">        self.log_target = log_target</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor, target: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.kl_div(input, target, reduction=self.reduction, log_target=self.log_target)</span><br></pre></td></tr></table></figure><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>KLDivLoss</mtext></mrow><annotation encoding="application/x-tex">\text{KLDivLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">KLDivLoss</span></span></span></span></span> 为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>KL</mtext></mrow><annotation encoding="application/x-tex">\text{KL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">KL</span></span></span></span></span> 散度损失函数. 损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>KLDivLoss</mtext></mrow><annotation encoding="application/x-tex">\text{KLDivLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">KLDivLoss</span></span></span></span></span> 其要求标签张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span></span></span></span>, 输入张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span></span></span></span> 均为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.66666em;vertical-align:-.08333em"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 维张量, 且 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub><mo>×</mo><mo>⋯</mo><mo>×</mo><msub><mi>d</mi><mi>n</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">X,Y\in\R^{N\times d_{1}\times\cdots\times d_{n}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.10903em">N</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>. 这里假设 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span></span></span></span> 已经过 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>LogSoftmax</mtext></mrow><annotation encoding="application/x-tex">\text{LogSoftmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">LogSoftmax</span></span></span></span></span> 网络层处理.</p><p>对于真实概率分布 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.13889em">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span> 与预测概率分布 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>, 其 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>KL</mtext></mrow><annotation encoding="application/x-tex">\text{KL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">KL</span></span></span></span></span> 散度定义如下:</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mtext>KL</mtext></msub><mo stretchy="false">(</mo><mi>P</mi><mo>∥</mo><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo></mrow><mo>=</mo><munder><mo>∑</mo><mi>i</mi></munder><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo>=</mo><mi>i</mi><mo stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo>=</mo><mi>i</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mo>−</mo><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mi>Q</mi><mo stretchy="false">(</mo><mi>x</mi><mo>=</mo><mi>i</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">D_{\text{KL}}(P\parallel Q)=\mathbb{E}_{P(x)}\log{(\dfrac{P(x)}{Q(x)})}=\sum_{i}P(x=i)\cdot(\log{(P(x=i))}-\log{(Q(x=i))})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.02778em">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">KL</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.13889em">P</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∥</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault">Q</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-.936em"></span><span class="mord"><span class="mord"><span class="mord mathbb">E</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.13889em">P</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.13889em">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.936em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.327674em;vertical-align:-1.277669em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0500050000000003em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.13889em">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault">i</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.13889em">P</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathdefault">i</span><span class="mclose">)</span><span class="mclose">)</span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault">Q</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathdefault">i</span><span class="mclose">)</span><span class="mclose">)</span></span><span class="mclose">)</span></span></span></span></span></p><h3 id="reduction-参数"><a class="markdownIt-Anchor" href="#reduction-参数"></a> reduction 参数</h3><p><code>reduction</code>: 用于指定计算的模式, <code>'none'</code>, <code>'mean'</code>, <code>'sum'</code> 或 <code>'batchmean'</code>. 默认为 <code>'mean'</code>. 以后 <code>'mean'</code> 的计算过程将与 <code>'batchmean'</code> 相同.</p><p>当 <code>reduction='none'</code> 时, 计算过程如下:</p><p class="katex-block katex-error" title="ParseError: KaTeX parse error: No such environment: subarray at position 166: …matrix}_{\begin{̲s̲u̲b̲a̲r̲r̲a̲y̲}̲{c}0\leq t&lt;N\\0…">\begin{aligned} \text{KLDivLoss}(X,Y)=&amp;\begin{bmatrix} Y_{t,i_{1},\cdots,i_{n}}\cdot(\log{(Y_{t,i_{1},\cdots,i_{n}})}-X_{t,i_{1},\cdots,i_{n}}) \end{bmatrix}_{\begin{subarray}{c}0\leq t&lt;N\\0\leq i_{1}&lt;d_{1}\\\vdots\\0\leq i_{n}&lt;d_{n}\end{subarray}}\\ \end{aligned}\\</p><p>当 <code>reduction='mean'</code> 时, 计算过程如下:</p><div class="post-button"><a class="btn" href="/posts/20211003011500.html#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003011300.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003011300.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.HuberLoss</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 01:13:00" itemprop="dateCreated datePublished" datetime="2021-10-03T01:13:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-27 18:42:42" itemprop="dateModified" datetime="2022-02-27T18:42:42+08:00">2022-02-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003011300.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003011300.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>5.6k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>5 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnhuberloss"><a class="markdownIt-Anchor" href="#pytorchtorchnnhuberloss"></a> Pytorch.torch.nn.HuberLoss</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HuberLoss</span>(<span class="params">_Loss</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Creates a criterion that uses a squared term if the absolute</span></span><br><span class="line"><span class="string">    element-wise error falls below delta and a delta-scaled L1 term otherwise.</span></span><br><span class="line"><span class="string">    This loss combines advantages of both :class:`L1Loss` and :class:`MSELoss`; the</span></span><br><span class="line"><span class="string">    delta-scaled L1 region makes the loss less sensitive to outliers than :class:`MSELoss`,</span></span><br><span class="line"><span class="string">    while the L2 region provides smoothness over :class:`L1Loss` near 0. See</span></span><br><span class="line"><span class="string">    `Huber loss &lt;https://en.wikipedia.org/wiki/Huber_loss&gt;`_ for more information.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For a batch of size :math:`N`, the unreduced loss can be described as:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \ell(x, y) = L = \&#123;l_1, ..., l_N\&#125;^T</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    with</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        l_n = \begin&#123;cases&#125;</span></span><br><span class="line"><span class="string">        0.5 (x_n - y_n)^2, &amp; \text&#123;if &#125; |x_n - y_n| &lt; delta \\</span></span><br><span class="line"><span class="string">        delta * (|x_n - y_n| - 0.5 * delta), &amp; \text&#123;otherwise &#125;</span></span><br><span class="line"><span class="string">        \end&#123;cases&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    If `reduction` is not `none`, then:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \ell(x, y) =</span></span><br><span class="line"><span class="string">        \begin&#123;cases&#125;</span></span><br><span class="line"><span class="string">            \operatorname&#123;mean&#125;(L), &amp;  \text&#123;if reduction&#125; = \text&#123;`mean&#x27;;&#125;\\</span></span><br><span class="line"><span class="string">            \operatorname&#123;sum&#125;(L),  &amp;  \text&#123;if reduction&#125; = \text&#123;`sum&#x27;.&#125;</span></span><br><span class="line"><span class="string">        \end&#123;cases&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. note::</span></span><br><span class="line"><span class="string">        When delta is set to 1, this loss is equivalent to :class:`SmoothL1Loss`.</span></span><br><span class="line"><span class="string">        In general, this loss differs from :class:`SmoothL1Loss` by a factor of delta (AKA beta</span></span><br><span class="line"><span class="string">        in Smooth L1).</span></span><br><span class="line"><span class="string">        See :class:`SmoothL1Loss` for additional discussion on the differences in behavior</span></span><br><span class="line"><span class="string">        between the two losses.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        reduction (string, optional): Specifies the reduction to apply to the output:</span></span><br><span class="line"><span class="string">            ``&#x27;none&#x27;`` | ``&#x27;mean&#x27;`` | ``&#x27;sum&#x27;``. ``&#x27;none&#x27;``: no reduction will be applied,</span></span><br><span class="line"><span class="string">            ``&#x27;mean&#x27;``: the sum of the output will be divided by the number of</span></span><br><span class="line"><span class="string">            elements in the output, ``&#x27;sum&#x27;``: the output will be summed. Default: ``&#x27;mean&#x27;``</span></span><br><span class="line"><span class="string">        delta (float, optional): Specifies the threshold at which to change between delta-scaled L1 and L2 loss.</span></span><br><span class="line"><span class="string">            The value must be positive.  Default: 1.0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(*)` where :math:`*` means any number of dimensions.</span></span><br><span class="line"><span class="string">        - Target: :math:`(*)`, same shape as the input.</span></span><br><span class="line"><span class="string">        - Output: scalar. If :attr:`reduction` is ``&#x27;none&#x27;``, then :math:`(*)`, same shape as the input.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;reduction&#x27;</span>, <span class="string">&#x27;delta&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, reduction: str = <span class="string">&#x27;mean&#x27;</span>, delta: float = <span class="number">1.0</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super().__init__(reduction=reduction)</span><br><span class="line">        self.delta = delta</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor, target: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.huber_loss(input, target, reduction=self.reduction, delta=self.delta)</span><br></pre></td></tr></table></figure><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>SmoothL1Loss</mtext></mrow><annotation encoding="application/x-tex">\text{SmoothL1Loss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">SmoothL1Loss</span></span></span></span></span> 为平滑的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>L1</mtext></mrow><annotation encoding="application/x-tex">\text{L1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">L1</span></span></span></span></span> 损失函数. 损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>SmoothL1Loss</mtext></mrow><annotation encoding="application/x-tex">\text{SmoothL1Loss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">SmoothL1Loss</span></span></span></span></span> 其要求标签张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span></span></span></span>, 输入张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span></span></span></span> 均为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">n</span></span></span></span> 维张量, 且 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>×</mo><mo>⋯</mo><mo>×</mo><msub><mi>d</mi><mi>n</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">X,Y\in\R^{d_{1}\times\cdots\times d_{n}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h3 id="reduction-参数"><a class="markdownIt-Anchor" href="#reduction-参数"></a> reduction 参数</h3><p><code>reduction</code>: 用于指定计算的模式, <code>'none'</code>, <code>'mean'</code> 或 <code>'sum'</code>. 默认为 <code>'mean'</code>.</p><p>当 <code>reduction='none'</code> 时, 计算过程如下:</p><p class="katex-block katex-error" title="ParseError: KaTeX parse error: No such environment: subarray at position 329: …matrix}_{\begin{̲s̲u̲b̲a̲r̲r̲a̲y̲}̲{c}0\leq i_{1}&lt;…">\begin{aligned} \text{SmoothL1Loss}(X,Y)=&amp;\begin{bmatrix}\begin{cases}\dfrac{(X_{i_{1},\cdots,i_{n}}-Y_{i_{1},\cdots,i_{n}})^{2}}{2},&amp;\text{ if }|X_{i_{1},\cdots,i_{n}}-Y_{i_{1},\cdots,i_{n}}|&lt;\delta,\\ \delta(|X_{i_{1},\cdots,i_{n}}-Y_{i_{1},\cdots,i_{n}}|-\dfrac{\delta}{2}),&amp;\text{otherwise}. \end{cases}\end{bmatrix}_{\begin{subarray}{c}0\leq i_{1}&lt;d_{1}\\\vdots\\0\leq i_{n}&lt;d_{n}\end{subarray}}\\ \end{aligned}\\</p><p>当 <code>reduction='mean'</code> 时, 计算过程如下:</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mtext>SmoothL1Loss</mtext><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo stretchy="false">)</mo><mo>=</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow><mfrac><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∑</mo><mrow><msub><mi>i</mi><mn>1</mn></msub><mo>=</mo><mn>0</mn></mrow><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>−</mo><mn>1</mn></mrow></munderover><mo>⋯</mo><munderover><mo>∑</mo><mrow><msub><mi>i</mi><mi>n</mi></msub><mo>=</mo><mn>0</mn></mrow><mrow><msub><mi>d</mi><mi>n</mi></msub><mo>−</mo><mn>1</mn></mrow></munderover><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow><mo stretchy="false">(</mo><msub><mi>X</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>i</mi><mi>n</mi></msub></mrow></msub><mo>−</mo><msub><mi>Y</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>i</mi><mi>n</mi></msub></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><mn>2</mn></mfrac></mstyle><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext> if </mtext><mi mathvariant="normal">∣</mi><msub><mi>X</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>i</mi><mi>n</mi></msub></mrow></msub><mo>−</mo><msub><mi>Y</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>i</mi><mi>n</mi></msub></mrow></msub><mi mathvariant="normal">∣</mi><mo>&lt;</mo><mi>δ</mi><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>δ</mi><mo stretchy="false">(</mo><mi mathvariant="normal">∣</mi><msub><mi>X</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>i</mi><mi>n</mi></msub></mrow></msub><mo>−</mo><msub><mi>Y</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>i</mi><mi>n</mi></msub></mrow></msub><mi mathvariant="normal">∣</mi><mo>−</mo><mstyle displaystyle="true" scriptlevel="0"><mfrac><mi>δ</mi><mn>2</mn></mfrac></mstyle><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>otherwise</mtext><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mstyle><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∏</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>d</mi><mi>t</mi></msub></mstyle></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} \text{SmoothL1Loss}(X,Y)=&amp;\dfrac{\displaystyle\sum_{i_{1}=0}^{d_{1}-1}\cdots\sum_{i_{n}=0}^{d_{n}-1}\begin{bmatrix}\begin{cases}\dfrac{(X_{i_{1},\cdots,i_{n}}-Y_{i_{1},\cdots,i_{n}})^{2}}{2},&amp;\text{ if }|X_{i_{1},\cdots,i_{n}}-Y_{i_{1},\cdots,i_{n}}|&lt;\delta,\\ \delta(|X_{i_{1},\cdots,i_{n}}-Y_{i_{1},\cdots,i_{n}}|-\dfrac{\delta}{2}),&amp;\text{otherwise}. \end{cases}\end{bmatrix}}{\displaystyle\prod_{t=1}^{n}d_{t}}\\ \end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:7.733058000000001em;vertical-align:-3.6165290000000008em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.116529em"><span style="top:-6.116529em"><span class="pstrut" style="height:6.624548000000001em"></span><span class="mord"><span class="mord text"><span class="mord">SmoothL1Loss</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.6165290000000008em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.116529em"><span style="top:-6.116529em"><span class="pstrut" style="height:6.624548000000001em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.624548000000001em"><span style="top:-2.825877em"><span class="pstrut" style="height:4.367274em"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em"><span style="top:-1.882887em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-4.5972740000000005em"><span class="pstrut" style="height:4.367274em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-6.624548000000001em"><span class="pstrut" style="height:4.367274em"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.847213em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.311105em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.377769em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.847213em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.311105em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.377769em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.351015em"><span style="top:-1.9499950000000004em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-3.104995em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.351015em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.850025em"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.367274em"><span style="top:-4.367274em"><span class="pstrut" style="height:4.367274em"></span><span class="mord"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.35002em"><span style="top:-2.19999em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎩</span></span></span><span style="top:-2.19999em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎪</span></span></span><span style="top:-3.1500100000000004em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎨</span></span></span><span style="top:-4.30001em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎪</span></span></span><span style="top:-4.60002em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎧</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.8500199999999998em"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.367274em"><span style="top:-4.367274em"><span class="pstrut" style="height:3.4911079999999997em"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4911079999999999em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">⋯</span><span class="mspace mtight" style="margin-right:.19516666666666668em"></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.22222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">⋯</span><span class="mspace mtight" style="margin-right:.19516666666666668em"></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span></span></span><span style="top:-2.3098339999999995em"><span class="pstrut" style="height:3.4911079999999997em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03785em">δ</span><span class="mopen">(</span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">⋯</span><span class="mspace mtight" style="margin-right:.19516666666666668em"></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.22222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">⋯</span><span class="mspace mtight" style="margin-right:.19516666666666668em"></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03785em">δ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.867274em"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.367274em"><span style="top:-4.367274em"><span class="pstrut" style="height:3.4911079999999997em"></span><span class="mord"><span class="mord text"><span class="mord"> if </span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">⋯</span><span class="mspace mtight" style="margin-right:.19516666666666668em"></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.22222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">⋯</span><span class="mspace mtight" style="margin-right:.19516666666666668em"></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathdefault" style="margin-right:.03785em">δ</span><span class="mpunct">,</span></span></span><span style="top:-2.3098339999999995em"><span class="pstrut" style="height:3.4911079999999997em"></span><span class="mord"><span class="mord text"><span class="mord">otherwise</span></span><span class="mord">.</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.867274em"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.867274em"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.351015em"><span style="top:-1.9499950000000004em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-3.104995em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.351015em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.850025em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.80851em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.6165290000000008em"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>当 <code>reduction='sum'</code> 时, 计算过程如下:</p><div class="post-button"><a class="btn" href="/posts/20211003011300.html#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003011200.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003011200.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.SmoothL1Loss</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 01:12:00" itemprop="dateCreated datePublished" datetime="2021-10-03T01:12:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-27 18:33:24" itemprop="dateModified" datetime="2022-02-27T18:33:24+08:00">2022-02-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003011200.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003011200.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>6.8k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>6 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnsmoothl1loss"><a class="markdownIt-Anchor" href="#pytorchtorchnnsmoothl1loss"></a> Pytorch.torch.nn.SmoothL1Loss</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SmoothL1Loss</span>(<span class="params">_Loss</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Creates a criterion that uses a squared term if the absolute</span></span><br><span class="line"><span class="string">    element-wise error falls below beta and an L1 term otherwise.</span></span><br><span class="line"><span class="string">    It is less sensitive to outliers than :class:`torch.nn.MSELoss` and in some cases</span></span><br><span class="line"><span class="string">    prevents exploding gradients (e.g. see the paper `Fast R-CNN`_ by Ross Girshick).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For a batch of size :math:`N`, the unreduced loss can be described as:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \ell(x, y) = L = \&#123;l_1, ..., l_N\&#125;^T</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    with</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        l_n = \begin&#123;cases&#125;</span></span><br><span class="line"><span class="string">        0.5 (x_n - y_n)^2 / beta, &amp; \text&#123;if &#125; |x_n - y_n| &lt; beta \\</span></span><br><span class="line"><span class="string">        |x_n - y_n| - 0.5 * beta, &amp; \text&#123;otherwise &#125;</span></span><br><span class="line"><span class="string">        \end&#123;cases&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    If `reduction` is not `none`, then:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \ell(x, y) =</span></span><br><span class="line"><span class="string">        \begin&#123;cases&#125;</span></span><br><span class="line"><span class="string">            \operatorname&#123;mean&#125;(L), &amp;  \text&#123;if reduction&#125; = \text&#123;`mean&#x27;;&#125;\\</span></span><br><span class="line"><span class="string">            \operatorname&#123;sum&#125;(L),  &amp;  \text&#123;if reduction&#125; = \text&#123;`sum&#x27;.&#125;</span></span><br><span class="line"><span class="string">        \end&#123;cases&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. note::</span></span><br><span class="line"><span class="string">        Smooth L1 loss can be seen as exactly :class:`L1Loss`, but with the :math:`|x - y| &lt; beta`</span></span><br><span class="line"><span class="string">        portion replaced with a quadratic function such that its slope is 1 at :math:`|x - y| = beta`.</span></span><br><span class="line"><span class="string">        The quadratic segment smooths the L1 loss near :math:`|x - y| = 0`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. note::</span></span><br><span class="line"><span class="string">        Smooth L1 loss is closely related to :class:`HuberLoss`, being</span></span><br><span class="line"><span class="string">        equivalent to :math:`huber(x, y) / beta` (note that Smooth L1&#x27;s beta hyper-parameter is</span></span><br><span class="line"><span class="string">        also known as delta for Huber). This leads to the following differences:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        * As beta -&gt; 0, Smooth L1 loss converges to :class:`L1Loss`, while :class:`HuberLoss`</span></span><br><span class="line"><span class="string">          converges to a constant 0 loss.</span></span><br><span class="line"><span class="string">        * As beta -&gt; :math:`+\infty`, Smooth L1 loss converges to a constant 0 loss, while</span></span><br><span class="line"><span class="string">          :class:`HuberLoss` converges to :class:`MSELoss`.</span></span><br><span class="line"><span class="string">        * For Smooth L1 loss, as beta varies, the L1 segment of the loss has a constant slope of 1.</span></span><br><span class="line"><span class="string">          For :class:`HuberLoss`, the slope of the L1 segment is beta.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. _`Fast R-CNN`: https://arxiv.org/abs/1504.08083</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,</span></span><br><span class="line"><span class="string">            the losses are averaged over each loss element in the batch. Note that for</span></span><br><span class="line"><span class="string">            some losses, there are multiple elements per sample. If the field :attr:`size_average`</span></span><br><span class="line"><span class="string">            is set to ``False``, the losses are instead summed for each minibatch. Ignored</span></span><br><span class="line"><span class="string">            when :attr:`reduce` is ``False``. Default: ``True``</span></span><br><span class="line"><span class="string">        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the</span></span><br><span class="line"><span class="string">            losses are averaged or summed over observations for each minibatch depending</span></span><br><span class="line"><span class="string">            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per</span></span><br><span class="line"><span class="string">            batch element instead and ignores :attr:`size_average`. Default: ``True``</span></span><br><span class="line"><span class="string">        reduction (string, optional): Specifies the reduction to apply to the output:</span></span><br><span class="line"><span class="string">            ``&#x27;none&#x27;`` | ``&#x27;mean&#x27;`` | ``&#x27;sum&#x27;``. ``&#x27;none&#x27;``: no reduction will be applied,</span></span><br><span class="line"><span class="string">            ``&#x27;mean&#x27;``: the sum of the output will be divided by the number of</span></span><br><span class="line"><span class="string">            elements in the output, ``&#x27;sum&#x27;``: the output will be summed. Note: :attr:`size_average`</span></span><br><span class="line"><span class="string">            and :attr:`reduce` are in the process of being deprecated, and in the meantime,</span></span><br><span class="line"><span class="string">            specifying either of those two args will override :attr:`reduction`. Default: ``&#x27;mean&#x27;``</span></span><br><span class="line"><span class="string">        beta (float, optional): Specifies the threshold at which to change between L1 and L2 loss.</span></span><br><span class="line"><span class="string">            The value must be non-negative. Default: 1.0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.</span></span><br><span class="line"><span class="string">        - Target: :math:`(*)`, same shape as the input.</span></span><br><span class="line"><span class="string">        - Output: scalar. If :attr:`reduction` is ``&#x27;none&#x27;``, then :math:`(*)`, same shape as the input.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;reduction&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, size_average=None, reduce=None, reduction: str = <span class="string">&#x27;mean&#x27;</span>, beta: float = <span class="number">1.0</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(SmoothL1Loss, self).__init__(size_average, reduce, reduction)</span><br><span class="line">        self.beta = beta</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor, target: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)</span><br></pre></td></tr></table></figure><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>SmoothL1Loss</mtext></mrow><annotation encoding="application/x-tex">\text{SmoothL1Loss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">SmoothL1Loss</span></span></span></span></span> 为平滑的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>L1</mtext></mrow><annotation encoding="application/x-tex">\text{L1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">L1</span></span></span></span></span> 损失函数. 损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>SmoothL1Loss</mtext></mrow><annotation encoding="application/x-tex">\text{SmoothL1Loss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord text"><span class="mord">SmoothL1Loss</span></span></span></span></span> 其要求标签张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span></span></span></span>, 输入张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span></span></span></span> 均为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">n</span></span></span></span> 维张量, 且 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>×</mo><mo>⋯</mo><mo>×</mo><msub><mi>d</mi><mi>n</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">X,Y\in\R^{d_{1}\times\cdots\times d_{n}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h3 id="reduction-参数"><a class="markdownIt-Anchor" href="#reduction-参数"></a> reduction 参数</h3><p><code>reduction</code>: 用于指定计算的模式, <code>'none'</code>, <code>'mean'</code> 或 <code>'sum'</code>. 默认为 <code>'mean'</code>.</p><p>当 <code>reduction='none'</code> 时, 计算过程如下:</p><p class="katex-block katex-error" title="ParseError: KaTeX parse error: No such environment: subarray at position 324: …matrix}_{\begin{̲s̲u̲b̲a̲r̲r̲a̲y̲}̲{c}0\leq i_{1}&lt;…">\begin{aligned} \text{SmoothL1Loss}(X,Y)=&amp;\begin{bmatrix}\begin{cases}\dfrac{(X_{i_{1},\cdots,i_{n}}-Y_{i_{1},\cdots,i_{n}})^{2}}{2\beta},&amp;\text{ if }|X_{i_{1},\cdots,i_{n}}-Y_{i_{1},\cdots,i_{n}}|&lt;\beta,\\ |X_{i_{1},\cdots,i_{n}}-Y_{i_{1},\cdots,i_{n}}|-\dfrac{\beta}{2},&amp;\text{otherwise}. \end{cases}\end{bmatrix}_{\begin{subarray}{c}0\leq i_{1}&lt;d_{1}\\\vdots\\0\leq i_{n}&lt;d_{n}\end{subarray}}\\ \end{aligned}\\</p><p>当 <code>reduction='mean'</code> 时, 计算过程如下:</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mtext>SmoothL1Loss</mtext><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo stretchy="false">)</mo><mo>=</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow><mfrac><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∑</mo><mrow><msub><mi>i</mi><mn>1</mn></msub><mo>=</mo><mn>0</mn></mrow><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>−</mo><mn>1</mn></mrow></munderover><mo>⋯</mo><munderover><mo>∑</mo><mrow><msub><mi>i</mi><mi>n</mi></msub><mo>=</mo><mn>0</mn></mrow><mrow><msub><mi>d</mi><mi>n</mi></msub><mo>−</mo><mn>1</mn></mrow></munderover><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow><mo stretchy="false">(</mo><msub><mi>X</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>i</mi><mi>n</mi></msub></mrow></msub><mo>−</mo><msub><mi>Y</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>i</mi><mi>n</mi></msub></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><mrow><mn>2</mn><mi>β</mi></mrow></mfrac></mstyle><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext> if </mtext><mi mathvariant="normal">∣</mi><msub><mi>X</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>i</mi><mi>n</mi></msub></mrow></msub><mo>−</mo><msub><mi>Y</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>i</mi><mi>n</mi></msub></mrow></msub><mi mathvariant="normal">∣</mi><mo>&lt;</mo><mi>β</mi><mo separator="true">,</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi mathvariant="normal">∣</mi><msub><mi>X</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>i</mi><mi>n</mi></msub></mrow></msub><mo>−</mo><msub><mi>Y</mi><mrow><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>i</mi><mi>n</mi></msub></mrow></msub><mi mathvariant="normal">∣</mi><mo>−</mo><mstyle displaystyle="true" scriptlevel="0"><mfrac><mi>β</mi><mn>2</mn></mfrac></mstyle><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>otherwise</mtext><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable></mrow></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mstyle><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∏</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>d</mi><mi>t</mi></msub></mstyle></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} \text{SmoothL1Loss}(X,Y)=&amp;\dfrac{\displaystyle\sum_{i_{1}=0}^{d_{1}-1}\cdots\sum_{i_{n}=0}^{d_{n}-1}\begin{bmatrix}\begin{cases}\dfrac{(X_{i_{1},\cdots,i_{n}}-Y_{i_{1},\cdots,i_{n}})^{2}}{2\beta},&amp;\text{ if }|X_{i_{1},\cdots,i_{n}}-Y_{i_{1},\cdots,i_{n}}|&lt;\beta,\\ |X_{i_{1},\cdots,i_{n}}-Y_{i_{1},\cdots,i_{n}}|-\dfrac{\beta}{2},&amp;\text{otherwise}. \end{cases}\end{bmatrix}}{\displaystyle\prod_{t=1}^{n}d_{t}}\\ \end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:7.927497999999999em;vertical-align:-3.713748999999999em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.213749em"><span style="top:-6.213749em"><span class="pstrut" style="height:6.818987999999999em"></span><span class="mord"><span class="mord text"><span class="mord">SmoothL1Loss</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.713748999999999em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.213749em"><span style="top:-6.213749em"><span class="pstrut" style="height:6.818987999999999em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.818987999999999em"><span style="top:-2.9230970000000003em"><span class="pstrut" style="height:4.464494em"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em"><span style="top:-1.882887em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-4.694494000000001em"><span class="pstrut" style="height:4.464494em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-6.818988000000001em"><span class="pstrut" style="height:4.464494em"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.847213em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.311105em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.377769em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.847213em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.311105em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.377769em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.351015em"><span style="top:-1.9499950000000004em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-3.104995em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.351015em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.850025em"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.4644939999999997em"><span style="top:-4.464494em"><span class="pstrut" style="height:4.464493999999999em"></span><span class="mord"><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.35002em"><span style="top:-2.19999em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎩</span></span></span><span style="top:-2.19999em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎪</span></span></span><span style="top:-3.1500100000000004em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎨</span></span></span><span style="top:-4.30001em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎪</span></span></span><span style="top:-4.60002em"><span class="pstrut" style="height:3.15em"></span><span class="delimsizinginner delim-size4"><span>⎧</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.8500199999999998em"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.4644939999999993em"><span style="top:-4.464493999999999em"><span class="pstrut" style="height:3.4911079999999997em"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4911079999999999em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span><span class="mord mathdefault" style="margin-right:.05278em">β</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">⋯</span><span class="mspace mtight" style="margin-right:.19516666666666668em"></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.22222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">⋯</span><span class="mspace mtight" style="margin-right:.19516666666666668em"></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8804400000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span></span></span><span style="top:-2.2126139999999994em"><span class="pstrut" style="height:3.4911079999999997em"></span><span class="mord"><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">⋯</span><span class="mspace mtight" style="margin-right:.19516666666666668em"></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.22222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">⋯</span><span class="mspace mtight" style="margin-right:.19516666666666668em"></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714399999999998em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.05278em">β</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.9644940000000002em"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.4644939999999993em"><span style="top:-4.464493999999999em"><span class="pstrut" style="height:3.4911079999999997em"></span><span class="mord"><span class="mord text"><span class="mord"> if </span></span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.07847em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">⋯</span><span class="mspace mtight" style="margin-right:.19516666666666668em"></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.22222em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="minner mtight">⋯</span><span class="mspace mtight" style="margin-right:.19516666666666668em"></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mord mathdefault" style="margin-right:.05278em">β</span><span class="mpunct">,</span></span></span><span style="top:-2.2126139999999994em"><span class="pstrut" style="height:3.4911079999999997em"></span><span class="mord"><span class="mord text"><span class="mord">otherwise</span></span><span class="mord">.</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.9644940000000002em"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.9644939999999997em"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.351015em"><span style="top:-1.9499950000000004em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-3.104995em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.351015em"><span class="pstrut" style="height:3.1550000000000002em"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.850025em"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.80851em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.713748999999999em"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>当 <code>reduction='sum'</code> 时, 计算过程如下:</p><div class="post-button"><a class="btn" href="/posts/20211003011200.html#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003011100.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003011100.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.GaussianNLLLoss</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 01:11:00" itemprop="dateCreated datePublished" datetime="2021-10-03T01:11:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-27 18:33:56" itemprop="dateModified" datetime="2022-02-27T18:33:56+08:00">2022-02-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003011100.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003011100.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>8.3k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>8 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnngaussiannllloss"><a class="markdownIt-Anchor" href="#pytorchtorchnngaussiannllloss"></a> Pytorch.torch.nn.GaussianNLLLoss</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GaussianNLLLoss</span>(<span class="params">_Loss</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Gaussian negative log likelihood loss.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The targets are treated as samples from Gaussian distributions with</span></span><br><span class="line"><span class="string">    expectations and variances predicted by the neural network. For a</span></span><br><span class="line"><span class="string">    ``target`` tensor modelled as having Gaussian distribution with a tensor</span></span><br><span class="line"><span class="string">    of expectations ``input`` and a tensor of positive variances ``var`` the loss is:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \text&#123;loss&#125; = \frac&#123;1&#125;&#123;2&#125;\left(\log\left(\text&#123;max&#125;\left(\text&#123;var&#125;,</span></span><br><span class="line"><span class="string">        \ \text&#123;eps&#125;\right)\right) + \frac&#123;\left(\text&#123;input&#125; - \text&#123;target&#125;\right)^2&#125;</span></span><br><span class="line"><span class="string">        &#123;\text&#123;max&#125;\left(\text&#123;var&#125;, \ \text&#123;eps&#125;\right)&#125;\right) + \text&#123;const.&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    where :attr:`eps` is used for stability. By default, the constant term of</span></span><br><span class="line"><span class="string">    the loss function is omitted unless :attr:`full` is ``True``. If ``var`` is not the same</span></span><br><span class="line"><span class="string">    size as ``input`` (due to a homoscedastic assumption), it must either have a final dimension</span></span><br><span class="line"><span class="string">    of 1 or have one fewer dimension (with all other sizes being the same) for correct broadcasting.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        full (bool, optional): include the constant term in the loss</span></span><br><span class="line"><span class="string">            calculation. Default: ``False``.</span></span><br><span class="line"><span class="string">        eps (float, optional): value used to clamp ``var`` (see note below), for</span></span><br><span class="line"><span class="string">            stability. Default: 1e-6.</span></span><br><span class="line"><span class="string">        reduction (string, optional): specifies the reduction to apply to the</span></span><br><span class="line"><span class="string">            output:``&#x27;none&#x27;`` | ``&#x27;mean&#x27;`` | ``&#x27;sum&#x27;``. ``&#x27;none&#x27;``: no reduction</span></span><br><span class="line"><span class="string">            will be applied, ``&#x27;mean&#x27;``: the output is the average of all batch</span></span><br><span class="line"><span class="string">            member losses, ``&#x27;sum&#x27;``: the output is the sum of all batch member</span></span><br><span class="line"><span class="string">            losses. Default: ``&#x27;mean&#x27;``.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, *)` where :math:`*` means any number of additional</span></span><br><span class="line"><span class="string">          dimensions</span></span><br><span class="line"><span class="string">        - Target: :math:`(N, *)`, same shape as the input, or same shape as the input</span></span><br><span class="line"><span class="string">          but with one dimension equal to 1 (to allow for broadcasting)</span></span><br><span class="line"><span class="string">        - Var: :math:`(N, *)`, same shape as the input, or same shape as the input but</span></span><br><span class="line"><span class="string">          with one dimension equal to 1, or same shape as the input but with one fewer</span></span><br><span class="line"><span class="string">          dimension (to allow for broadcasting)</span></span><br><span class="line"><span class="string">        - Output: scalar if :attr:`reduction` is ``&#x27;mean&#x27;`` (default) or</span></span><br><span class="line"><span class="string">          ``&#x27;sum&#x27;``. If :attr:`reduction` is ``&#x27;none&#x27;``, then :math:`(N, *)`, same</span></span><br><span class="line"><span class="string">          shape as the input</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; loss = nn.GaussianNLLLoss()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(5, 2, requires_grad=True)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; target = torch.randn(5, 2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; var = torch.ones(5, 2, requires_grad=True) #heteroscedastic</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = loss(input, target, var)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output.backward()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; loss = nn.GaussianNLLLoss()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(5, 2, requires_grad=True)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; target = torch.randn(5, 2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; var = torch.ones(5, 1, requires_grad=True) #homoscedastic</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = loss(input, target, var)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output.backward()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note:</span></span><br><span class="line"><span class="string">        The clamping of ``var`` is ignored with respect to autograd, and so the</span></span><br><span class="line"><span class="string">        gradients are unaffected by it.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">        Nix, D. A. and Weigend, A. S., &quot;Estimating the mean and variance of the</span></span><br><span class="line"><span class="string">        target probability distribution&quot;, Proceedings of 1994 IEEE International</span></span><br><span class="line"><span class="string">        Conference on Neural Networks (ICNN&#x27;94), Orlando, FL, USA, 1994, pp. 55-60</span></span><br><span class="line"><span class="string">        vol.1, doi: 10.1109/ICNN.1994.374138.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;full&#x27;</span>, <span class="string">&#x27;eps&#x27;</span>, <span class="string">&#x27;reduction&#x27;</span>]</span><br><span class="line">    full: bool</span><br><span class="line">    eps: float</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *, full: bool = False, eps: float = <span class="number">1e-6</span>, reduction: str = <span class="string">&#x27;mean&#x27;</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(GaussianNLLLoss, self).__init__(<span class="literal">None</span>, <span class="literal">None</span>, reduction)</span><br><span class="line">        self.full = full</span><br><span class="line">        self.eps = eps</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor, target: Tensor, var: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.gaussian_nll_loss(input, target, var, full=self.full, eps=self.eps, reduction=self.reduction)</span><br></pre></td></tr></table></figure><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>GaussianNLLLoss</mtext></mrow><annotation encoding="application/x-tex">\text{GaussianNLLLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">GaussianNLLLoss</span></span></span></span></span> 为真实标签服从正态分布的负对数似然损失函数.</p><p>对于随机变量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.03588em">y</span></span></span></span>, 假设其服从正态分布, 则</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>y</mi><mo separator="true">;</mo><mi>μ</mi><mo separator="true">,</mo><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mi>π</mi></mrow></msqrt><mi>σ</mi></mrow></mfrac><mi>exp</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mo>−</mo><mfrac><mrow><mo stretchy="false">(</mo><mi>y</mi><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><mrow><mn>2</mn><msup><mi>σ</mi><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(y;\mu,\sigma^{2})=\dfrac{1}{\sqrt{2\pi}\sigma}\exp{(-\dfrac{(y-\mu)^{2}}{2\sigma^{2}})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="mpunct">;</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault">μ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.4211080000000003em;vertical-align:-.93em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.2027799999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.90722em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord">2</span><span class="mord mathdefault" style="margin-right:.03588em">π</span></span></span><span style="top:-2.86722em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,
-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,
-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,
35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,
-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467
s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422
s-65,47,-65,47z M834 80H400000v40H845z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.13278em"><span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:.03588em">σ</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">exp</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.491108em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></span></p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>f</mi><mo stretchy="false">(</mo><mi>y</mi><mo separator="true">;</mo><mi>μ</mi><mo separator="true">,</mo><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mo>=</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow><mo>−</mo><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mfrac><mn>1</mn><mrow><msqrt><mrow><mn>2</mn><mi>π</mi></mrow></msqrt><mi>σ</mi></mrow></mfrac><mi>exp</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mo>−</mo><mfrac><mrow><mo stretchy="false">(</mo><mi>y</mi><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><mrow><mn>2</mn><msup><mi>σ</mi><mn>2</mn></msup></mrow></mfrac><mo stretchy="false">)</mo></mrow><mo stretchy="false">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mo>=</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mn>2</mn><mi>π</mi><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><mo>+</mo><mfrac><mrow><mo stretchy="false">(</mo><mi>y</mi><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><mrow><mn>2</mn><msup><mi>σ</mi><mn>2</mn></msup></mrow></mfrac></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mo>=</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><mo>+</mo><mfrac><mrow><mo stretchy="false">(</mo><mi>y</mi><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><msup><mi>σ</mi><mn>2</mn></msup></mfrac><mo stretchy="false">)</mo><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>2</mn><mi>π</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} -\log f(y;\mu,\sigma^{2})=&amp;-\log{(\dfrac{1}{\sqrt{2\pi}\sigma}\exp{(-\dfrac{(y-\mu)^{2}}{2\sigma^{2}})})}\\ =&amp;\frac{1}{2}\log{(2\pi\sigma^{2})} +\dfrac{(y-\mu)^{2}}{2\sigma^{2}}\\ =&amp;\dfrac{1}{2}(\log{(\sigma^{2})}+\dfrac{(y-\mu)^{2}}{\sigma^{2}})+\dfrac{1}{2}\log(2\pi) \end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:7.675324em;vertical-align:-3.587662em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.087662em"><span style="top:-6.087662em"><span class="pstrut" style="height:3.491108em"></span><span class="mord"><span class="mord">−</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="mpunct">;</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault">μ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span></span></span><span style="top:-3.366554em"><span class="pstrut" style="height:3.491108em"></span><span class="mord"><span class="mrel">=</span></span></span><span style="top:-.8894460000000003em"><span class="pstrut" style="height:3.491108em"></span><span class="mord"><span class="mrel">=</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.587662em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.087662em"><span style="top:-6.087662em"><span class="pstrut" style="height:3.491108em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.2027799999999997em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.90722em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord">2</span><span class="mord mathdefault" style="margin-right:.03588em">π</span></span></span><span style="top:-2.86722em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,
-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,
-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,
35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,
-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467
s-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422
s-65,47,-65,47z M834 80H400000v40H845z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.13278em"><span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:.03588em">σ</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">exp</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.491108em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span><span class="mclose">)</span></span></span></span><span style="top:-3.366554em"><span class="pstrut" style="height:3.491108em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord">2</span><span class="mord mathdefault" style="margin-right:.03588em">π</span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.491108em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-.8894460000000003em"><span class="pstrut" style="height:3.491108em"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.491108em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathdefault">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mopen">(</span><span class="mord">2</span><span class="mord mathdefault" style="margin-right:.03588em">π</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.587662em"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>GaussianNLLLoss</mtext></mrow><annotation encoding="application/x-tex">\text{GaussianNLLLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">GaussianNLLLoss</span></span></span></span></span> 其要求标签张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span></span></span></span>, 均值张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span></span></span></span>, 方差张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">V</span></span></span></span> 均为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">n</span></span></span></span> 维张量, 且 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo separator="true">,</mo><mi>V</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>×</mo><mo>⋯</mo><mo>×</mo><msub><mi>d</mi><mi>n</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">X,Y,V\in\R^{d_{1}\times\cdots\times d_{n}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">V</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>.(对于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">V</span></span></span></span> 可以允许其为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.66666em;vertical-align:-.08333em"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 维张量, 计算时进行广播操作, 这里就不做考虑).</p><h3 id="reduction-参数"><a class="markdownIt-Anchor" href="#reduction-参数"></a> reduction 参数</h3><p><code>reduction</code>: 用于指定计算的模式, <code>'none'</code>, <code>'mean'</code> 或 <code>'sum'</code>. 默认为 <code>'mean'</code>.</p><p>当 <code>reduction='none'</code> 时, 计算过程如下:</p><div class="post-button"><a class="btn" href="/posts/20211003011100.html#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003011000.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003011000.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.PoissonNLLLoss</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 01:10:00" itemprop="dateCreated datePublished" datetime="2021-10-03T01:10:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-27 18:33:14" itemprop="dateModified" datetime="2022-02-27T18:33:14+08:00">2022-02-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003011000.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003011000.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>8.9k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>8 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnpoissonnllloss"><a class="markdownIt-Anchor" href="#pytorchtorchnnpoissonnllloss"></a> Pytorch.torch.nn.PoissonNLLLoss</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PoissonNLLLoss</span>(<span class="params">_Loss</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Negative log likelihood loss with Poisson distribution of target.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The loss can be described as:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \text&#123;target&#125; \sim \mathrm&#123;Poisson&#125;(\text&#123;input&#125;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        \text&#123;loss&#125;(\text&#123;input&#125;, \text&#123;target&#125;) = \text&#123;input&#125; - \text&#123;target&#125; * \log(\text&#123;input&#125;)</span></span><br><span class="line"><span class="string">                                    + \log(\text&#123;target!&#125;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The last term can be omitted or approximated with Stirling formula. The</span></span><br><span class="line"><span class="string">    approximation is used for target values more than 1. For targets less or</span></span><br><span class="line"><span class="string">    equal to 1 zeros are added to the loss.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        log_input (bool, optional): if ``True`` the loss is computed as</span></span><br><span class="line"><span class="string">            :math:`\exp(\text&#123;input&#125;) - \text&#123;target&#125;*\text&#123;input&#125;`, if ``False`` the loss is</span></span><br><span class="line"><span class="string">            :math:`\text&#123;input&#125; - \text&#123;target&#125;*\log(\text&#123;input&#125;+\text&#123;eps&#125;)`.</span></span><br><span class="line"><span class="string">        full (bool, optional): whether to compute full loss, i. e. to add the</span></span><br><span class="line"><span class="string">            Stirling approximation term</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            .. math::</span></span><br><span class="line"><span class="string">                \text&#123;target&#125;*\log(\text&#123;target&#125;) - \text&#123;target&#125; + 0.5 * \log(2\pi\text&#123;target&#125;).</span></span><br><span class="line"><span class="string">        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,</span></span><br><span class="line"><span class="string">            the losses are averaged over each loss element in the batch. Note that for</span></span><br><span class="line"><span class="string">            some losses, there are multiple elements per sample. If the field :attr:`size_average`</span></span><br><span class="line"><span class="string">            is set to ``False``, the losses are instead summed for each minibatch. Ignored</span></span><br><span class="line"><span class="string">            when :attr:`reduce` is ``False``. Default: ``True``</span></span><br><span class="line"><span class="string">        eps (float, optional): Small value to avoid evaluation of :math:`\log(0)` when</span></span><br><span class="line"><span class="string">            :attr:`log_input = False`. Default: 1e-8</span></span><br><span class="line"><span class="string">        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the</span></span><br><span class="line"><span class="string">            losses are averaged or summed over observations for each minibatch depending</span></span><br><span class="line"><span class="string">            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per</span></span><br><span class="line"><span class="string">            batch element instead and ignores :attr:`size_average`. Default: ``True``</span></span><br><span class="line"><span class="string">        reduction (string, optional): Specifies the reduction to apply to the output:</span></span><br><span class="line"><span class="string">            ``&#x27;none&#x27;`` | ``&#x27;mean&#x27;`` | ``&#x27;sum&#x27;``. ``&#x27;none&#x27;``: no reduction will be applied,</span></span><br><span class="line"><span class="string">            ``&#x27;mean&#x27;``: the sum of the output will be divided by the number of</span></span><br><span class="line"><span class="string">            elements in the output, ``&#x27;sum&#x27;``: the output will be summed. Note: :attr:`size_average`</span></span><br><span class="line"><span class="string">            and :attr:`reduce` are in the process of being deprecated, and in the meantime,</span></span><br><span class="line"><span class="string">            specifying either of those two args will override :attr:`reduction`. Default: ``&#x27;mean&#x27;``</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; loss = nn.PoissonNLLLoss()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; log_input = torch.randn(5, 2, requires_grad=True)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; target = torch.randn(5, 2)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = loss(log_input, target)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output.backward()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(*)`, where :math:`*` means any number of dimensions.</span></span><br><span class="line"><span class="string">        - Target: :math:`(*)`, same shape as the input.</span></span><br><span class="line"><span class="string">        - Output: scalar by default. If :attr:`reduction` is ``&#x27;none&#x27;``, then :math:`(*)`,</span></span><br><span class="line"><span class="string">          the same shape as the input.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;log_input&#x27;</span>, <span class="string">&#x27;full&#x27;</span>, <span class="string">&#x27;eps&#x27;</span>, <span class="string">&#x27;reduction&#x27;</span>]</span><br><span class="line">    log_input: bool</span><br><span class="line">    full: bool</span><br><span class="line">    eps: float</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, log_input: bool = True, full: bool = False, size_average=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 eps: float = <span class="number">1e-8</span>, reduce=None, reduction: str = <span class="string">&#x27;mean&#x27;</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(PoissonNLLLoss, self).__init__(size_average, reduce, reduction)</span><br><span class="line">        self.log_input = log_input</span><br><span class="line">        self.full = full</span><br><span class="line">        self.eps = eps</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, log_input: Tensor, target: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.poisson_nll_loss(log_input, target, log_input=self.log_input, full=self.full,</span><br><span class="line">                                  eps=self.eps, reduction=self.reduction)</span><br></pre></td></tr></table></figure><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>PoissonNLLLoss</mtext></mrow><annotation encoding="application/x-tex">\text{PoissonNLLLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">PoissonNLLLoss</span></span></span></span></span> 为真实标签服从泊松分布的负对数似然损失函数.</p><p>对于随机变量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.03588em">y</span></span></span></span>, 假设其服从泊松分布, 则</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>y</mi><mo>=</mo><mi>k</mi><mo separator="true">;</mo><mi>λ</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi>λ</mi><mi>k</mi></msup><mrow><mi>k</mi><mo stretchy="false">!</mo></mrow></mfrac><mi>exp</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mo>−</mo><mi>λ</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(y=k;\lambda)=\dfrac{\lambda^{k}}{k!}\exp{(-\lambda)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.13889em">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathdefault" style="margin-right:.03148em">k</span><span class="mpunct">;</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault">λ</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.212108em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.526108em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.03148em">k</span><span class="mclose">!</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.03148em">k</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">exp</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen">(</span><span class="mord">−</span><span class="mord mathdefault">λ</span><span class="mclose">)</span></span></span></span></span></span></p><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>PoissonNLLLoss</mtext></mrow><annotation encoding="application/x-tex">\text{PoissonNLLLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">PoissonNLLLoss</span></span></span></span></span> 其要求输入张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span></span></span></span> 与标签张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span></span></span></span> 均为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathdefault">n</span></span></span></span> 维张量, 且 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msub><mi>d</mi><mn>1</mn></msub><mo>×</mo><mo>⋯</mo><mo>×</mo><msub><mi>d</mi><mi>n</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">X,Y\in\R^{d_{1}\times\cdots\times d_{n}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><h3 id="reduction-参数"><a class="markdownIt-Anchor" href="#reduction-参数"></a> reduction 参数</h3><p><code>reduction</code>: 用于指定计算的模式, <code>'none'</code>, <code>'mean'</code> 或 <code>'sum'</code>. 默认为 <code>'mean'</code>.</p><p>当 <code>reduction='none'</code> 时, 计算过程如下:</p><p class="katex-block katex-error" title="ParseError: KaTeX parse error: No such environment: subarray at position 148: …matrix}_{\begin{̲s̲u̲b̲a̲r̲r̲a̲y̲}̲{c}0\leq i_{1}&lt;…">\begin{aligned} \text{PoissonNLLLoss}(X,Y)=&amp;\begin{bmatrix}-\log{(P(y=Y_{i_{1},\cdots,i_{n}};\lambda=X_{i_{1},\cdots,i_{n}}))}\end{bmatrix}_{\begin{subarray}{c}0\leq i_{1}&lt;d_{1}\\\vdots\\0\leq i_{n}&lt;d_{n}\end{subarray}}\\ =&amp;\begin{bmatrix}-\log{(\dfrac{X_{i_{1},\cdots,i_{n}}^{Y_{i_{1},\cdots,i_{n}}}}{Y_{i_{1},\cdots,i_{n}}!}\exp{(-X_{i_{1},\cdots,i_{n}})})}\end{bmatrix}_{\begin{subarray}{c}0\leq i_{1}&lt;d_{1}\\\vdots\\0\leq i_{n}&lt;d_{n}\end{subarray}}\\ =&amp;\begin{bmatrix}X_{i_{1},\cdots,i_{n}}-Y_{i_{1},\cdots,i_{n}}\log{(X_{i_{1},\cdots,i_{n}})}+\log{(Y_{i_{1},\cdots,i_{n}}!)}\end{bmatrix}_{\begin{subarray}{c}0\leq i_{1}&lt;d_{1}\\\vdots\\0\leq i_{n}&lt;d_{n}\end{subarray}}\\ \end{aligned}</p><div class="post-button"><a class="btn" href="/posts/20211003011000.html#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003010900.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003010900.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.NLLLoss</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 01:09:00" itemprop="dateCreated datePublished" datetime="2021-10-03T01:09:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-02-27 10:41:22" itemprop="dateModified" datetime="2022-02-27T10:41:22+08:00">2022-02-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003010900.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003010900.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>10k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>9 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnnnllloss"><a class="markdownIt-Anchor" href="#pytorchtorchnnnllloss"></a> Pytorch.torch.nn.NLLLoss</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NLLLoss</span>(<span class="params">_WeightedLoss</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;The negative log likelihood loss. It is useful to train a classification</span></span><br><span class="line"><span class="string">    problem with `C` classes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    If provided, the optional argument :attr:`weight` should be a 1D Tensor assigning</span></span><br><span class="line"><span class="string">    weight to each of the classes. This is particularly useful when you have an</span></span><br><span class="line"><span class="string">    unbalanced training set.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The `input` given through a forward call is expected to contain</span></span><br><span class="line"><span class="string">    log-probabilities of each class. `input` has to be a Tensor of size either</span></span><br><span class="line"><span class="string">    :math:`(minibatch, C)` or :math:`(minibatch, C, d_1, d_2, ..., d_K)`</span></span><br><span class="line"><span class="string">    with :math:`K \geq 1` for the `K`-dimensional case. The latter is useful for</span></span><br><span class="line"><span class="string">    higher dimension inputs, such as computing NLL loss per-pixel for 2D images.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Obtaining log-probabilities in a neural network is easily achieved by</span></span><br><span class="line"><span class="string">    adding a  `LogSoftmax`  layer in the last layer of your network.</span></span><br><span class="line"><span class="string">    You may use `CrossEntropyLoss` instead, if you prefer not to add an extra</span></span><br><span class="line"><span class="string">    layer.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The `target` that this loss expects should be a class index in the range :math:`[0, C-1]`</span></span><br><span class="line"><span class="string">    where `C = number of classes`; if `ignore_index` is specified, this loss also accepts</span></span><br><span class="line"><span class="string">    this class index (this index may not necessarily be in the class range).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The unreduced (i.e. with :attr:`reduction` set to ``&#x27;none&#x27;``) loss can be described as:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \ell(x, y) = L = \&#123;l_1,\dots,l_N\&#125;^\top, \quad</span></span><br><span class="line"><span class="string">        l_n = - w_&#123;y_n&#125; x_&#123;n,y_n&#125;, \quad</span></span><br><span class="line"><span class="string">        w_&#123;c&#125; = \text&#123;weight&#125;[c] \cdot \mathbb&#123;1&#125;\&#123;c \not= \text&#123;ignore\_index&#125;\&#125;,</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight, and</span></span><br><span class="line"><span class="string">    :math:`N` is the batch size. If :attr:`reduction` is not ``&#x27;none&#x27;``</span></span><br><span class="line"><span class="string">    (default ``&#x27;mean&#x27;``), then</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \ell(x, y) = \begin&#123;cases&#125;</span></span><br><span class="line"><span class="string">            \sum_&#123;n=1&#125;^N \frac&#123;1&#125;&#123;\sum_&#123;n=1&#125;^N w_&#123;y_n&#125;&#125; l_n, &amp;</span></span><br><span class="line"><span class="string">            \text&#123;if reduction&#125; = \text&#123;`mean&#x27;;&#125;\\</span></span><br><span class="line"><span class="string">            \sum_&#123;n=1&#125;^N l_n,  &amp;</span></span><br><span class="line"><span class="string">            \text&#123;if reduction&#125; = \text&#123;`sum&#x27;.&#125;</span></span><br><span class="line"><span class="string">        \end&#123;cases&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        weight (Tensor, optional): a manual rescaling weight given to each</span></span><br><span class="line"><span class="string">            class. If given, it has to be a Tensor of size `C`. Otherwise, it is</span></span><br><span class="line"><span class="string">            treated as if having all ones.</span></span><br><span class="line"><span class="string">        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,</span></span><br><span class="line"><span class="string">            the losses are averaged over each loss element in the batch. Note that for</span></span><br><span class="line"><span class="string">            some losses, there are multiple elements per sample. If the field :attr:`size_average`</span></span><br><span class="line"><span class="string">            is set to ``False``, the losses are instead summed for each minibatch. Ignored</span></span><br><span class="line"><span class="string">            when :attr:`reduce` is ``False``. Default: ``True``</span></span><br><span class="line"><span class="string">        ignore_index (int, optional): Specifies a target value that is ignored</span></span><br><span class="line"><span class="string">            and does not contribute to the input gradient. When</span></span><br><span class="line"><span class="string">            :attr:`size_average` is ``True``, the loss is averaged over</span></span><br><span class="line"><span class="string">            non-ignored targets.</span></span><br><span class="line"><span class="string">        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the</span></span><br><span class="line"><span class="string">            losses are averaged or summed over observations for each minibatch depending</span></span><br><span class="line"><span class="string">            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per</span></span><br><span class="line"><span class="string">            batch element instead and ignores :attr:`size_average`. Default: ``True``</span></span><br><span class="line"><span class="string">        reduction (string, optional): Specifies the reduction to apply to the output:</span></span><br><span class="line"><span class="string">            ``&#x27;none&#x27;`` | ``&#x27;mean&#x27;`` | ``&#x27;sum&#x27;``. ``&#x27;none&#x27;``: no reduction will</span></span><br><span class="line"><span class="string">            be applied, ``&#x27;mean&#x27;``: the weighted mean of the output is taken,</span></span><br><span class="line"><span class="string">            ``&#x27;sum&#x27;``: the output will be summed. Note: :attr:`size_average`</span></span><br><span class="line"><span class="string">            and :attr:`reduce` are in the process of being deprecated, and in</span></span><br><span class="line"><span class="string">            the meantime, specifying either of those two args will override</span></span><br><span class="line"><span class="string">            :attr:`reduction`. Default: ``&#x27;mean&#x27;``</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C)` or :math:`(C)`, where `C = number of classes`, or</span></span><br><span class="line"><span class="string">          :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1`</span></span><br><span class="line"><span class="string">          in the case of `K`-dimensional loss.</span></span><br><span class="line"><span class="string">        - Target: :math:`(N)` or :math:`()`, where each value is</span></span><br><span class="line"><span class="string">          :math:`0 \leq \text&#123;targets&#125;[i] \leq C-1`, or</span></span><br><span class="line"><span class="string">          :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \geq 1` in the case of</span></span><br><span class="line"><span class="string">          K-dimensional loss.</span></span><br><span class="line"><span class="string">        - Output: If :attr:`reduction` is ``&#x27;none&#x27;``, shape :math:`(N)` or</span></span><br><span class="line"><span class="string">          :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \geq 1` in the case of K-dimensional loss.</span></span><br><span class="line"><span class="string">          Otherwise, scalar.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.LogSoftmax(dim=1)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; loss = nn.NLLLoss()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # input is of size N x C = 3 x 5</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # each element in target has to have 0 &lt;= value &lt; C</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; target = torch.tensor([1, 0, 4])</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = loss(m(input), target)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output.backward()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt;</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt;</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # 2D loss example (used, for example, with image inputs)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; N, C = 5, 4</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; loss = nn.NLLLoss()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # input is of size N x C x height x width</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; data = torch.randn(N, 16, 10, 10)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; conv = nn.Conv2d(16, C, (3, 3))</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; m = nn.LogSoftmax(dim=1)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # each element in target has to have 0 &lt;= value &lt; C</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = loss(m(conv(data)), target)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output.backward()</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;ignore_index&#x27;</span>, <span class="string">&#x27;reduction&#x27;</span>]</span><br><span class="line">    ignore_index: int</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = <span class="number">-100</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 reduce=None, reduction: str = <span class="string">&#x27;mean&#x27;</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(NLLLoss, self).__init__(weight, size_average, reduce, reduction)</span><br><span class="line">        self.ignore_index = ignore_index</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor, target: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)</span><br></pre></td></tr></table></figure><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>NLLLoss</mtext></mrow><annotation encoding="application/x-tex">\text{NLLLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">NLLLoss</span></span></span></span></span> 为负对数似然损失函数. <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>CrossEntropyLoss</mtext><mo stretchy="false">(</mo><mi>X</mi><mo separator="true">,</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{CrossEntropyLoss}(X,Y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">CrossEntropyLoss</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mclose">)</span></span></span></span> 等价于 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>NLLLoss</mtext><mo stretchy="false">(</mo><mtext>LogSoftmax</mtext><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{NLLLoss}(\text{LogSoftmax}(X),Y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord text"><span class="mord">NLLLoss</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">LogSoftmax</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mclose">)</span></span></span></span>.</p><p>对于损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>NLLLoss</mtext></mrow><annotation encoding="application/x-tex">\text{NLLLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">NLLLoss</span></span></span></span></span>, 其要求真实张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub><mo>×</mo><mo>⋯</mo><mo>×</mo><msub><mi>d</mi><mi>n</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">Y\in\R^{N\times d_{1}\times \cdots\times d_{n}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72243em;vertical-align:-.0391em"></span><span class="mord mathdefault" style="margin-right:.22222em">Y</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.10903em">N</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>, 且其取值范围在 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mi>C</mi><mo>−</mo><mn>1</mn><mo stretchy="false">]</mo><mo>∩</mo><mi mathvariant="double-struck">N</mi></mrow><annotation encoding="application/x-tex">[0,C-1]\cap\N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathdefault" style="margin-right:.07153em">C</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68889em;vertical-align:0"></span><span class="mord"><span class="mord mathbb">N</span></span></span></span></span>, 输入张量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>N</mi><mo>×</mo><mi>C</mi><mo>×</mo><msub><mi>d</mi><mn>1</mn></msub><mo>×</mo><mo>⋯</mo><mo>×</mo><msub><mi>d</mi><mi>n</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">X\in\R^{N\times C\times d_{1}\times\cdots\times d_{n}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72243em;vertical-align:-.0391em"></span><span class="mord mathdefault" style="margin-right:.07847em">X</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.849108em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.849108em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.10903em">N</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right:.07153em">C</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31731428571428577em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="minner mtight">⋯</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.16454285714285719em"><span style="top:-2.357em;margin-left:0;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>.</p><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>NLLLoss</mtext></mrow><annotation encoding="application/x-tex">\text{NLLLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord text"><span class="mord">NLLLoss</span></span></span></span></span> 其参数如下:</p><ul><li><code>weight</code>: 为加权矩阵, 用于对每个类别进行加权处理.</li><li><code>reduction</code>: 用于指定输出的模式, <code>'none'</code>, <code>'mean'</code> 或 <code>'sum'</code>. 默认为 <code>'mean'</code>.</li><li><code>ignore_index</code>: 表示忽略计算交叉熵的类别, 并且不会计算其梯度.</li></ul><h3 id="weight-参数"><a class="markdownIt-Anchor" href="#weight-参数"></a> weight 参数</h3><p><code>weight</code> 参数用于指定对每个类的加权系数. 默认不使用权重. 该参数可以用于缓解类不平衡的问题. 假设权重矩阵为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>C</mi></msup></mrow><annotation encoding="application/x-tex">W\in\R^{C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72243em;vertical-align:-.0391em"></span><span class="mord mathdefault" style="margin-right:.13889em">W</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.07153em">C</span></span></span></span></span></span></span></span></span></span></span></span>, 不采用权重参数时可视其为全 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 张量.</p><h3 id="reduction-参数"><a class="markdownIt-Anchor" href="#reduction-参数"></a> reduction 参数</h3><p><code>reduction</code>: 用于指定输出的模式, <code>'none'</code>, <code>'mean'</code> 或 <code>'sum'</code>. 默认为 <code>'mean'</code>.</p><div class="post-button"><a class="btn" href="/posts/20211003010900.html#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211003010800.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211003010800.html" class="post-title-link" itemprop="url">Pytorch.torch.nn.CrossEntropyLoss</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-03 01:08:00" itemprop="dateCreated datePublished" datetime="2021-10-03T01:08:00+08:00">2021-10-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-04-02 20:06:54" itemprop="dateModified" datetime="2022-04-02T20:06:54+08:00">2022-04-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211003010800.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211003010800.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>16k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>15 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchnncrossentropyloss"><a class="markdownIt-Anchor" href="#pytorchtorchnncrossentropyloss"></a> Pytorch.torch.nn.CrossEntropyLoss</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrossEntropyLoss</span>(<span class="params">_WeightedLoss</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;This criterion computes the cross entropy loss between input and target.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    It is useful when training a classification problem with `C` classes.</span></span><br><span class="line"><span class="string">    If provided, the optional argument :attr:`weight` should be a 1D `Tensor`</span></span><br><span class="line"><span class="string">    assigning weight to each of the classes.</span></span><br><span class="line"><span class="string">    This is particularly useful when you have an unbalanced training set.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The `input` is expected to contain raw, unnormalized scores for each class.</span></span><br><span class="line"><span class="string">    `input` has to be a Tensor of size either :math:`(minibatch, C)` or</span></span><br><span class="line"><span class="string">    :math:`(minibatch, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1` for the</span></span><br><span class="line"><span class="string">    `K`-dimensional case. The latter is useful for higher dimension inputs, such</span></span><br><span class="line"><span class="string">    as computing cross entropy loss per-pixel for 2D images.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The `target` that this criterion expects should contain either:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    - Class indices in the range :math:`[0, C-1]` where :math:`C` is the number of classes; if</span></span><br><span class="line"><span class="string">      `ignore_index` is specified, this loss also accepts this class index (this index</span></span><br><span class="line"><span class="string">      may not necessarily be in the class range). The unreduced (i.e. with :attr:`reduction`</span></span><br><span class="line"><span class="string">      set to ``&#x27;none&#x27;``) loss for this case can be described as:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      .. math::</span></span><br><span class="line"><span class="string">          \ell(x, y) = L = \&#123;l_1,\dots,l_N\&#125;^\top, \quad</span></span><br><span class="line"><span class="string">          l_n = - w_&#123;y_n&#125; \log \frac&#123;\exp(x_&#123;n,y_n&#125;)&#125;&#123;\sum_&#123;c=1&#125;^C \exp(x_&#123;n,c&#125;)&#125;</span></span><br><span class="line"><span class="string">          \cdot \mathbb&#123;1&#125;\&#123;y_n \not= \text&#123;ignore\_index&#125;\&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,</span></span><br><span class="line"><span class="string">      :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as</span></span><br><span class="line"><span class="string">      :math:`d_1, ..., d_k` for the `K`-dimensional case. If</span></span><br><span class="line"><span class="string">      :attr:`reduction` is not ``&#x27;none&#x27;`` (default ``&#x27;mean&#x27;``), then</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      .. math::</span></span><br><span class="line"><span class="string">          \ell(x, y) = \begin&#123;cases&#125;</span></span><br><span class="line"><span class="string">              \sum_&#123;n=1&#125;^N \frac&#123;1&#125;&#123;\sum_&#123;n=1&#125;^N w_&#123;y_n&#125; \cdot \mathbb&#123;1&#125;\&#123;y_n \not= \text&#123;ignore\_index&#125;\&#125;&#125; l_n, &amp;</span></span><br><span class="line"><span class="string">               \text&#123;if reduction&#125; = \text&#123;`mean&#x27;;&#125;\\</span></span><br><span class="line"><span class="string">                \sum_&#123;n=1&#125;^N l_n,  &amp;</span></span><br><span class="line"><span class="string">                \text&#123;if reduction&#125; = \text&#123;`sum&#x27;.&#125;</span></span><br><span class="line"><span class="string">            \end&#123;cases&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      Note that this case is equivalent to the combination of :class:`~torch.nn.LogSoftmax` and</span></span><br><span class="line"><span class="string">      :class:`~torch.nn.NLLLoss`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    - Probabilities for each class; useful when labels beyond a single class per minibatch item</span></span><br><span class="line"><span class="string">      are required, such as for blended labels, label smoothing, etc. The unreduced (i.e. with</span></span><br><span class="line"><span class="string">      :attr:`reduction` set to ``&#x27;none&#x27;``) loss for this case can be described as:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      .. math::</span></span><br><span class="line"><span class="string">          \ell(x, y) = L = \&#123;l_1,\dots,l_N\&#125;^\top, \quad</span></span><br><span class="line"><span class="string">          l_n = - \sum_&#123;c=1&#125;^C w_c \log \frac&#123;\exp(x_&#123;n,c&#125;)&#125;&#123;\exp(\sum_&#123;i=1&#125;^C x_&#123;n,i&#125;)&#125; y_&#123;n,c&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      where :math:`x` is the input, :math:`y` is the target, :math:`w` is the weight,</span></span><br><span class="line"><span class="string">      :math:`C` is the number of classes, and :math:`N` spans the minibatch dimension as well as</span></span><br><span class="line"><span class="string">      :math:`d_1, ..., d_k` for the `K`-dimensional case. If</span></span><br><span class="line"><span class="string">      :attr:`reduction` is not ``&#x27;none&#x27;`` (default ``&#x27;mean&#x27;``), then</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      .. math::</span></span><br><span class="line"><span class="string">          \ell(x, y) = \begin&#123;cases&#125;</span></span><br><span class="line"><span class="string">              \frac&#123;\sum_&#123;n=1&#125;^N l_n&#125;&#123;N&#125;, &amp;</span></span><br><span class="line"><span class="string">               \text&#123;if reduction&#125; = \text&#123;`mean&#x27;;&#125;\\</span></span><br><span class="line"><span class="string">                \sum_&#123;n=1&#125;^N l_n,  &amp;</span></span><br><span class="line"><span class="string">                \text&#123;if reduction&#125; = \text&#123;`sum&#x27;.&#125;</span></span><br><span class="line"><span class="string">            \end&#123;cases&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. note::</span></span><br><span class="line"><span class="string">        The performance of this criterion is generally better when `target` contains class</span></span><br><span class="line"><span class="string">        indices, as this allows for optimized computation. Consider providing `target` as</span></span><br><span class="line"><span class="string">        class probabilities only when a single class label per minibatch item is too restrictive.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        weight (Tensor, optional): a manual rescaling weight given to each class.</span></span><br><span class="line"><span class="string">            If given, has to be a Tensor of size `C`</span></span><br><span class="line"><span class="string">        size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,</span></span><br><span class="line"><span class="string">            the losses are averaged over each loss element in the batch. Note that for</span></span><br><span class="line"><span class="string">            some losses, there are multiple elements per sample. If the field :attr:`size_average`</span></span><br><span class="line"><span class="string">            is set to ``False``, the losses are instead summed for each minibatch. Ignored</span></span><br><span class="line"><span class="string">            when :attr:`reduce` is ``False``. Default: ``True``</span></span><br><span class="line"><span class="string">        ignore_index (int, optional): Specifies a target value that is ignored</span></span><br><span class="line"><span class="string">            and does not contribute to the input gradient. When :attr:`size_average` is</span></span><br><span class="line"><span class="string">            ``True``, the loss is averaged over non-ignored targets. Note that</span></span><br><span class="line"><span class="string">            :attr:`ignore_index` is only applicable when the target contains class indices.</span></span><br><span class="line"><span class="string">        reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the</span></span><br><span class="line"><span class="string">            losses are averaged or summed over observations for each minibatch depending</span></span><br><span class="line"><span class="string">            on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per</span></span><br><span class="line"><span class="string">            batch element instead and ignores :attr:`size_average`. Default: ``True``</span></span><br><span class="line"><span class="string">        reduction (string, optional): Specifies the reduction to apply to the output:</span></span><br><span class="line"><span class="string">            ``&#x27;none&#x27;`` | ``&#x27;mean&#x27;`` | ``&#x27;sum&#x27;``. ``&#x27;none&#x27;``: no reduction will</span></span><br><span class="line"><span class="string">            be applied, ``&#x27;mean&#x27;``: the weighted mean of the output is taken,</span></span><br><span class="line"><span class="string">            ``&#x27;sum&#x27;``: the output will be summed. Note: :attr:`size_average`</span></span><br><span class="line"><span class="string">            and :attr:`reduce` are in the process of being deprecated, and in</span></span><br><span class="line"><span class="string">            the meantime, specifying either of those two args will override</span></span><br><span class="line"><span class="string">            :attr:`reduction`. Default: ``&#x27;mean&#x27;``</span></span><br><span class="line"><span class="string">        label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount</span></span><br><span class="line"><span class="string">            of smoothing when computing the loss, where 0.0 means no smoothing. The targets</span></span><br><span class="line"><span class="string">            become a mixture of the original ground truth and a uniform distribution as described in</span></span><br><span class="line"><span class="string">            `Rethinking the Inception Architecture for Computer Vision &lt;https://arxiv.org/abs/1512.00567&gt;`__. Default: :math:`0.0`.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Shape:</span></span><br><span class="line"><span class="string">        - Input: :math:`(N, C)` where `C = number of classes`, or</span></span><br><span class="line"><span class="string">          :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \geq 1`</span></span><br><span class="line"><span class="string">          in the case of `K`-dimensional loss.</span></span><br><span class="line"><span class="string">        - Target: If containing class indices, shape :math:`(N)` where each value is</span></span><br><span class="line"><span class="string">          :math:`0 \leq \text&#123;targets&#125;[i] \leq C-1`, or :math:`(N, d_1, d_2, ..., d_K)` with</span></span><br><span class="line"><span class="string">          :math:`K \geq 1` in the case of K-dimensional loss. If containing class probabilities,</span></span><br><span class="line"><span class="string">          same shape as the input.</span></span><br><span class="line"><span class="string">        - Output: If :attr:`reduction` is ``&#x27;none&#x27;``, shape :math:`(N)` or</span></span><br><span class="line"><span class="string">          :math:`(N, d_1, d_2, ..., d_K)` with :math:`K \geq 1` in the case of K-dimensional loss.</span></span><br><span class="line"><span class="string">          Otherwise, scalar.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Examples::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # Example of target with class indices</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; loss = nn.CrossEntropyLoss()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; target = torch.empty(3, dtype=torch.long).random_(5)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = loss(input, target)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output.backward()</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt;</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; # Example of target with class probabilities</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; input = torch.randn(3, 5, requires_grad=True)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; target = torch.randn(3, 5).softmax(dim=1)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output = loss(input, target)</span></span><br><span class="line"><span class="string">        &gt;&gt;&gt; output.backward()</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    __constants__ = [<span class="string">&#x27;ignore_index&#x27;</span>, <span class="string">&#x27;reduction&#x27;</span>, <span class="string">&#x27;label_smoothing&#x27;</span>]</span><br><span class="line">    ignore_index: int</span><br><span class="line">    label_smoothing: float</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = <span class="number">-100</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 reduce=None, reduction: str = <span class="string">&#x27;mean&#x27;</span>, label_smoothing: float = <span class="number">0.0</span></span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        super(CrossEntropyLoss, self).__init__(weight, size_average, reduce, reduction)</span><br><span class="line">        self.ignore_index = ignore_index</span><br><span class="line">        self.label_smoothing = label_smoothing</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input: Tensor, target: Tensor</span>) -&gt; Tensor:</span></span><br><span class="line">        <span class="keyword">return</span> F.cross_entropy(input, target, weight=self.weight,</span><br><span class="line">                               ignore_index=self.ignore_index, reduction=self.reduction,</span><br><span class="line">                               label_smoothing=self.label_smoothing)</span><br></pre></td></tr></table></figure><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>CrossEntropyLoss</mtext></mrow><annotation encoding="application/x-tex">\text{CrossEntropyLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">CrossEntropyLoss</span></span></span></span></span> 为交叉熵损失函数.</p><p>损失函数层 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>CrossEntropyLoss</mtext></mrow><annotation encoding="application/x-tex">\text{CrossEntropyLoss}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8777699999999999em;vertical-align:-.19444em"></span><span class="mord text"><span class="mord">CrossEntropyLoss</span></span></span></span></span> 其参数如下:</p><ul><li><code>weight</code>: 为加权矩阵, 用于对每个类别进行加权处理.</li><li><code>reduction</code>: 用于指定输出的模式, <code>'none'</code>, <code>'mean'</code> 或 <code>'sum'</code>. 默认为 <code>'mean'</code>.</li><li><code>ignore_index</code>: 表示忽略计算交叉熵的类别, 并且不会计算其梯度.</li><li><code>label_smoothing</code>: 用于平滑操作, 降低过拟合的可能性.</li></ul><h3 id="weight-参数"><a class="markdownIt-Anchor" href="#weight-参数"></a> weight 参数</h3><p><code>weight</code> 参数用于指定对每个类的加权系数. 默认不使用权重. 该参数可以用于缓解类不平衡的问题. 权重矩阵为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>C</mi></msup></mrow><annotation encoding="application/x-tex">W\in\R^{C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72243em;vertical-align:-.0391em"></span><span class="mord mathdefault" style="margin-right:.13889em">W</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8413309999999999em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:.07153em">C</span></span></span></span></span></span></span></span></span></span></span></span>, 不采用权重参数时可视其为全 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 张量.</p><h3 id="reduction-参数"><a class="markdownIt-Anchor" href="#reduction-参数"></a> reduction 参数</h3><p><code>reduction</code>: 用于指定输出的模式, <code>'none'</code>, <code>'mean'</code> 或 <code>'sum'</code>. 默认为 <code>'mean'</code>.</p><p>在采用 <code>weight</code> 参数时, 对于真实张量的维度个数和 <code>reduction</code> 参数的不同, 其计算过程有细微的区别.</p><div class="post-button"><a class="btn" href="/posts/20211003010800.html#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article><nav class="pagination"><a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/60/">60</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right" aria-label="下一页"></i></a></nav></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="智商为零的小白" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">智商为零的小白</p><div class="site-description" itemprop="description">生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">593</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">32</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">92</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zswldxb" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zswldxb" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:1979938740@qq.com" title="E-Mail → mailto:1979938740@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">智商为零的小白</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="站点总字数">2.4m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">35:44 小时</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-divider">|</span> <span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css"><script>NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'rxJydM3QVoypB9apkSU3e9ML-gzGzoHsz',
      appKey     : 'NqXT8ScfaD1udoMiPk3NQ6MF',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});</script><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><canvas class="fireworks" style="position:fixed;left:0;top:0;z-index:1;pointer-events:none"></canvas><script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script><script type="text/javascript" src="/js/src/fireworks.js"></script></body></html>