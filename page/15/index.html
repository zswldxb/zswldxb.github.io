<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.1.1"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon_logo_2.svg"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon_logo_2.svg"><link rel="mask-icon" href="/images/logo_2.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/themes/blue/pace-theme-minimal.min.css"><script src="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"zswldxb.github.io",root:"/",scheme:"Mist",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:type" content="website"><meta property="og:title" content="智商为零的小白的博客"><meta property="og:url" content="https://zswldxb.github.io/page/15/index.html"><meta property="og:site_name" content="智商为零的小白的博客"><meta property="og:description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"><meta property="og:locale" content="zh_CN"><meta property="article:author" content="智商为零的小白"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://zswldxb.github.io/page/15/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!0,isPost:!1,lang:"zh-CN"}</script><title>智商为零的小白的博客</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">智商为零的小白的博客</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content index posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002001000.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002001000.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.TenCrop</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:10:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:10:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:24:26" itemprop="dateModified" datetime="2021-10-27T09:24:26+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002001000.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002001000.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>5k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>5 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformstencrop"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformstencrop"></a> Pytorch.torchvision.transforms.TenCrop</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TenCrop</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crop the given image into four corners and the central crop plus the flipped version of these (horizontal flipping is used by default). If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note:</span></span><br><span class="line"><span class="string">         This transform returns a tuple of images and there may be a mismatch in the number of inputs and targets your Dataset returns. See below for an example of how to deal with this.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        size (sequence or int): Desired output size of the crop. If size is an int instead of sequence like (h, w), a square crop (size, size) is made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).</span></span><br><span class="line"><span class="string">        vertical_flip (bool): Use vertical flipping instead of horizontal</span></span><br><span class="line"><span class="string">	&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><code>TenCrop</code> 将对图片进行裁剪并获得十张图片，裁剪方式为：左上角、右上角、左下角、右下角和中心的裁剪，然后将裁剪后的图片进行翻转（可以通过设置 <code>vertical_flip</code> 来选择是水平翻转还是垂直翻转）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">100</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.TenCrop(<span class="number">6</span>)</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> t(a):</span><br><span class="line">    print(e)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[ 4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85],</span></span><br><span class="line"><span class="string">         [90, 91, 92, 93, 94, 95]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [94, 95, 96, 97, 98, 99]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[22, 23, 24, 25, 26, 27],</span></span><br><span class="line"><span class="string">         [32, 33, 34, 35, 36, 37],</span></span><br><span class="line"><span class="string">         [42, 43, 44, 45, 46, 47],</span></span><br><span class="line"><span class="string">         [52, 53, 54, 55, 56, 57],</span></span><br><span class="line"><span class="string">         [62, 63, 64, 65, 66, 67],</span></span><br><span class="line"><span class="string">         [72, 73, 74, 75, 76, 77]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[ 9,  8,  7,  6,  5,  4],</span></span><br><span class="line"><span class="string">         [19, 18, 17, 16, 15, 14],</span></span><br><span class="line"><span class="string">         [29, 28, 27, 26, 25, 24],</span></span><br><span class="line"><span class="string">         [39, 38, 37, 36, 35, 34],</span></span><br><span class="line"><span class="string">         [49, 48, 47, 46, 45, 44],</span></span><br><span class="line"><span class="string">         [59, 58, 57, 56, 55, 54]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[ 5,  4,  3,  2,  1,  0],</span></span><br><span class="line"><span class="string">         [15, 14, 13, 12, 11, 10],</span></span><br><span class="line"><span class="string">         [25, 24, 23, 22, 21, 20],</span></span><br><span class="line"><span class="string">         [35, 34, 33, 32, 31, 30],</span></span><br><span class="line"><span class="string">         [45, 44, 43, 42, 41, 40],</span></span><br><span class="line"><span class="string">         [55, 54, 53, 52, 51, 50]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[49, 48, 47, 46, 45, 44],</span></span><br><span class="line"><span class="string">         [59, 58, 57, 56, 55, 54],</span></span><br><span class="line"><span class="string">         [69, 68, 67, 66, 65, 64],</span></span><br><span class="line"><span class="string">         [79, 78, 77, 76, 75, 74],</span></span><br><span class="line"><span class="string">         [89, 88, 87, 86, 85, 84],</span></span><br><span class="line"><span class="string">         [99, 98, 97, 96, 95, 94]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[45, 44, 43, 42, 41, 40],</span></span><br><span class="line"><span class="string">         [55, 54, 53, 52, 51, 50],</span></span><br><span class="line"><span class="string">         [65, 64, 63, 62, 61, 60],</span></span><br><span class="line"><span class="string">         [75, 74, 73, 72, 71, 70],</span></span><br><span class="line"><span class="string">         [85, 84, 83, 82, 81, 80],</span></span><br><span class="line"><span class="string">         [95, 94, 93, 92, 91, 90]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[27, 26, 25, 24, 23, 22],</span></span><br><span class="line"><span class="string">         [37, 36, 35, 34, 33, 32],</span></span><br><span class="line"><span class="string">         [47, 46, 45, 44, 43, 42],</span></span><br><span class="line"><span class="string">         [57, 56, 55, 54, 53, 52],</span></span><br><span class="line"><span class="string">         [67, 66, 65, 64, 63, 62],</span></span><br><span class="line"><span class="string">         [77, 76, 75, 74, 73, 72]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(<span class="string">&#x27;--&#x27;</span> * <span class="number">10</span>)</span><br><span class="line">t = transforms.TenCrop(<span class="number">6</span>, vertical_flip=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> t(a):</span><br><span class="line">    print(e)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[ 4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85],</span></span><br><span class="line"><span class="string">         [90, 91, 92, 93, 94, 95]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [94, 95, 96, 97, 98, 99]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[22, 23, 24, 25, 26, 27],</span></span><br><span class="line"><span class="string">         [32, 33, 34, 35, 36, 37],</span></span><br><span class="line"><span class="string">         [42, 43, 44, 45, 46, 47],</span></span><br><span class="line"><span class="string">         [52, 53, 54, 55, 56, 57],</span></span><br><span class="line"><span class="string">         [62, 63, 64, 65, 66, 67],</span></span><br><span class="line"><span class="string">         [72, 73, 74, 75, 76, 77]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[90, 91, 92, 93, 94, 95],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[94, 95, 96, 97, 98, 99],</span></span><br><span class="line"><span class="string">         [84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [44, 45, 46, 47, 48, 49]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[50, 51, 52, 53, 54, 55],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15],</span></span><br><span class="line"><span class="string">         [ 0,  1,  2,  3,  4,  5]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [ 4,  5,  6,  7,  8,  9]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[72, 73, 74, 75, 76, 77],</span></span><br><span class="line"><span class="string">         [62, 63, 64, 65, 66, 67],</span></span><br><span class="line"><span class="string">         [52, 53, 54, 55, 56, 57],</span></span><br><span class="line"><span class="string">         [42, 43, 44, 45, 46, 47],</span></span><br><span class="line"><span class="string">         [32, 33, 34, 35, 36, 37],</span></span><br><span class="line"><span class="string">         [22, 23, 24, 25, 26, 27]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002000900.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000900.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.FiveCrop</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:09:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:09:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:17:14" itemprop="dateModified" datetime="2021-10-27T09:17:14+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000900.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000900.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.3k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsfivecrop"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsfivecrop"></a> Pytorch.torchvision.transforms.FiveCrop</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FiveCrop</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crop the given image into four corners and the central crop.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note:</span></span><br><span class="line"><span class="string">         This transform returns a tuple of images and there may be a mismatch in the number of inputs and targets your Dataset returns. See below for an example of how to deal with this.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">         size (sequence or int): Desired output size of the crop. If size is an ``int`` instead of sequence like (h, w), a square crop of size (size, size) is made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>FiveCrop</code> 将对图片进行裁剪并获得五张图片，裁剪方式为：左上角、右上角、左下角、右下角和中心的裁剪。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">100</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.FiveCrop(<span class="number">6</span>)</span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> t(a):</span><br><span class="line">    print(e)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15],</span></span><br><span class="line"><span class="string">         [20, 21, 22, 23, 24, 25],</span></span><br><span class="line"><span class="string">         [30, 31, 32, 33, 34, 35],</span></span><br><span class="line"><span class="string">         [40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[ 4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [14, 15, 16, 17, 18, 19],</span></span><br><span class="line"><span class="string">         [24, 25, 26, 27, 28, 29],</span></span><br><span class="line"><span class="string">         [34, 35, 36, 37, 38, 39],</span></span><br><span class="line"><span class="string">         [44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[40, 41, 42, 43, 44, 45],</span></span><br><span class="line"><span class="string">         [50, 51, 52, 53, 54, 55],</span></span><br><span class="line"><span class="string">         [60, 61, 62, 63, 64, 65],</span></span><br><span class="line"><span class="string">         [70, 71, 72, 73, 74, 75],</span></span><br><span class="line"><span class="string">         [80, 81, 82, 83, 84, 85],</span></span><br><span class="line"><span class="string">         [90, 91, 92, 93, 94, 95]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[44, 45, 46, 47, 48, 49],</span></span><br><span class="line"><span class="string">         [54, 55, 56, 57, 58, 59],</span></span><br><span class="line"><span class="string">         [64, 65, 66, 67, 68, 69],</span></span><br><span class="line"><span class="string">         [74, 75, 76, 77, 78, 79],</span></span><br><span class="line"><span class="string">         [84, 85, 86, 87, 88, 89],</span></span><br><span class="line"><span class="string">         [94, 95, 96, 97, 98, 99]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">tensor([[[22, 23, 24, 25, 26, 27],</span></span><br><span class="line"><span class="string">         [32, 33, 34, 35, 36, 37],</span></span><br><span class="line"><span class="string">         [42, 43, 44, 45, 46, 47],</span></span><br><span class="line"><span class="string">         [52, 53, 54, 55, 56, 57],</span></span><br><span class="line"><span class="string">         [62, 63, 64, 65, 66, 67],</span></span><br><span class="line"><span class="string">         [72, 73, 74, 75, 76, 77]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002000800.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000800.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.RandomResizedCrop</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:08:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:08:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:23:08" itemprop="dateModified" datetime="2021-10-27T09:23:08+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000800.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000800.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.5k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsrandomresizedcrop"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsrandomresizedcrop"></a> Pytorch.torchvision.transforms.RandomResizedCrop</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomResizedCrop</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crop a random portion of image and resize it to a given size.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions</span></span><br><span class="line"><span class="string">	A crop of the original image is made: the crop has a random area (H * W) and a random aspect ratio. This crop is finally resized to the given size. This is popularly used to train the Inception networks.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	Args:</span></span><br><span class="line"><span class="string">        size (int or sequence): expected output size of the crop, for each edge. If size is an int instead of sequence like (h, w), a square output size ``(size, size)`` is made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	note:</span></span><br><span class="line"><span class="string">		In torchscript mode size as single int is not supported, use a sequence of length 1: ``[size, ]``.</span></span><br><span class="line"><span class="string">        scale (tuple of float): Specifies the lower and upper bounds for the random area of the crop, before resizing. The scale is defined with respect to the area of the original image.</span></span><br><span class="line"><span class="string">        ratio (tuple of float): lower and upper bounds for the random aspect ratio of the crop, before resizing.</span></span><br><span class="line"><span class="string">        interpolation (InterpolationMode): Desired interpolation enum defined by :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.BILINEAR``. If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` and ``InterpolationMode.BICUBIC`` are supported. For backward compatibility integer values (e.g. ``PIL.Image.NEAREST``) are still acceptable.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>RandomResizedCrop</code> 将输入图像随机裁剪为不同的大小和宽高比，然后将裁剪后的图像放缩为输出大小。</p><p>参数：</p><ul><li><code>size</code>：表示输出的大小，若 <code>size</code> 为 <code>int</code> 值，则输出的大小为 <code>(size, size)</code>，若 <code>size</code> 为 <code>(h, w)</code>，则输出的大小为 <code>(h, w)</code>。</li><li><code>scale</code>：表示裁剪的图片相对于原始图片的比例的最小值和最大值。</li><li><code>ratio</code>：表示裁剪的图片相对于原始图片的高宽比的最小值和最大值。</li><li><code>interpolation</code>：表示插值的模式。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">16</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3],</span></span><br><span class="line"><span class="string">         [ 4,  5,  6,  7],</span></span><br><span class="line"><span class="string">         [ 8,  9, 10, 11],</span></span><br><span class="line"><span class="string">         [12, 13, 14, 15]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomResizedCrop(<span class="number">10</span>, scale=(<span class="number">0.1</span>, <span class="number">1</span>), ratio=(<span class="number">0.5</span>, <span class="number">2</span>))</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 1,  1,  1,  2,  2,  2,  2,  3,  3,  3],</span></span><br><span class="line"><span class="string">         [ 1,  1,  2,  2,  2,  3,  3,  3,  3,  3],</span></span><br><span class="line"><span class="string">         [ 3,  3,  3,  4,  4,  4,  4,  5,  5,  5],</span></span><br><span class="line"><span class="string">         [ 5,  5,  5,  5,  5,  6,  6,  6,  7,  7],</span></span><br><span class="line"><span class="string">         [ 6,  6,  6,  7,  7,  7,  8,  8,  8,  8],</span></span><br><span class="line"><span class="string">         [ 8,  8,  8,  8,  9,  9,  9, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [ 9,  9, 10, 10, 10, 11, 11, 11, 11, 11],</span></span><br><span class="line"><span class="string">         [11, 11, 11, 12, 12, 12, 12, 13, 13, 13],</span></span><br><span class="line"><span class="string">         [13, 13, 13, 13, 13, 14, 14, 14, 15, 15],</span></span><br><span class="line"><span class="string">         [13, 13, 13, 14, 14, 14, 14, 15, 15, 15]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002000700.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000700.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.CenterCrop</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:07:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:07:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:16:16" itemprop="dateModified" datetime="2021-10-27T09:16:16+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000700.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000700.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.3k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformscentercrop"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformscentercrop"></a> Pytorch.torchvision.transforms.CenterCrop</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">center_crop</span>(<span class="params">img: Tensor, output_size: List[int]</span>) -&gt; Tensor:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crops the given image at the center.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected</span></span><br><span class="line"><span class="string">    to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions.</span></span><br><span class="line"><span class="string">    If image size is smaller than output size along any edge, image is padded with 0 and then center cropped.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        img (PIL Image or Tensor): Image to be cropped.</span></span><br><span class="line"><span class="string">        output_size (sequence or int): (height, width) of the crop box. If int or sequence with single int,</span></span><br><span class="line"><span class="string">            it is used for both directions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        PIL Image or Tensor: Cropped image.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>CenterCrop</code> 将根据给定的 <code>size</code> 从中心裁剪，若图片大小小于输出大小，则将填充 <code>0</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = torch.arange(<span class="number">20</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">2</span>, <span class="number">10</span>)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],</span></span><br><span class="line"><span class="string">         [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.CenterCrop(<span class="number">6</span>)</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ 0,  0,  0,  0,  0,  0],</span></span><br><span class="line"><span class="string">         [ 0,  0,  0,  0,  0,  0],</span></span><br><span class="line"><span class="string">         [ 2,  3,  4,  5,  6,  7],</span></span><br><span class="line"><span class="string">         [12, 13, 14, 15, 16, 17],</span></span><br><span class="line"><span class="string">         [ 0,  0,  0,  0,  0,  0],</span></span><br><span class="line"><span class="string">         [ 0,  0,  0,  0,  0,  0]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002000600.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000600.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.RandomCrop</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:06:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:06:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:19:50" itemprop="dateModified" datetime="2021-10-27T09:19:50+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000600.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000600.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>4.3k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>4 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsrandomcrop"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsrandomcrop"></a> Pytorch.torchvision.transforms.RandomCrop</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomCrop</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crop the given image at a random location.</span></span><br><span class="line"><span class="string">    If the image is torch Tensor, it is expected to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions, but if non-constant padding is used, the input is expected to have at most 2 leading dimensions</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        size (sequence or int): Desired output size of the crop. If size is an int instead of sequence like (h, w), a square crop (size, size) is made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).</span></span><br><span class="line"><span class="string">        padding (int or sequence, optional): Optional padding on each border of the image. Default is None. If a single int is provided this is used to pad all borders. If sequence of length 2 is provided this is the padding on left/right and top/bottom respectively. If a sequence of length 4 is provided  this is the padding for the left, top, right and bottom borders respectively.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    note:</span></span><br><span class="line"><span class="string">        In torchscript mode padding as single int is not supported, use a sequence of length 1: ``[padding, ]``.</span></span><br><span class="line"><span class="string">        pad_if_needed (boolean): It will pad the image if smaller than the desired size to avoid raising an exception. Since cropping is done after padding, the padding seems to be done at a random offset.</span></span><br><span class="line"><span class="string">        fill (number or str or tuple): Pixel fill value for constant fill. Default is 0. If a tuple of length 3, it is used to fill R, G, B channels respectively. This value is only used when the padding_mode is constant. Only number is supported for torch Tensor. Only int or str or tuple value is supported for PIL Image.</span></span><br><span class="line"><span class="string">        padding_mode (str): Type of padding. Should be: constant, edge, reflect or symmetric. Default is constant.</span></span><br><span class="line"><span class="string">            - constant: pads with a constant value, this value is specified with fill</span></span><br><span class="line"><span class="string">            - edge: pads with the last value at the edge of the image. If input a 5D torch Tensor, the last 3 dimensions will be padded instead of the last 2</span></span><br><span class="line"><span class="string">            - reflect: pads with reflection of image without repeating the last value on the edge. For example, padding [1, 2, 3, 4] with 2 elements on both sides in reflect mode will result in [3, 2, 1, 2, 3, 4, 3, 2]</span></span><br><span class="line"><span class="string">            - symmetric: pads with reflection of image repeating the last value on the edge. For example, padding [1, 2, 3, 4] with 2 elements on both sides in symmetric mode will result in [2, 1, 1, 2, 3, 4, 4, 3]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>RandomCrop</code> 将对原始图片进行随机裁剪，要求被处理的 <code>tensor</code> 的形状为 <code>[..., H, W]</code>。</p><p>参数：</p><ul><li><code>size</code>：表示输出的大小，若 <code>size</code> 为 <code>int</code> 值，则输出的大小为 <code>(size, size)</code>，若 <code>size</code> 为 <code>(h, w)</code>，则输出的大小为 <code>(h, w)</code>。</li><li><code>padding</code>：表示填充情况，若 <code>padding</code> 为 <code>int</code> 值，则在上下左右都填充 <code>padding</code>，若 <code>padding</code> 为长度为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">2</span></span></span></span> 的序列，则左右填充 <code>padding[0]</code>，上下填充 <code>padding[1]</code>，若 <code>padding</code> 为长度为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">4</span></span></span></span> 的序列，则左上右下分别填充为 <code>padding[0], padding[1], padding[2], padding[3]</code>。注意 <code>padding</code> 为 <code>int</code> 在 <code>torchscript</code> 模式下不支持，建议使用长度为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 的序列 <code>[padding, ]</code>。</li><li><code>pad_if_needed</code>：是否在经过 <code>padding</code> 后的图片大小小于输出大小时，对 <code>padding</code> 后的图片进行填充，若为是，则设 <code>padding</code> 后的图片的宽高为 <code>width, height</code>，输出的宽高为 <code>size[1], size[0]</code>，则左右填充 <code>size[1]-weight</code>，上下填充 <code>size[0]-height</code>，后续的 <code>crop</code> 进行随机裁剪，其等价于使用随机偏移进行填充。</li><li><code>fill</code>：表示填充的数值，默认为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span>，其仅在 <code>padding_mode=constant</code> 时有效。</li><li><code>padding_mode</code> 为设置填充模式，有如下几种模式：<ul><li><code>constant</code>：将填充为固定值 <code>fill</code>。</li><li><code>edge</code>：将根据边缘值进行填充。</li><li><code>reflect</code>：进行反射填充。</li><li><code>symmetric</code>：进行对称填充。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">img = torch.arange(<span class="number">9</span>, dtype=torch.uint8).view(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">print(img)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 1, 2],</span></span><br><span class="line"><span class="string">         [3, 4, 5],</span></span><br><span class="line"><span class="string">         [6, 7, 8]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomCrop(size=<span class="number">7</span>, padding=<span class="number">1</span>, pad_if_needed=<span class="literal">True</span>, fill=<span class="number">10</span>)</span><br><span class="line">print(t(img))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[10, 10, 10, 10, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [10, 10, 10, 10, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [10,  0,  1,  2, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [10,  3,  4,  5, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [10,  6,  7,  8, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [10, 10, 10, 10, 10, 10, 10],</span></span><br><span class="line"><span class="string">         [10, 10, 10, 10, 10, 10, 10]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomCrop(size=<span class="number">7</span>, padding=<span class="number">2</span>, padding_mode=<span class="string">&#x27;edge&#x27;</span>)</span><br><span class="line">print(t(img))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0, 0, 0, 1, 2, 2, 2],</span></span><br><span class="line"><span class="string">         [0, 0, 0, 1, 2, 2, 2],</span></span><br><span class="line"><span class="string">         [0, 0, 0, 1, 2, 2, 2],</span></span><br><span class="line"><span class="string">         [3, 3, 3, 4, 5, 5, 5],</span></span><br><span class="line"><span class="string">         [6, 6, 6, 7, 8, 8, 8],</span></span><br><span class="line"><span class="string">         [6, 6, 6, 7, 8, 8, 8],</span></span><br><span class="line"><span class="string">         [6, 6, 6, 7, 8, 8, 8]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomCrop(size=<span class="number">7</span>, padding=<span class="number">2</span>, padding_mode=<span class="string">&#x27;reflect&#x27;</span>)</span><br><span class="line">print(t(img))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[8, 7, 6, 7, 8, 7, 6],</span></span><br><span class="line"><span class="string">         [5, 4, 3, 4, 5, 4, 3],</span></span><br><span class="line"><span class="string">         [2, 1, 0, 1, 2, 1, 0],</span></span><br><span class="line"><span class="string">         [5, 4, 3, 4, 5, 4, 3],</span></span><br><span class="line"><span class="string">         [8, 7, 6, 7, 8, 7, 6],</span></span><br><span class="line"><span class="string">         [5, 4, 3, 4, 5, 4, 3],</span></span><br><span class="line"><span class="string">         [2, 1, 0, 1, 2, 1, 0]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.RandomCrop(size=<span class="number">7</span>, padding=<span class="number">2</span>, padding_mode=<span class="string">&#x27;symmetric&#x27;</span>)</span><br><span class="line">print(t(img))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[4, 3, 3, 4, 5, 5, 4],</span></span><br><span class="line"><span class="string">         [1, 0, 0, 1, 2, 2, 1],</span></span><br><span class="line"><span class="string">         [1, 0, 0, 1, 2, 2, 1],</span></span><br><span class="line"><span class="string">         [4, 3, 3, 4, 5, 5, 4],</span></span><br><span class="line"><span class="string">         [7, 6, 6, 7, 8, 8, 7],</span></span><br><span class="line"><span class="string">         [7, 6, 6, 7, 8, 8, 7],</span></span><br><span class="line"><span class="string">         [4, 3, 3, 4, 5, 5, 4]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002000500.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000500.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.ConvertImageDtype</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:05:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:05:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:16:54" itemprop="dateModified" datetime="2021-10-27T09:16:54+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000500.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000500.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.7k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformsconvertimagedtype"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformsconvertimagedtype"></a> Pytorch.torchvision.transforms.ConvertImageDtype</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvertImageDtype</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Convert a tensor image to the given ``dtype`` and scale the values accordingly</span></span><br><span class="line"><span class="string">    This function does not support PIL Image.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dtype (torch.dtype): Desired data type of the output</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    note:</span></span><br><span class="line"><span class="string">        When converting from a smaller to a larger integer ``dtype`` the maximum values are **not** mapped exactly. If converted back and forth, this mismatch has no effect.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Raises:</span></span><br><span class="line"><span class="string">        RuntimeError: When trying to cast :class:`torch.float32` to :class:`torch.int32` or :class:`torch.int64` as well as for trying to cast :class:`torch.float64` to :class:`torch.int64`. These conversions might lead to overflow errors since the floating point ``dtype`` cannot store consecutive integers over the whole range of the integer ``dtype``.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>ConvertImageDtype</code> 将转变数据类型，可能会出现溢出的情况。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">img = torch.tensor([[[<span class="number">255</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">255</span>]], [[<span class="number">0</span>, <span class="number">255</span>], [<span class="number">0</span>, <span class="number">255</span>]], [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">255</span>, <span class="number">0</span>]]], dtype=torch.uint8)</span><br><span class="line">print(img)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[255,   0],</span></span><br><span class="line"><span class="string">         [  0, 255]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[  0, 255],</span></span><br><span class="line"><span class="string">         [  0, 255]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[  0,   0],</span></span><br><span class="line"><span class="string">         [255,   0]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t1 = transforms.ConvertImageDtype(torch.int32)</span><br><span class="line">print(t1(img))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[2139095040,          0],</span></span><br><span class="line"><span class="string">         [         0, 2139095040]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[         0, 2139095040],</span></span><br><span class="line"><span class="string">         [         0, 2139095040]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[         0,          0],</span></span><br><span class="line"><span class="string">         [2139095040,          0]]], dtype=torch.int32)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t2 = transforms.ConvertImageDtype(torch.uint8)</span><br><span class="line">print(t2(img))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[255,   0],</span></span><br><span class="line"><span class="string">         [  0, 255]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[  0, 255],</span></span><br><span class="line"><span class="string">         [  0, 255]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[  0,   0],</span></span><br><span class="line"><span class="string">         [255,   0]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002000400.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000400.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.ToPILImage</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:04:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:04:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:24:50" itemprop="dateModified" datetime="2021-10-27T09:24:50+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000400.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000400.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.8k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformstopilimage"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformstopilimage"></a> Pytorch.torchvision.transforms.ToPILImage</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToPILImage</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Convert a tensor or an ndarray to PIL Image. This transform does not support torchscript.</span></span><br><span class="line"><span class="string">    Converts a torch.*Tensor of shape C x H x W or a numpy ndarray of shape H x W x C to a PIL Image while preserving the value range.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        mode (`PIL.Image mode`_): color space and pixel depth of input data (optional).</span></span><br><span class="line"><span class="string">            If ``mode`` is ``None`` (default) there are some assumptions made about the input data:</span></span><br><span class="line"><span class="string">            - If the input has 4 channels, the ``mode`` is assumed to be ``RGBA``.</span></span><br><span class="line"><span class="string">            - If the input has 3 channels, the ``mode`` is assumed to be ``RGB``.</span></span><br><span class="line"><span class="string">            - If the input has 2 channels, the ``mode`` is assumed to be ``LA``.</span></span><br><span class="line"><span class="string">            - If the input has 1 channel, the ``mode`` is determined by the data type (i.e ``int``, ``float``, ``short``).</span></span><br><span class="line"><span class="string">	&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>ToPILImage</code> 将 <code>tensor(C x H x W)</code> 或 <code>numpy.ndarray(H x W x C)</code> 转换为 <code>PIL.Image</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> PIL.Image <span class="keyword">as</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">img = np.array([[[<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>]], [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>], [<span class="number">255</span>, <span class="number">255</span>, <span class="number">0</span>]]])</span><br><span class="line">print(img)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[[255   0   0]</span></span><br><span class="line"><span class="string">  [  0 255   0]]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> [[  0   0 255]</span></span><br><span class="line"><span class="string">  [255 255   0]]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.ToPILImage(mode=<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">img = t(img)</span><br><span class="line">print(img)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;PIL.Image.Image image mode=RGB size=2x2 at 0x1D968E24320&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">img = torch.tensor([[[<span class="number">255</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">255</span>]], [[<span class="number">0</span>, <span class="number">255</span>], [<span class="number">0</span>, <span class="number">255</span>]], [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">255</span>, <span class="number">0</span>]]], dtype=torch.uint8)</span><br><span class="line">print(img)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[255,   0],</span></span><br><span class="line"><span class="string">         [  0, 255]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[  0, 255],</span></span><br><span class="line"><span class="string">         [  0, 255]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[  0,   0],</span></span><br><span class="line"><span class="string">         [255,   0]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">img = t(img)</span><br><span class="line">print(img)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;PIL.Image.Image image mode=RGB size=2x2 at 0x1D954D02128&gt;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002000300.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000300.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.PILToTensor</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:03:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:03:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:18:42" itemprop="dateModified" datetime="2021-10-27T09:18:42+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000300.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000300.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformspiltotensor"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformspiltotensor"></a> Pytorch.torchvision.transforms.PILToTensor</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PILToTensor</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Convert a ``PIL Image`` to a tensor of the same type. This transform does not support torchscript.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Converts a PIL Image (H x W x C) to a Tensor of shape (C x H x W).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>PILToTensor</code> 将取值范围为 <code>[0, 255]</code> 的 <code>PIL Image(H x W x C)</code> 转换为 <code>tensor(C x H x W)</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> PIL.Image <span class="keyword">as</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">img = np.array([[[<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>]], [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>], [<span class="number">255</span>, <span class="number">255</span>, <span class="number">0</span>]]])</span><br><span class="line">print(img)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[[255   0   0]</span></span><br><span class="line"><span class="string">  [  0 255   0]]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> [[  0   0 255]</span></span><br><span class="line"><span class="string">  [255 255   0]]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">img = Image.fromarray(img.astype(<span class="string">&#x27;uint8&#x27;</span>), <span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">t = transforms.PILToTensor()</span><br><span class="line">print(t(img))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[255,   0],</span></span><br><span class="line"><span class="string">         [  0, 255]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[  0, 255],</span></span><br><span class="line"><span class="string">         [  0, 255]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[  0,   0],</span></span><br><span class="line"><span class="string">         [255,   0]]], dtype=torch.uint8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>上述维度转换过程如下图所示。</p><p><img src="/images/Pytorch/Pytorch.torchvision.transforms.PILToTensor_figure_1.PNG" alt=""></p></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002000200.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000200.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.ToTensor</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:02:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:02:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:26:24" itemprop="dateModified" datetime="2021-10-27T09:26:24+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000200.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000200.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.8k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>2 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformstotensor"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformstotensor"></a> Pytorch.torchvision.transforms.ToTensor</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToTensor</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor. This transform does not support torchscript.</span></span><br><span class="line"><span class="string">    Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8. In the other cases, tensors are returned without scaling.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	note:</span></span><br><span class="line"><span class="string">		Because the input image is scaled to [0.0, 1.0], this transformation should not be used when transforming target image masks. See the `references`_ for implementing the transforms for image masks.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>ToTensor</code> 将取值范围为 <code>[0, 255]</code> 的 <code>PIL Image(H x W x C)</code> 或 <code>dtype = np.int8</code> 的 <code>numpy.ndarray(H x W x C)</code> 转换为 <code>tensor(C x H x W)</code>，并将值放缩到 <code>[0.0, 1.0]</code>。注意，如果格式或数据类型不是上述两个类型，则直接返回转换后的 <code>tensor</code> 而不进行放缩。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = np.array([[<span class="number">255</span>, <span class="number">255</span>], [<span class="number">127</span>, <span class="number">127</span>]], dtype=np.uint8)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[255 255]</span></span><br><span class="line"><span class="string"> [127 127]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t = transforms.ToTensor()</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[1.0000, 1.0000],</span></span><br><span class="line"><span class="string">         [0.4980, 0.4980]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = np.array([[<span class="number">255</span>, <span class="number">255</span>], [<span class="number">127</span>, <span class="number">127</span>]], dtype=np.int8)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[ -1  -1]</span></span><br><span class="line"><span class="string"> [127 127]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[ -1,  -1],</span></span><br><span class="line"><span class="string">         [127, 127]]], dtype=torch.int8)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = np.array([[<span class="number">255</span>, <span class="number">255</span>], [<span class="number">127</span>, <span class="number">127</span>]], dtype=np.int32)</span><br><span class="line">print(a)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[[255 255]</span></span><br><span class="line"><span class="string"> [127 127]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[255, 255],</span></span><br><span class="line"><span class="string">         [127, 127]]], dtype=torch.int32)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://zswldxb.github.io/posts/20211002000100.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="智商为零的小白"><meta itemprop="description" content="生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="智商为零的小白的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/20211002000100.html" class="post-title-link" itemprop="url">Pytorch.torchvision.transforms.Compose</a></h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-10-02 00:01:00" itemprop="dateCreated datePublished" datetime="2021-10-02T00:01:00+08:00">2021-10-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2021-10-27 09:16:42" itemprop="dateModified" datetime="2021-10-27T09:16:42+08:00">2021-10-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Pytorch/" itemprop="url" rel="index"><span itemprop="name">Pytorch</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/20211002000100.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/20211002000100.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>1.5k 字</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="pytorchtorchvisiontransformscompose"><a class="markdownIt-Anchor" href="#pytorchtorchvisiontransformscompose"></a> Pytorch.torchvision.transforms.Compose</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Compose</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Composes several transforms together. This transform does not support torchscript. Please, see the note below.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        transforms (list of ``Transform`` objects): list of transforms to compose.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><p><code>Compose</code> 将多个 <code>transform</code> 线性组合为 <code>list</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">print(<span class="string">f&#x27;torch version: <span class="subst">&#123;torch.__version__&#125;</span>&#x27;</span>)</span><br><span class="line">print(<span class="string">f&#x27;torchvision version: <span class="subst">&#123;torchvision.__version__&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">torch version: 1.9.0</span></span><br><span class="line"><span class="string">torchvision version: 0.10.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">a = np.array([[<span class="number">255</span>, <span class="number">255</span>], [<span class="number">127</span>, <span class="number">127</span>]], dtype=np.uint8)</span><br><span class="line">t = transforms.Compose([transforms.ToTensor(), transforms.CenterCrop(<span class="number">6</span>)])</span><br><span class="line">print(t(a))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],  </span></span><br><span class="line"><span class="string">         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],  </span></span><br><span class="line"><span class="string">         [0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000],  </span></span><br><span class="line"><span class="string">         [0.0000, 0.0000, 0.4980, 0.4980, 0.0000, 0.0000],  </span></span><br><span class="line"><span class="string">         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],  </span></span><br><span class="line"><span class="string">         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">t1 = transforms.ToTensor()</span><br><span class="line">t2 = transforms.CenterCrop(<span class="number">6</span>)</span><br><span class="line">print(t2(t1(a)))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],</span></span><br><span class="line"><span class="string">         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],</span></span><br><span class="line"><span class="string">         [0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000],</span></span><br><span class="line"><span class="string">         [0.0000, 0.0000, 0.4980, 0.4980, 0.0000, 0.0000],</span></span><br><span class="line"><span class="string">         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],</span></span><br><span class="line"><span class="string">         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></div><footer class="post-footer"><div class="post-eof"></div></footer></article><nav class="pagination"><a class="extend prev" rel="prev" href="/page/14/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="page-number" href="/page/14/">14</a><span class="page-number current">15</span><a class="page-number" href="/page/16/">16</a><a class="page-number" href="/page/17/">17</a><span class="space">&hellip;</span><a class="page-number" href="/page/60/">60</a><a class="extend next" rel="next" href="/page/16/"><i class="fa fa-angle-right" aria-label="下一页"></i></a></nav></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="智商为零的小白" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">智商为零的小白</p><div class="site-description" itemprop="description">生命并不是你活了多少日子。而是你记住了多少日子。你要使你过的每一天。都值得记忆。</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">593</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">32</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">92</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zswldxb" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zswldxb" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:1979938740@qq.com" title="E-Mail → mailto:1979938740@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">智商为零的小白</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="站点总字数">2.4m 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">35:44 小时</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-divider">|</span> <span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});</script><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css"><script>NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'rxJydM3QVoypB9apkSU3e9ML-gzGzoHsz',
      appKey     : 'NqXT8ScfaD1udoMiPk3NQ6MF',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});</script><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><canvas class="fireworks" style="position:fixed;left:0;top:0;z-index:1;pointer-events:none"></canvas><script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script><script type="text/javascript" src="/js/src/fireworks.js"></script></body></html>